{
  
    
        "post0": {
            "title": "SSH鍵の作成と使用について",
            "content": "はじめに . 現在のシステム開発・運用において、Linuxにリモートアクセスする際には、公開鍵認証を用いたSSH(Secure Shell)が多く使用されています。 本記事では、キーベアを使用する際の注意点について説明します。 . SSH・公開鍵認証とは何か(簡単に) . SSHとは . サーバへネットワークを介したリモートログインを安全に行うためのプロトコルです | 通信経路が暗号化されるためインターネットを経由しても安全にアクセスできます | . 公開鍵認証とは . 秘密鍵と公開鍵のペアを使って認証する方式です 秘密鍵と公開鍵のペアをキーペアと言います | 公開鍵をアクセス先のサーバに登録し、秘密鍵をアクセス元のPC等に保管します | 十分な鍵長をもったキーペアであれば、使い回すことのリスクがほぼありません 秘密鍵はネットワーク上に一切送出されません | 暗号化方式や鍵長にもよりますが、公開鍵から秘密鍵を割り出すことは、(理論上は可能ですが)現実的には非常に困難です | . | . | . キーペアの作成 . どこで作成するか . キーペアはローカルPCで作成します。 macOSであればssh-keygenコマンドを用いて作成します。 AWS EC2など、サービス側でキーペアを作成し秘密鍵をダウンロードすることができるサービスものもありますが、サービスごとにキーペアを作成するよりも、ローカルPCで一つのキーペアを作成し、作成した公開鍵をそれぞれのサービスへ登録する方が管理が簡単になります。 . | 鍵の種類と鍵長 . SSHで使用するキーペアにはいくつかの種類があり、作成時に選択することができます。 . Ed25519 . RSAよりも強固でパフォーマンスも良い方式です。 鍵長は256bit固定です。 古いSSHクライアントやサーバは対応していない場合があります。 . ssh-keygenコマンドでは-tオプションにed25519を与えることで作成できます。 . ssh-keygen -t ed25519 . | RSA . 移植性が高いがセキュリティを確保するためには鍵長を大きくする必要があります。 鍵長は最小1024bit,最大16384bitです。 一般に3072bitで十分とされています。 macOS Venturaでは、デフォルトでは使用できなくなっています。 . ssh-keygenコマンドで作成する場合はデフォルトでRSA 2048bitのキーペアが作成されます。 RSAを明示的に指定する場合は-tオプションにrsaを与えます。鍵長は-bオプションで指定できます。 . rsaを明示的に設定して鍵長4096bitのキーペアを作成する場合は以下のようになります。 . ssh-keygen -t rsa -b 4096 . | ECDSA . Ed25519よりも移植性が高いが、安全性には懸念が持たれています。 Ed25519が使用可能なのであれば、選択する必要はないでしょう。 . | DSA . 脆弱性が発見されたため使用してはいけません。 新しいOpenSSHサーバでは使用できなくなっています。 . | . キーペアを新しく作成する際は、使用可能であるならばEd25519を、Ed25519が使用できないならば3072bitまたは4096bitのRSAを選択するのが良いでしょう。 . | パスフレーズを設定する . パスフレーズは必ず設定しましょう。 設定するパスフレーズは、システムにログインする際のパスワードと同じく、十分に長く推測が困難なものを設定すべきです。 パスフレーズを設定しないと、秘密鍵は平文で保存されることになるので、Linuxサーバに保存した場合はrootユーザがアクセスできてしまいます。 . ssh-keygenコマンドでキーペアを作成する場合は、パスフレーズを要求するプロンプトが表示されるので、そこで設定します。 . $ ssh-keygen -t ed25519 Generating public/private ed25519 key pair. Enter file in which to save the key (/Users/user/.ssh/id_ed25519): yes Enter passphrase (empty for no passphrase): # &lt;= ここでパスフレーズを入力 Enter same passphrase again: # &lt;= パスフレーズを再入力 . | . 秘密鍵の使用 . SSH接続する際はssh-agentを使用する . 何度もSSH接続する場合、パスフレーズの入力が面倒になります。 ssh-agentは秘密鍵を一時的に保存することができ、保存の際にパスフレーズを入力しておけば、使用の際にはパスフレーズを入力せずにSSH接続ができます。 ただし、他人にPCを操作されるとパスフレーズ入力なしでSSH接続されてしまうので、離席時にはPCをロックしたり登録した鍵を全て削除したりといった配慮が必要です。 ssh-agentはプロセスを終了すると、一時的に保存した秘密鍵を全て忘れます。よってOSの終了や再起動を行うと、使用する秘密鍵を再度登録しなければなりません。 . ssh-agentを起動する . macOSであればssh-addコマンドの実行をトリガーとして起動するため、起動操作は必要ありません。 . | ssh-agentに秘密鍵を登録する . ssh-agentに秘密鍵を登録するには、ssh-addコマンドに秘密鍵のパスを与えます。 秘密鍵にパスフレーズを設定している場合は入力を要求されるので、入力します。 登録に成功するとIdentity added: (秘密鍵のパス)が表示されます。 . $ ssh-add .ssh/id_ed25519 # &lt;= 登録する秘密鍵のパス Enter passphrase for .ssh/id_ed25519: # &lt;= 秘密鍵のパスフレーズを入力 Identity added: .ssh/id_ed25519 . | ssh-agentに登録されている秘密鍵を確認する . ssh-agentに登録されている秘密鍵を確認するには、ssh-agent -lコマンドを実行します . | ssh-agentから秘密鍵を削除する . ssh-agentに登録されている秘密鍵を削除するには、ssh-agent -d (秘密鍵のパス)コマンドを実行します。 登録されている全ての秘密鍵を削除する場合はssh-agent -Dになります。 . | mac OSであれば、ssh-addコマンドに--apple-use-keychainオプションを追加することで、秘密鍵をキーチェーンに保管できます。 . キーチェーンに秘密鍵を登録する . mac OSのキーチェーンに秘密鍵を登録するには、ssh-addコマンドに--apple-use-keychainを与えます。 この操作により、ssh-agetに秘密鍵を追加するのと同時にキーチェーンにも秘密鍵を追加します。 . ssh-add --apple-use-keychain .ssh/id_ed25519 # &lt;= 登録する秘密鍵のパス Enter passphrase for .ssh/id_ed25519: # &lt;= 秘密鍵のパスフレーズを入力 Identity added: .ssh/id_ed25519 . | キーチェーンから秘密鍵を読み込む . ssh-agentを終了すると追加した秘密鍵を忘れてしまうのは前述した通りです。 秘密鍵をキーチェーンに追加してある場合はssh-addコマンドに--apple-load-keychainオプションを与えると、キーチェーンから秘密鍵を読み込みます。 . ssh-add --apple-load-keychain Identity added: .ssh/id_ed25519 # &lt;= ロードされた秘密鍵 . | その他 . パスフレーズを設定していないキーペアを既に使用している場合 . ssh-keygenコマンドの-pオプションを使うと、パスフレーズを再設定できます . ssh-keygen -p -f (パスフレーズを再設定する秘密鍵のパス) . | .",
            "url": "https://taka4ma.github.io/fastpages/ssh/2023/04/29/about-ssh-key-management.html",
            "relUrl": "/ssh/2023/04/29/about-ssh-key-management.html",
            "date": " • Apr 29, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "GaleraCluster構築手順",
            "content": "はじめに . このドキュメントは、Rocky Linux 8をインストールした複数のノードにmariadbを使ってGalera Clusterを構築する手順を提供します。 . Galera Clusterは奇数のノード数で構成することが推奨されます。 これは、クラスタを構成するノードがネットワーク障害等によって分断された場合、各ノードは通信可能な他ノードを調べ、過半数を超えている場合は動作を継続し、下回っている場合は動作を停止するためです。 . しかし、本ドキュメントではノード1, ノード2の2ノードでクラスタを構成します。 これは分かりやすさを優先するためです。 とはいえ、ノード2に対する操作をノード3, ノード4…に適用することでより多い数のノードでクラスタを構成する場合でも本ドキュメントを利用できるよう記述してあります。 . Galera Clusterとは . Galera Clusterは、MySQLとMariaDBのマルチマスタークラスタリングと同期レプリケーションを提供します。 詳細は公式サイト( https://galeracluster.com/ )を参照してください。 . | . MariaDBをインストールする . まずは、クラスタを構成する各ノードにMariaDBをインストールします。 . リポジトリを追加する . MariaDBのパッケージリポジトリセットアップスクリプトを使います。 このスクリプトは、以下のタスクを行います。 . /etc/yum.repos.d/mariadb.repo へのリポジトリ設定ファイル作成 | MariaDBソフトウェアパッケージの署名検証に使用するGPG公開鍵をdownloads.mariadb.comからインポート | . スクリプト実行時に、--mariadb-server-versionを使用することで、バージョンを指定します。今回は、本ドキュメント作成時点で最新の10.11を指定しています。 . $ sudo curl -LsS https://r.mariadb.com/downloads/mariadb_repo_setup | sudo bash -s -- --mariadb-server-version=&quot;mariadb-10.11&quot; # [info] Checking for script prerequisites.# [info] MariaDB Server version 10.11 is valid # [info] Repository file successfully written to /etc/yum.repos.d/mariadb.repo # [info] Adding trusted package signing keys... /etc/pki/rpm-gpg /home/rocky /home/rocky # [info] Successfully added trusted package signing keys # [info] Cleaning package cache... 41 files removed . 作成されたリポジトリ設定ファイルは以下です。 . $ cat /etc/yum.repos.d/mariadb.repo [mariadb-main] name = MariaDB Server baseurl = https://dlm.mariadb.com/repo/mariadb-server/10.11/yum/rhel/8/x86_64 gpgkey = file:///etc/pki/rpm-gpg/MariaDB-Server-GPG-KEY gpgcheck = 1 enabled = 1 module_hotfixes = 1 [mariadb-maxscale] # To use the latest stable release of MaxScale, use &quot;latest&quot; as the version # To use the latest beta (or stable if no current beta) release of MaxScale, use &quot;beta&quot; as the version name = MariaDB MaxScale baseurl = https://dlm.mariadb.com/repo/maxscale/latest/yum/rhel/8/x86_64 gpgkey = file:///etc/pki/rpm-gpg/MariaDB-MaxScale-GPG-KEY gpgcheck = 1 enabled = 1 [mariadb-tools] name = MariaDB Tools baseurl = https://downloads.mariadb.com/Tools/rhel/8/x86_64 gpgkey = file:///etc/pki/rpm-gpg/MariaDB-Enterprise-GPG-KEY gpgcheck = 1 enabled = 1 . | パッケージをインストールする . リポジトリ追加後、パッケージをインストールします。 . $ sudo dnf install -y MariaDB-server MariaDB-client MariaDB-backup &lt;&lt; 中略 &gt;&gt; Complete! . | データベースの設定 . MariaDBをインストールできたら、初期設定を行なっていきます。 . サービスの自動起動が無効になっていることを確認する . Galera Clusterを構成する場合、OS起動時にDBが自動起動すると困る場合があるので、自動起動しない設定になっていることを確認しておきます。 . このセクションはクラスタを構成する全てのノードで行います。 . $ sudo systemctl is-enabled mariadb disabled . systemctl is-enabledの結果がdisabledであればOKです。 . ログ出力設定 . MariaDBはインストール直後の状態ではログが出力されないので、ログを出力するよう設定します。 本ドキュメントでは/var/log/mariadbに出力することにします。 . このセクションはクラスタを構成する全てのノードで行います。 . ログの出力先ディレクトリを作成する . $ sudo install -d -m 0755 -o mysql -g mysql /var/log/mariadb . | ログの出力先を設定する . /etc/my.cnf.d/server.cnfをエディタで開いて、[mysqld]セクションに、以下の行を追加します。 . log-error=/var/log/mariadb/mariadb.log . | rootアカウントを設定する . mariadbをインストールすると、rootアカウントが作成されますが、パスワードが設定されていないので、パスワードを設定します。 . このセクションは、クラスタを構成するノードの最初の1台になるノード(本ドキュメントではノード1)のみで行います。 . MariaDBを開始する . アカウントを設定するにはmariadbが動作していなければならないので、まずはmariadbを開始します。 . $ sudo systemctl start mariadb . | MariaDBサーバへrootユーザで接続する . $ sudo mysql . MariaDBサーバへの接続はmysqlコマンドを使用します。 mysqlコマンドは-uオプションでログインするユーザを指定しますが、-uオプションを設定しない場合はLinuxの現在のユーザー名をユーザとして使用します。 (sudo mysqlとした場合、ユーザはrootになります。) ログインに成功すると、MariaDB &gt;プロンプトが表示されます。 . | rootにパスワードを設定する . ALTER USERステートメントを使って、パスワードを設定します。 . &gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;new_password&#39;; . new_passwordの箇所を実際に設定したいパスワードにしてください。 . | MariaDBサーバから切断する . パスワードを設定したら、一度、mariadbサーバから切断します。 . &gt; exit; . | もう一度MariaDBサーバへ接続し、パスワードが設定できていることを確認する . もう一度mariadbサーバへ接続し、パスワードが設定できていることを確認します。今回は-pオプションをつけます。Enter password:というプロンプトが表示されたら、先ほど設定したパスワードを入力します。 . $ sudo mysql -p Enter password: ******** . ********の箇所に、実際に設定したパスワードを入力します。 ログインに成功すれば、MariaDB &gt;プロンプトが表示されます。 . | MariaDBサーバから切断する . パスワードを設定できていることが確認できたら、mariadbサーバから切断します。 . &gt; exit; . | (オプション) .my.cnf を作成する . セキュリティポリシー上許されるのであれば、以下のファイルを/root/.my.cnfに作成します。 (********の箇所は実際に設定したパスワードを記述してください。) このファイルを作成しておくと、sudo mysqlでパスワードを入力せずにログインできるようになります。 . [mysql] user=root host=localhost password=&#39;********&#39; socket=/var/lib/mysql/mysql.sock [client] user=root host=localhost password=&#39;********&#39; socket=/var/lib/mysql/mysql.sock [mysqldump] user=root host=localhost password=&#39;********&#39; socket=/var/lib/mysql/mysql.sock [mysqladmin] user=root host=localhost password=&#39;********&#39; socket=/var/lib/mysql/mysql.sock [mysqlcheck] user=root host=localhost password=&#39;********&#39; socket=/var/lib/mysql/mysql.sock . | 匿名ユーザを削除する . MariaDBをインストールすると、匿名のユーザが作成されているので、削除しておきます。 . このセクションは、クラスタを構成するノードの最初の1台になるノード(本ドキュメントではノード1)のみで行います。 . ユーザを確認する . mysqlコマンドの-eオプションにSQL分を渡すことで、クエリーを実行することができます。今回はそれを利用して、現在のユーザ一覧を出力します。 (-eオプションを使わず、一度ログインしてから実行しても構いません。) (/root/.my.cnfを設定している場合は-pオプションは不要です。-pオプションをつけると/root/.my.cnfの設定に関わらずパスワードを要求されます。) . $ sudo mysql -p -e &quot;select user,host,password from mysql.user;&quot; Enter password: +-++-+ | User | Host | Password | +-++-+ | mariadb.sys | localhost | | | root | localhost | *0913BF2E2CE20CE21BFB1961AF124D4920458E5F | | mysql | localhost | invalid | | PUBLIC | | | | | localhost | | | | hostname | | +-++-+ . Userの箇所が空になっているレコードが匿名ユーザです。 Hostがhostnameになっている箇所は、実際はインストールされているマシンのhostnameが設定されています。 . | 匿名ユーザを削除する . 以下のようにクエリーを実行して、匿名ユーザを削除します。 . $ sudo mysql -p -e &quot;delete from mysql.user where user = &#39;&#39;;&quot; Enter password: . | 結果を確認しておく . 匿名ユーザが削除されていることを確認しておきます。 . $ sudo mysql -p -e &quot;select user,host,password from mysql.user;&quot; Enter password: +-+--+-+ | User | Host | Password | +-+--+-+ | mariadb.sys | localhost | | | root | localhost | *0913BF2E2CE20CE21BFB1961AF124D4920458E5F | | mysql | localhost | invalid | | PUBLIC | | | +-+--+-+ . | MariaDBを停止する . アカウントを設定が終わったら、MariaDBを停止しておきます。 . $ sudo systemctl stop mariadb . | wsrepオプションを設定する . /etc/my.cnf.d/server.cnfファイルのwsrepオプションを設定します。 (“wsrep”は”Write Set REPlication”の略で、Galera Clusterにおいてレプリケーションやデータ同期のために使用されるプロトコルおよびAPIです。) . このセクションはクラスタを構成する全てのノードで行います。 . wsrep_on . レプリケーションを行うかの設定です。コメントアウトされているので、アンコメントします。 . [galera] # Mandatory settings wsrep_on=ON . | wsrep_provider . レプリケーションプラグインのパスを設定します。コメントアウトされているので、アンコメントした上で、パスを設定します。 Rocky8にMariaDB10.11をインストールした場合のパスは/usr/lib64/galera-4/libgalera_smm.soです。 (他のOS, バージョンの場合はfindコマンドを使うなどの方法で、libgalera_smm.soを探してください。」) . [galera] # Mandatory settings wsrep_on=ON wsrep_provider=/usr/lib64/galera-4/libgalera_smm.so . | binlog_format . バイナリログのフォーマットです。コメントアウトされているので、アンコメントします。 . binlog_format=row . | default_storage_engine . デフォルトのストレージエンジンです。コメントアウトされているので、アンコメントします。 . default_storage_engine=InnoDB . | innodb_autoinc_lock_mode . 自動インクリメント値を生成するためのInnoDB ロックモードの設定です。 コメントアウトされているので、アンコメントします。 この設定は必ず2 でなければなりません。 . innodb_autoinc_lock_mode=2 . | . wsrep_cluster設定 . /etc/my.cnf.d/server.cnfファイルにクラスタ関連のオプションを設定します。 . このセクションはクラスタを構成する全てのノードで行います。 . wsrep_cluster_name . クラスタの名前を設定します。 ノードがクラスタに接続する際にこの値を照合し、一致した場合のみ接続します。 そのため、クラスタを構成する全てのノードで同じ値を設定する必要があります。 コメントアウトされているので、アンコメントした上で値を設定します。 本ドキュメントではクラスタ名を仮にsample_clusterとします。 . wsrep_cluster_name=sample_cluster . | wsrep_node_name . ノードの論理名を設定します。 この設定はノードごとに異なる値を設定する必要があります。 本ドキュメントではノード1のノード名を仮にnode1、ノード2のノード名を仮にnode2とします。 . ノード1 wsrep_node_name=node1 . | ノード2 wsrep_node_name=node2 . | . | wsrep_node_address . ノードのIPアドレスを設定します。 本ドキュメントではノード1のIPアドレスを仮に192.168.1.1、ノード1のIPアドレスを仮に192.168.1.2とします。 . ノード1 wsrep_node_address=192.168.1.1 # &lt;= 実際の値を設定してください . | ノード2 wsrep_node_address=192.168.1.2 # &lt;= 実際の値を設定してください . | . | . ファイアウォールの設定 . クラスタを構成する各ノードが相互に通信できるように、以下のポートを解放してください。 環境により必要な設定が異なるので、本ドキュメントでは設定方法は省略します。 . 3306 通常、MySQL/MariaDBはポート3306を使用します。このポートは、クライアントアプリケーションがデータベースに接続するために必要です。 | . | 4444 SSTのために使用します。SST（State Snapshot Transfer）は、クラスタ内のノード間でデータの同期を行うプロセスの一種です。SSTは、新しく追加されたノードや、オフライン状態で大量のデータ変更があった場合に、そのノードが他のノードと完全なデータの同期を行うために使用されます。 | . | 4567 クラスタ内のレプリケーションとクラスタ通信に使用します。 | . | 4568 ISTのために使用します。IST（Incremental State Transfer）は、クラスタ内のノード間でデータの同期を行うプロセスの一種です。ISTは、ノードが一時的にオフライン状態になった後、再びオンラインになった際に、そのノードがオフライン時に失ったデータを迅速かつ効率的に同期するために使用されます。 | . | . GaleraClusterの初期化 . データベースの設定が終わったら、クラスタの初期化を行います。 このセクションは、クラスタを構成するノードの最初の1台になるノード(本ドキュメントではノード1)のみで行います。 . クラスタを構成するノードとバックエンドスキーマを設定する . /etc/my.cnf.d/server.cnfファイルにオプションを設定します。 . wsrep_cluster_address . ノードがクラスタに接続する際のバックエンドスキーマとIPアドレスを設定します。 コメントアウトされているので、アンコメントした上で値を設定します。 サポートされるバックエンドスキーマはgcommのみとなります。 最初に構成する際には、ノード1のIPアドレスのみ記述しておきます。 . wsrep_cluster_address=gcomm://192.168.1.1 . | . クラスタを起動する . 以下のコマンドを実行して新しいクラスタを起動します。 sudo systemctl start mariadbでmariadbを起動すると新しいクラスタにならないので、必ずgalera_new_clusterコマンドで起動します。 . $ sudo galera_new_cluster mariadb . クラスタを起動したら、systemctl status mariadbでステータスを確認します。 Activeの項目が｀active (running)`になっていれば、起動に成功しています。 . $ sudo systemctl status mariadb ● mariadb.service - MariaDB 10.11.2 database server Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor preset: disabled) Drop-In: /etc/systemd/system/mariadb.service.d └─migrated-from-my.cnf-settings.conf Active: active (running) since Sat 2023-05-06 07:26:56 UTC; 3min 31s ago Docs: man:mariadbd(8) https://mariadb.com/kb/en/library/systemd/ Process: 863935 ExecStartPost=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Process: 863865 ExecStartPre=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] &amp;&amp; VAR= || VAR=`cd /usr/bin/..; /usr/bin/galera_recovery`; [ $? -eq 0 ] &amp;&amp; systemctl set-environment _WSREP_START_POSITION=$VAR &gt; Process: 863860 ExecStartPre=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Main PID: 863920 (mariadbd) Status: &quot;Taking your SQL requests now...&quot; Tasks: 13 (limit: 822260) Memory: 218.6M CGroup: /system.slice/mariadb.service └─863920 /usr/sbin/mariadbd --wsrep-new-cluster --wsrep_start_position=00000000-0000-0000-0000-000000000000:-1 . ノードのステータスを確認する . mysqlコマンドでクエリーを実行し、ステータスを確認します。 (/root/.my.cnfを設定している場合は-pオプションは不要です。-pオプションをつけると/root/.my.cnfの設定に関わらずパスワードを要求されます。) . wsrep_cluster_status wsrep_cluster_statusがPrimaryになっていれば、ノードはクラスタに接続し、同期されている、つまり正常であることを表しています。 . sudo mysql -p -e &quot;show status;&quot; | grep cluster_status Enter password: wsrep_cluster_status Primary . | wsrep_cluster_size wsrep_cluster_sizeはクラスタ内のノード数を表しています。この段階では1のはずです。 . sudo mysql -p -e &quot;show status;&quot; | grep cluster_size Enter password: wsrep_cluster_size 1 . | . ノードの追加 . クラスタを起動したら、ノードの追加を行います。 このセクションは、クラスタを構成するノードの2台目以降のノード(本ドキュメントではノード2)で行います。 . クラスタを構成するノードとバックエンドスキーマの設定 . /etc/my.cnf.d/server.cnfファイルにオプションを設定します。 . wsrep_cluster_address . 以下のように、クラスタの既存ノードのIPアドレスに加えて、追加するノードのIPアドレスを設定します。 それぞれのIPアドレスは,(カンマ)で区切ります。 . wsrep_cluster_address=gcomm://192.168.1.1,192.168.1.2 . | . MariaDBを開始する . systemctl start mariadbでMariaDBを開始します。 クラスタを起動したときに使用したgalera_new_clusterを 実行してはいけません。 galera_new_clusterを実行すると既存のクラスタとは別のクラスタになってしまうため、必ずsystemctl start mariadbでMariaDBを開始します。 . $ sudo systemctl start mariadb . MariaDBを起動したら、systemctl status mariadbでステータスを確認します。 Activeの項目が｀active (running)`になっていれば、起動に成功しています。 . $ sudo systemctl status mariadb ● mariadb.service - MariaDB 10.11.2 database server Loaded: loaded (/usr/lib/systemd/system/mariadb.service; disabled; vendor preset: disabled) Drop-In: /etc/systemd/system/mariadb.service.d └─migrated-from-my.cnf-settings.conf Active: active (running) since Sat 2023-05-06 08:38:06 UTC; 15s ago Docs: man:mariadbd(8) https://mariadb.com/kb/en/library/systemd/ Process: 24024 ExecStartPost=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=&gt; Process: 23759 ExecStartPre=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] &amp;&amp; VAR= || VAR=`cd /usr/bin/..; /usr&gt; Process: 23757 ExecStartPre=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0&gt; Main PID: 23814 (mariadbd) Status: &quot;Taking your SQL requests now...&quot; Tasks: 19 (limit: 822260) Memory: 206.6M CGroup: /system.slice/mariadb.service └─23814 /usr/sbin/mariadbd --wsrep_start_position=00000000-0000-0000-0000-000000000000:-1 . もし、Activeの項目が｀active (running)`にならない場合はログを確認し、問題を特定してください。 追加するノードのログだけでなく、クラスタの既存ノードのログも確認してください。 (そちらに問題解決のヒントがある場合もあります。) . ノードのステータスを確認する . 追加したノードにて、mysqlコマンドでクエリーを実行し、ステータスを確認します。 このとき入力するパスワードは、ノード1で設定したMariaDBのrootのパスワードです。 クラスタに正しく参加し同期ができていれば、MariaDBのユーザ設定が入っているmysqlデータベースも同期されるため、同じユーザとパスワードでログインすることになります。 (ノード1で/root/.my.cnfを作成している場合は、追加ノードにコピーしておくと便利です。) . wsrep_cluster_status wsrep_cluster_statusがPrimaryになっていれば、ノードはクラスタに接続し、同期されている、つまり正常であることを表しています。 . $ sudo mysql -p -e &quot;show status;&quot; | grep cluster_status Enter password: wsrep_cluster_status Primary . | wsrep_cluster_size wsrep_cluster_sizeはクラスタ内のノード数を表しています。この段階では2のはずです。 . $ sudo mysql -p -e &quot;show status;&quot; | grep cluster_size Enter password: wsrep_cluster_size 2 . | . 既存ノードにクラスタ構成ノードの情報を追加する . クラスタにすでに参加しているノードのwsrep_cluster_addressオプションに、追加したノードの情報を加えます。 もし、この変更を怠ると、既存ノードがなんらかの理由でクラスタから切断された場合、自動的にクラスタに再接続することができません。 . ノード1の/etc/my.cnf.d/server.cnfファイルは、この段階では以下のようになっているはずです。 . wsrep_cluster_address=gcomm://192.168.1.1 . これを追加したノードと同じく、以下のように変更します。 . wsrep_cluster_address=gcomm://192.168.1.1,192.168.1.2 . 設定を変更したら、MariaDBを再起動します。 (このとき、ノード2でsudo tail -f /var/log/mariadb/mariadb.logしておくと、ノードがクラスタから切断され再接続する際に出力されるログを観測することができます。) . sudo systemctl restart mariadb . コマンドが終わったら、mysqlコマンドを使ってwsrep_cluster_statusとwsrep_cluster_sizeを確認してください。ノードを追加した時と同じ値になっていれば、クラスタに再接続できています。 . 以上で、GaleraClusterの構築は完了です。 .",
            "url": "https://taka4ma.github.io/fastpages/galera/rocky-linux/2023/04/26/GaleraClusterConstructionProcedure.html",
            "relUrl": "/galera/rocky-linux/2023/04/26/GaleraClusterConstructionProcedure.html",
            "date": " • Apr 26, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "FirebaseのRealtime Databaseのメモ",
            "content": "&#12503;&#12525;&#12472;&#12455;&#12463;&#12488;&#12398;&#20316;&#25104; . Firebaseにアクセスする | コンソールへ移動をクリック Googleアカウントにログインしていると、右上にアカウントのアイコンが表示される | 複数のアカウントを所有している場合は、意図したアカウントか確認しておく | ログインしていない場合は右上にログインと表示されるので、クリックしてログインする | . | . プロジェクトを追加をクリック | . プロジェクトの作成画面(1/3) が表示されるので、プロジェクト名を入力し、続行をクリック | プロジェクトの作成(2/3) が表示されるので、Googleアナリティクスを有効にし、続行をクリック | プロジェクトの作成(3/3) が表示されるので、Googleアナリティクスアカウントを選択または作成し、プロジェクトを作成をクリック | 新しいプロジェクトの準備ができました、と表示されたら続行をクリック | 新しく作成したプロジェクトの概要が表示されるのでウェブをクリック | . ウェブアプリへのFirebaseの追加が表示されるので、 アプリのニックネームに任意の名前を入力 | このアプリのFirebase Hosting も設定しますを選択 | デプロイ先はデフォルトのままにする | . | 入力・設定できたらアプリの登録をクリック | . Firabase SDKの追加が表示されるので、 今回は&lt;script&gt;タグを選択するをクリック | 表示されたスクリプトをコピーし、一旦適当なテキストファイルに保存しておく | . | スクリプトを保存したら次へをクリック | . Firebase CLIのインストールが表示されるが、前回インストール済みなので、何もせず、次へをクリック | . Firabase Hostingへのデプロイが表示されるが、後でやるので、コンソールに進むをクリック | . &#12487;&#12540;&#12479;&#12505;&#12540;&#12473;&#12398;&#20316;&#25104; . プロジェクトの概要画面で構築 &gt; Realtime Databaseを選択 | . データベースを作成をクリック | . 任意のRealtime Databaseのロケーションを選択し、次へ 今回は米国(us-central1)を選択した | . | . データベースのセキュリティルールはテストモードで開始するを選択し、有効にするをクリック | . データベースが作成されたので、ルールタブを選択 | read, writeをtrueに変更 | 公開をクリック | . &#12525;&#12540;&#12459;&#12523;&#29872;&#22659;&#12398;&#27083;&#31689; . firebase loginは実行済みなので省略 . 適当なディレクトリを作成し、そのディレクトリへ移動する | % mkdir chat-app % cd chat-app . firebase initコマンドでディレクトリを初期化する このディレクトリで使用するfirebaseの機能を聞かれる | 今回は以下の3つを選択する Hosting: Configure files for Firebase Hosting and (optionally) set up GitHub Action deploys | Emulators: Set up local emulators for Firebase products | Realtime Database: Configure a security rules file for Realtime Database and (optionally) provision default in stance | . | . | % firebase init ######## #### ######## ######## ######## ### ###### ######## ## ## ## ## ## ## ## ## ## ## ## ###### ## ######## ###### ######## ######### ###### ###### ## ## ## ## ## ## ## ## ## ## ## ## #### ## ## ######## ######## ## ## ###### ######## You&#39;re about to initialize a Firebase project in this directory: &lt;directory path&gt; ? Which Firebase features do you want to set up for this directory? Press Space to select features, then Enter to confirm your choices. (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection, and &lt;enter&gt; to proce ed) ❯◯ Realtime Database: Configure a security rules file for Realtime Database and (optionally) provision default in stance ◯ Firestore: Configure security rules and indexes files for Firestore ◯ Functions: Configure a Cloud Functions directory and its files ◯ Hosting: Configure files for Firebase Hosting and (optionally) set up GitHub Action deploys ◯ Hosting: Set up GitHub Action deploys ◯ Storage: Configure a security rules file for Cloud Storage (Move up and down to reveal more choices) . プロジェクトへの関連付けを設定する 今回は、最初に作成したプロジェクトに関連づけたいので、Use an existing projectを選択する | . | === Project Setup First, let&#39;s associate this project directory with a Firebase project. You can create multiple project aliases by running firebase use --add, but for now we&#39;ll just set up a default project. ? Please select an option: ❯ Use an existing project Create a new project Add Firebase to an existing Google Cloud Platform project Don&#39;t set up a default project . 関連付けるプロジェクトを選択する | ? Please select an option: Use an existing project ? Select a default Firebase project for this directory: test-be918 (test) ❯ test2-626eb (test2) . データベースのセットアップ データベースのセキュリティルールのファイルを設定します | 今回はデフォルトのままにします | . | === Database Setup i database: ensuring required API firebasedatabase.googleapis.com is enabled... ✔ database: required API firebasedatabase.googleapis.com is enabled Firebase Realtime Database Security Rules allow you to define how your data should be structured and when your data can be read from and written to. ? What file should be used for Realtime Database Security Rules? (database.rules.json) . 公開するディレクトリを設定する 今回はデフォルト(public)のままにする | . | === Hosting Setup Your public directory is the folder (relative to your project directory) that will contain Hosting assets to be uploaded with firebase deploy. If you have a build process for your assets, use your build&#39;s output directory. ? What do you want to use as your public directory? (public) . SPA(single page application)用の設定を行うか否か 今回はNを選択 | . | ? Configure as a single-page app (rewrite all urls to /index.html)? (y/N) . GitHubからの自動デプロイを設定するか否か 今回はNを選択 | . | ? Set up automatic builds and deploys with GitHub? (y/N) . エミュレータのセットアップ 今回は、以下の2つを選択する Database Emulator | Hosting Emulator | . | . | === Emulators Setup ? Which Firebase emulators do you want to set up? Press Space to select emulators, then Enter to confirm your cho ices. (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection, and &lt;enter&gt; to proceed) ❯◯ Authentication Emulator ◯ Functions Emulator ◯ Firestore Emulator ◯ Database Emulator ◯ Hosting Emulator ◯ Pub/Sub Emulator ◯ Storage Emulator . databaseエミュレータ、hostingエミュレータのポート設定 今回はデフォルトのままにする | . | ? Which port do you want to use for the database emulator? (9000) ? Which port do you want to use for the hosting emulator? (5000) . エミュレータのUI設定 今回はデフォルトのままにする | . | ? Would you like to enable the Emulator UI? Yes ? Which port do you want to use for the Emulator UI (leave empty to use any available port)? . 今すぐエミュレータをダウンロードするか 今回はデフォルトのままにする | . | ? Would you like to download the emulators now? (y/N) . 以上の設定を終えると、フォルダの初期化が行われる | i Writing configuration info to firebase.json... i Writing project information to .firebaserc... i Writing gitignore file to .gitignore... ✔ Firebase initialization complete! . フォルダ内に、ファイル・フォルダが作成されている . % tree . ├── database.rules.json ├── firebase.json └── public ├── 404.html └── index.html . &#12501;&#12449;&#12452;&#12523;&#12434;&#20316;&#25104;&#12539;&#32232;&#38598;&#12377;&#12427; . public/style.css . publicディレクトリにstyle.cssを作成する . body { background-color: gainsboro; } h1 { color: coral; text-align: center; } div { text-align: center; } textarea { vertical-align:top; } #output { background-color: skyblue; } . public/index.js . publicディレクトリにindex.jsを作成する . var database = firebase.database(); let room = &quot;chat_room&quot;; const send = document.getElementById(&quot;send&quot;); const name = document.getElementById(&quot;name&quot;); const message = document.getElementById(&quot;message&quot;); const output = document.getElementById(&quot;output&quot;); //送信処理 send.addEventListener(&#39;click&#39;, function() { var now = new Date(); database.ref(room).push({ name: name.value, message: message.value, date: now.getFullYear() + &#39;年&#39; + now.getMonth()+1 + &#39;月&#39; + now.getDate() + &#39;日&#39; + now.getHours() + &#39;時&#39; + now.getMinutes() + &#39;分&#39; }); message.value=&quot;&quot;; name.value=&quot;&quot;; }); //受信処理 database.ref(room).on(&quot;child_added&quot;, function(data) { const v = data.val(); const k = data.key; let str = &quot;&quot;; str += &#39;&lt;div class=&quot;name&quot;&gt;名前：&#39;+v.name+&#39;&lt;/div&gt;&#39;; str += &#39;&lt;div class=&quot;text&quot;&gt;日時：&#39;+v.date+&#39;&lt;/div&gt;&#39;; str += &#39;&lt;div class=&quot;text&quot;&gt;メッセージ：&#39;+v.message+&#39;&lt;/div&gt;&lt;hr&gt;&#39;; output.innerHTML += str; }); . public/index.html . index.htmlを以下に書き換える . &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Chat App&lt;/title&gt; &lt;!-- ここにアプリのscriptタグを貼り付けます。 --&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;./style.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;リアルタイムチャット&lt;/h1&gt; &lt;div&gt; &lt;div&gt; Name&lt;br&gt;&lt;input type=&quot;text&quot; id=&quot;name&quot;&gt; &lt;/div&gt; &lt;br&gt; &lt;div&gt; Message&lt;br&gt;&lt;textarea id=&quot;message&quot; row=&quot;10&quot;&gt;&lt;/textarea&gt;&lt;br&gt;&lt;br&gt; &lt;button id=&quot;send&quot;&gt;send&lt;/button&gt; &lt;/div&gt; &lt;hr&gt; &lt;div id=&quot;output&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;script src=&quot;./index.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; . &#12456;&#12511;&#12517;&#12524;&#12540;&#12479;&#12391;&#21205;&#20316;&#30906;&#35469;&#12377;&#12427; . エミュレータを実行 . % firebase emulators:start ⚠ emulators: Support for Java version &lt;= 10 will be dropped soon in firebase-tools@11. Please upgrade to Java version 11 or above to continue using the emulators. i emulators: Starting emulators: database, hosting i database: Database Emulator logging to database-debug.log i emulators: Shutting down emulators. i database: Stopping Database Emulator i hub: Stopping emulator hub Error: TIMEOUT: Port 8089 on localhost was not active within 60000ms . エラーが出てしまう。 . firebase-toolsのIssueによるとnode.js 16へのダウングレードが回避策の模様 . Error: TIMEOUT: Port 8080 on localhost was not active within 30000ms · Issue #2379 · firebase/firebase-tools . ダウンロード | Node.jsから16.15.0のパッケージをダウンロードして、インストールする . % node -v v16.15.0 maruokatakashi@m1-Mac-mini chat-app % npm -v 8.5.5 . もう一度エミュレータを実行 . % firebase emulators:start ⚠ emulators: Support for Java version &lt;= 10 will be dropped soon in firebase-tools@11. Please upgrade to Java version 11 or above to continue using the emulators. i emulators: Starting emulators: database, hosting i database: Database Emulator logging to database-debug.log i emulators: Shutting down emulators. i database: Stopping Database Emulator i hub: Stopping emulator hub ⚠ hosting: Port 5000 is not open on localhost, could not start Hosting Emulator. ⚠ hosting: To select a different host/port, specify that host/port in a firebase.json config file: { // ... &quot;emulators&quot;: { &quot;hosting&quot;: { &quot;host&quot;: &quot;HOST&quot;, &quot;port&quot;: &quot;PORT&quot; } } } i emulators: Shutting down emulators. Error: Could not start Hosting Emulator, port taken. . 5000番portがコンフリクトしているので、firebase.jsonを編集し、hostingエミュレータのポートを8080に変更 . &quot;emulators&quot;: { &quot;database&quot;: { &quot;port&quot;: 9000 }, &quot;hosting&quot;: { &quot;port&quot;: 8080 }, &quot;ui&quot;: { &quot;enabled&quot;: true } . もう一度エミュレータを実行 . % firebase emulators:start ⚠ emulators: Support for Java version &lt;= 10 will be dropped soon in firebase-tools@11. Please upgrade to Java version 11 or above to continue using the emulators. i emulators: Starting emulators: database, hosting i database: Database Emulator logging to database-debug.log i hosting: Serving hosting files from: public ✔ hosting: Local server: http://localhost:8080 i ui: Emulator UI logging to ui-debug.log ┌─────────────────────────────────────────────────────────────┐ │ ✔ All emulators ready! It is now safe to connect your app. │ │ i View Emulator UI at http://localhost:4000 │ └─────────────────────────────────────────────────────────────┘ ┌──────────┬────────────────┬────────────────────────────────┐ │ Emulator │ Host:Port │ View in Emulator UI │ ├──────────┼────────────────┼────────────────────────────────┤ │ Database │ localhost:9000 │ http://localhost:4000/database │ ├──────────┼────────────────┼────────────────────────────────┤ │ Hosting │ localhost:8080 │ n/a │ └──────────┴────────────────┴────────────────────────────────┘ Emulator Hub running at localhost:4400 Other reserved ports: 4500 Issues? Report them at https://github.com/firebase/firebase-tools/issues and attach the *-debug.log files. ⚠ emulators: Support for Java version &lt;= 10 will be dropped soon in firebase-tools@11. Please upgrade to Java version 11 or above to continue using the emulators. . 今度は起動できた . ブラウザでlocalhost:8080にアクセスすると、開発者コンソールに以下のエラーメッセージが出る。 . Uncaught ReferenceError: database is not defined at index.js:20:1 . 色々と調べてみたが、参考にしたサイトのfirebasejsのバージョンが7、現在インストールされるバージョンが9と大きく違うので、簡単には解決できなさそう。 . 改めて、調査したいと思う。 .",
            "url": "https://taka4ma.github.io/fastpages/firebase/2022/04/29/firebase-memo2.html",
            "relUrl": "/firebase/2022/04/29/firebase-memo2.html",
            "date": " • Apr 29, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Firebaseのセットアップと静的コンテンツデプロイのメモ",
            "content": "Firebase&#12503;&#12525;&#12472;&#12455;&#12463;&#12488;&#12398;&#20316;&#25104; . Firebase にアクセスする | 使ってみる をクリック | . Firebaseへようこそと表示される Googleアカウントにログインしていると、右上にアカウントのアイコンが表示される | 複数のアカウントを所有している場合は、意図したアカウントか確認しておく | ログインしていない場合は右上にログインと表示されるので、クリックしてログインする | . | . プロジェクトを作成をクリック | . プロジェクトの作成画面(1/3) が表示されるので、プロジェクト名を入力し、利用規約、自身の取引(以下略)を確認し、続行 | . プロジェクトの作成(2/3) が表示されるので、Googleアナリティクスを有効にし、続行 | . プロジェクトの作成(3/3) が表示されるので、Googleアナリティクス利用規約を確認し、プロジェクトを作成 | . 新しいプロジェクトの準備ができました、と表示されたら続行 | . プロジェクトの概要が表示される。Firebaseプロジェクトの作成手順は以上。 | . Firebase Command Line Interface (CLI)&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . Firebase CLIは、Firebase プロジェクトのテスト、管理、デプロイをコマンドラインから行うためのソフトウェア。 . Node.js&#12398;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . Firebase CLIをインストールするためには、Node.jsが必要。 . MacにNote.jsがインストールされているか確認。 . % node -v zsh: command not found: node . インストールされていない。 . nodebrewを使う方法もあるようだが、(参考: MacにNode.jsをインストール - Qiita)まずは、公式に乗っかって、パッケージをインストールする。 . Download | Node.jsから最新のmacOS Installerをダウンロードして、インストールする。 . インストールされたバージョンを確認。 . % node -v v18.0.0 % npm -v 8.6.0 . Node.jsは18.0.0、npmは8.6.0がインストールされた。 . firebase-tools&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . npmを使って、Firebase CLIをインストールする。パッケージ名はfirebase-tools . % sudo npm install -g firebase-tools Password: npm WARN deprecated har-validator@5.1.3: this library is no longer supported npm WARN deprecated debug@4.1.0: Debug versions &gt;=3.2.0 &lt;3.2.7 || &gt;=4 &lt;4.3.1 have a low-severity ReDos regression when used in a Node.js environment. It is recommended you upgrade to 3.2.7 or 4.3.1. (https://github.com/visionmedia/debug/issues/797) npm WARN deprecated debug@4.1.1: Debug versions &gt;=3.2.0 &lt;3.2.7 || &gt;=4 &lt;4.3.1 have a low-severity ReDos regression when used in a Node.js environment. It is recommended you upgrade to 3.2.7 or 4.3.1. (https://github.com/visionmedia/debug/issues/797) npm WARN deprecated uuid@3.4.0: Please upgrade to version 7 or higher. Older versions may use Math.random() in certain circumstances, which is known to be problematic. See https://v8.dev/blog/math-random for details. npm WARN deprecated request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 added 688 packages, and audited 689 packages in 27s 35 packages are looking for funding run `npm fund` for details 21 vulnerabilities (15 moderate, 6 high) To address all issues, run: npm audit fix Run `npm audit` for details. . インストールされたバージョンを確認する . % firebase --version 10.8.0 . Firebase CLI&#12391;Google&#12450;&#12459;&#12454;&#12531;&#12488; . firebase loginを実行する | % firebase login . Firebase が CLI の使用状況やエラー報告情報を収集することを許可するか聞かれるので、Y or nを入力する | i Firebase optionally collects CLI usage and error reporting information to help improve our products. Data is collected in accordance with Google&#39;s privacy policy (https://policies.google.com/privacy) and is not used to identify you. ? Allow Firebase to collect CLI usage and error reporting information? (Y/n) . ログインのためのURLが表示され、自動的にブラウザが開かれる ブラウザが開かれない場合はURLをブラウザへコピーし、開く | . | i To change your data collection preference at any time, run `firebase logout` and log in again. Visit this URL on this device to log in: &lt;URL&gt; Waiting for authentication... . 許可をクリック | . ログインに成功すると、以下のように表示される。ブラウザは閉じて良い。 | . ターミナルには、以下のように表示される。 | ✔ Success! Logged in as &lt;Googleアカウント&gt; . &#38745;&#30340;&#12467;&#12531;&#12486;&#12531;&#12484;&#12434;&#12487;&#12503;&#12525;&#12452;&#12377;&#12427; . &#12501;&#12457;&#12523;&#12480;&#12434;&#21021;&#26399;&#21270;&#12377;&#12427; . 適当なディレクトリを作成し、そのディレクトリへ移動する | % mkdir firebase-test % cd test . firebase initコマンドでディレクトリを初期化する このディレクトリで使用するfirebaseの機能を聞かれる | 今回は静的コンテンツをホスティングするだけなので、 Hosting: Configure files for Firebase Hosting and (optionally) set up GitHub Action deploysを選択する | . | % firebase init ######## #### ######## ######## ######## ### ###### ######## ## ## ## ## ## ## ## ## ## ## ## ###### ## ######## ###### ######## ######### ###### ###### ## ## ## ## ## ## ## ## ## ## ## ## #### ## ## ######## ######## ## ## ###### ######## You&#39;re about to initialize a Firebase project in this directory: &lt;directory path&gt; ? Which Firebase features do you want to set up for this directory? Press Space to select features, then Enter to confirm your choices. (Press &lt;space&gt; to select, &lt;a&gt; to toggle all, &lt;i&gt; to invert selection, and &lt;enter&gt; to proce ed) ❯◯ Realtime Database: Configure a security rules file for Realtime Database and (optionally) provision default in stance ◯ Firestore: Configure security rules and indexes files for Firestore ◯ Functions: Configure a Cloud Functions directory and its files ◯ Hosting: Configure files for Firebase Hosting and (optionally) set up GitHub Action deploys ◯ Hosting: Set up GitHub Action deploys ◯ Storage: Configure a security rules file for Cloud Storage (Move up and down to reveal more choices) . プロジェクトへの関連付けを設定する 今回は、最初に作成したプロジェクトに関連づけたいので、Use an existing projectを選択する | . | === Project Setup First, let&#39;s associate this project directory with a Firebase project. You can create multiple project aliases by running firebase use --add, but for now we&#39;ll just set up a default project. ? Please select an option: ❯ Use an existing project Create a new project Add Firebase to an existing Google Cloud Platform project Don&#39;t set up a default project . 関連付けるプロジェクトを選択する | ? Select a default Firebase project for this directory: ❯ test-be918 (test) . 公開するディレクトリを設定する 今回はデフォルト(public)のままにする | . | === Hosting Setup Your public directory is the folder (relative to your project directory) that will contain Hosting assets to be uploaded with firebase deploy. If you have a build process for your assets, use your build&#39;s output directory. ? What do you want to use as your public directory? (public) . SPA(single page application)用の設定を行うか否か 今回はNを選択 | . | ? Configure as a single-page app (rewrite all urls to /index.html)? (y/N) . GitHubからの自動デプロイを設定するか否か 今回はNを選択 | . | ? Set up automatic builds and deploys with GitHub? (y/N) . 以上の設定を終えると、フォルダの初期化が行われる | ✔ Wrote public/404.html ✔ Wrote public/index.html i Writing configuration info to firebase.json... i Writing project information to .firebaserc... i Writing gitignore file to .gitignore... ✔ Firebase initialization complete! . フォルダ内に、ファイル・フォルダが作成されている . % tree . ├── firebase.json └── public ├── 404.html └── index.html . &#12525;&#12540;&#12459;&#12523;&#12391;&#30906;&#35469;&#12377;&#12427; . firebaseのエミュレータを使用して、ローカルで動作確認を行う . 現在のfirebase.jsonを確認する | { &quot;hosting&quot;: { &quot;public&quot;: &quot;public&quot;, &quot;ignore&quot;: [ &quot;firebase.json&quot;, &quot;**/.*&quot;, &quot;**/node_modules/**&quot; ] } } . エミュレータの設定を追加する localhost:8080 で確認できるよう設定する | . | { &quot;hosting&quot;: { &quot;public&quot;: &quot;public&quot;, &quot;ignore&quot;: [ &quot;firebase.json&quot;, &quot;**/.*&quot;, &quot;**/node_modules/**&quot; ] }, &quot;emulators&quot;: { &quot;hosting&quot;: { &quot;host&quot;: &quot;localhost&quot;, &quot;port&quot;: &quot;8080&quot; } } } . エミュレータを起動する | % firebase emulators:start i emulators: Starting emulators: hosting i hosting: Serving hosting files from: public ✔ hosting: Local server: http://localhost:8080 ⚠ emulators: The Emulator UI requires a project ID to start. Configure your default project with &#39;firebase use&#39; or pass the --project flag. ┌─────────────────────────────────────────────────────────────┐ │ ✔ All emulators ready! It is now safe to connect your app. │ └─────────────────────────────────────────────────────────────┘ ┌──────────┬────────────────┐ │ Emulator │ Host:Port │ ├──────────┼────────────────┤ │ Hosting │ localhost:8080 │ └──────────┴────────────────┘ Emulator Hub running at localhost:4400 Other reserved ports: 4500 Issues? Report them at https://github.com/firebase/firebase-tools/issues and attach the *-debug.log files. . ブラウザでアクセスする 今回は、エミュレータが localhost:8080 でホストするよう設定したので、ブラウザで localhost:8080 にアクセスする | 以下のように表示されれば成功 | . | . エミュレータを終了する Ctrl + Cで終了します | . | i emulators: Received SIGINT (Ctrl-C) for the first time. Starting a clean shutdown. i emulators: Please wait for a clean shutdown or send the SIGINT (Ctrl-C) signal again to stop right now. i emulators: Shutting down emulators. i hosting: Stopping Hosting Emulator i hub: Stopping emulator hub i logging: Stopping Logging Emulator . &#12487;&#12503;&#12525;&#12452;&#12377;&#12427; . firebase deployコマンドでデプロイを行う | % firebase deploy === Deploying to &#39;test-be918&#39;... i deploying hosting i hosting[test-be918]: beginning deploy... i hosting[test-be918]: found 2 files in public ✔ hosting[test-be918]: file upload complete i hosting[test-be918]: finalizing version... ✔ hosting[test-be918]: version finalized i hosting[test-be918]: releasing new version... ✔ hosting[test-be918]: release complete ✔ Deploy complete! Project Console: https://console.firebase.google.com/project/test-be918/overview Hosting URL: https://test-be918.web.app . Hosting URL にデプロイされたURLが表示されるので、ブラウザでそのURLにアクセスする 以下のように表示されれば成功 | . | .",
            "url": "https://taka4ma.github.io/fastpages/firebase/2022/04/28/firebase-memo.html",
            "relUrl": "/firebase/2022/04/28/firebase-memo.html",
            "date": " • Apr 28, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Colabで始めるPythonテキスト処理",
            "content": "&#21021;&#12417;&#12395; . このページを、taka4ma.github.io/fastpagesで見ている場合、タイトルの下に表示されている[Open in Colab]アイコンをクリックすると、Cloabで開くことができます。 . システム開発・運用の現場ではテキストを処理して別のテキストを作る仕事が多くあります。 . このNotebookでは、ColabでPythonを実行することによってテキスト処理を行う際の基礎的な情報を提供します。 . なお、Pythonにおけるフロー制御(if文、for文など)やデータ構造(リスト型、辞書型など)は説明しません。それらの情報は、python.orgのPython チュートリアル — Python 3.10.4 ドキュメントを参照することを推奨します。(リンク先は3.10.4のものですが、使用するPythonのバージョンに対応したものを参照してください。)また、正規表現も扱いません。このNotebookでは正規表現を使用せずに実現できる簡単なテキスト処理を扱います。 . Colab(Google Colaboratory)&#12392;&#12399; . Colaboratory へようこそ - Colaboratory　を参照してください。 . Jupyter Notebook&#12392;&#12398;&#38306;&#20418; . Colabは、Colabがホストする Jupyter Notebook(.ipynb)の実行環境です。 Colabで作成したNotebookをJupyterで実行したり、Jupyterで作成したNotebookをColabで実行したりできます。 . Jupyterプロジェクトについては、Project Jupyter | Homeを参照してください。 . Colab&#12398;&#20351;&#12356;&#26041; . Overview of Colaboratory Features - Colaboratory を参照してください。 . &#22793;&#25968;&#12434;&#30906;&#35469;&#12377;&#12427;&#24190;&#12388;&#12363;&#12398;&#26041;&#27861; . Colabはインタラクティブな実行環境なので、コードセルを実行するたびにその結果を確認しながら進めるのが確実です。このセクションでは変数の中身を確認するいくつかの方法を説明します。 . &#22793;&#25968;&#12434;&#20516;&#35413;&#20385;&#12377;&#12427; . 変数を評価すると、文字列に変換してコードセルのアウトプットに書き出されます。 . s = &#39;foo&#39; s . &#39;foo&#39; . ただし、この方法では、最後に評価した結果のみ出力されます。 . s1 = &#39;foo&#39; s2 = &#39;bar&#39; s1 s2 . &#39;bar&#39; . また、改行コードを含む文字列では改行コードを文字として出力します。 . s = &quot;foo nbar&quot; s . &#39;foo nbar&#39; . Noneである場合は出力されません。 . s = None s . listを評価すると次のように出力されます。 . l = [&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;] l . [&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;] . print&#38306;&#25968;&#12434;&#20351;&#12358; . print関数を使っても、コードセルのアウトプットに書き出すことができます。 . s = &#39;foo&#39; print(s) . foo . この方法では、print関数を実行するたびにアウトプットに書き出されます。 . s1 = &#39;foo&#39; s2 = &#39;bar&#39; print(s1) print(s2) . foo bar . また、改行コードを含む文字列では改行コードを改行として出力します。 . s = &quot;foo nbar&quot; print(s) . foo bar . また、Noneである場合はNoneという文字列として出力されます。 . s = None print(s) . None . listを書き出す場合、ただprint関数に与えると次のようになります。 . l = [&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;] print(l) . [&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;] . str.joinを利用すると次のように、１要素を１行として書き出すことができます。 . l = [&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;] print(&#39; n&#39;.join(l)) . abs() aiter() all() any() anext() ascii() . pandas.Dataframe&#12434;&#20351;&#12358; . listのインデックスも表示したいのであれば、enumerate関数を利用するのが典型的な方法ですが、 . for i, x in enumerate([&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;]): print(i,x) . 0 abs() 1 aiter() 2 all() 3 any() 4 anext() 5 ascii() . pandas.DataFrameを使って書き出すと簡単です。 . import pandas pandas.DataFrame([&#39;abs()&#39;, &#39;aiter()&#39;, &#39;all()&#39;, &#39;any()&#39;, &#39;anext()&#39;, &#39;ascii()&#39;]) . 0 . 0 abs() | . 1 aiter() | . 2 all() | . 3 any() | . 4 anext() | . 5 ascii() | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; listの要素に改行コードを含む場合、print関数を使用すると次にようになってしまいますが、 . for i, x in enumerate([&#39;ab ns()&#39;, &#39;ai nter()&#39;]): print(i,x) . 0 ab s() 1 ai ter() . pandas.DataFrameであれば改行コードを文字列として書き出します。 . import pandas pandas.DataFrame([&#39;ab ns()&#39;, &#39;ai nter()&#39;]) . 0 . 0 ab ns() | . 1 ai nter() | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; pandas.DataFrameは次のように、dictionaryを要素とするlistを表として書き出すことができます。 . import pandas pandas.DataFrame( [ {&#39;col1&#39;: &#39;row1-1&#39;, &#39;col2&#39;: &#39;row1-2&#39;}, {&#39;col1&#39;: &#39;row2-1&#39;, &#39;col2&#39;: &#39;row2-2&#39;}, ] ) . col1 col2 . 0 row1-1 | row1-2 | . 1 row2-1 | row2-2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; &#12486;&#12461;&#12473;&#12488;&#12434;&#35501;&#12415;&#36796;&#12416;&#12356;&#12367;&#12388;&#12363;&#12398;&#26041;&#27861; . Colabでテキストを処理するためには、処理するテキストを読み込まなければなりません。このセクションでは、そのいくつかの方法について説明します。 . &#12486;&#12461;&#12473;&#12488;&#12434;&#12467;&#12540;&#12489;&#12395;&#22475;&#12417;&#36796;&#12416; . 通常のプログラムであれば、処理するテキストをコードに埋め込むのはナンセンスです。しかし、Colabはインタラクティブな実行環境なので、処理するテキストをコードとして書いてしまっても構わないでしょう。 . テキストを１行ずつ処理する場合、１行が１要素となっているリストとして扱うのが便利です。以下のように書きます。 . user_list = [ &#39;TAGUCHI Tetsuya&#39;, &#39;TAKATA Yoshinao&#39;, &#39;IWAMOTO Yoshiya&#39;, &#39;NONAKA Takeichi&#39;, &#39;TSUKAMOTO Hisami&#39; ] user_list . [&#39;TAGUCHI Tetsuya&#39;, &#39;TAKATA Yoshinao&#39;, &#39;IWAMOTO Yoshiya&#39;, &#39;NONAKA Takeichi&#39;, &#39;TSUKAMOTO Hisami&#39;] . 先述の方法は、各行をシングルクォートで囲み、カンマで区切る必要があるので、行数が増えると面倒です。その場合はヒアドキュメントとして記述し、行ごとに分割することもできます。 . user_list = &#39;&#39;&#39;TAGUCHI Tetsuya TAKATA Yoshinao IWAMOTO Yoshiya NONAKA Takeichi TSUKAMOTO Hisami &#39;&#39;&#39;.splitlines() user_list . [&#39;TAGUCHI Tetsuya&#39;, &#39;TAKATA Yoshinao&#39;, &#39;IWAMOTO Yoshiya&#39;, &#39;NONAKA Takeichi&#39;, &#39;TSUKAMOTO Hisami&#39;] . &#12501;&#12449;&#12452;&#12523;&#12434;&#35501;&#12415;&#36796;&#12416; . 処理するテキストが他のシステムからファイルとして提供されている場合など、コードに埋め込むよりも直接ファイルを読み込んだ方が良い場合もあるので、併せて説明します。 . &#12469;&#12531;&#12503;&#12523;&#12501;&#12449;&#12452;&#12523;&#12434;&#29992;&#24847;&#12377;&#12427; . ファイルを読み込むコードを例示するためには、Colabのランタイム上に読み込むファイルを用意する必要があります。 . 以下のコードを実行すると、カレントディレクトリにuser.txtファイルが作成されます。 . %%writefile user.txt TAGUCHI Tetsuya TAKATA Yoshinao IWAMOTO Yoshiya NONAKA Takeichi TSUKAMOTO Hisami . Overwriting user.txt . Python&#12398;file object&#12434;&#20351;&#12387;&#12390;&#35501;&#12415;&#36796;&#12416; . 用意したサンプルファイルをPythonのopen関数にファイルパスを渡すことで、開きます。開いたファイルはfile objectとして扱われます。また、with文でラップしておくと、file bcjectはwith文ブロックを抜ける際に閉じられます。 . これはPythonでファイルを読み込むときの典型的な方法です。 . with open(&#39;user.txt&#39;) as f: lines = f.read() lines . &#39;TAGUCHI Tetsuya nTAKATA Yoshinao nIWAMOTO Yoshiya nNONAKA Takeichi nTSUKAMOTO Hisami&#39; . file objectのreadメソッドでファイルを読み込むと、ファイルの内容が1つの文字列になるので、splitlinesメソッドで行ごとに分割すると、あとで処理するときに便利です。 . user_list = lines.splitlines() user_list . [&#39;TAGUCHI Tetsuya&#39;, &#39;TAKATA Yoshinao&#39;, &#39;IWAMOTO Yoshiya&#39;, &#39;NONAKA Takeichi&#39;, &#39;TSUKAMOTO Hisami&#39;] . file objectのreadlinesメソッドで読み込むと、１行1要素のリストになりますが、末尾に改行文字を含みます。 . with open(&#39;user.txt&#39;) as f: user_list = f.readlines() user_list . [&#39;TAGUCHI Tetsuya n&#39;, &#39;TAKATA Yoshinao n&#39;, &#39;IWAMOTO Yoshiya n&#39;, &#39;NONAKA Takeichi n&#39;, &#39;TSUKAMOTO Hisami&#39;] . listにfile objectを与えても同様です。 . with open(&#39;user.txt&#39;) as f: user_list = list(f) user_list . [&#39;TAGUCHI Tetsuya n&#39;, &#39;TAKATA Yoshinao n&#39;, &#39;IWAMOTO Yoshiya n&#39;, &#39;NONAKA Takeichi n&#39;, &#39;TSUKAMOTO Hisami&#39;] . &#12510;&#12472;&#12483;&#12463;&#12467;&#12510;&#12531;&#12489;&#12434;&#20351;&#12387;&#12390;&#35501;&#12415;&#36796;&#12416; . %sxマジックの簡略化記法である!を使ってシステムコマンド(この場合はcat)を実行しその結果を変数に受け取る方法でも、ファイルを読み込むことができます。なお、%sxマジック(とその簡略化記法!)は、実行結果を改行文字で分割したリストとして返します。 . user_list = !cat user.txt user_list . [&#39;TAGUCHI Tetsuya&#39;, &#39;TAKATA Yoshinao&#39;, &#39;IWAMOTO Yoshiya&#39;, &#39;NONAKA Takeichi&#39;, &#39;TSUKAMOTO Hisami&#39;] . Colabでファイルを読み込む場合は、!からcatコマンドを実行する方が、file objectを使用するよりも簡単に書くことができます。 . GoogleDrive&#12395;&#12354;&#12427;&#12501;&#12449;&#12452;&#12523;&#12434;&#35501;&#12415;&#36796;&#12416;&#26041;&#27861; . Colabでファイルを読み込む場合は、ファイルをGoogleDrive上に置き、ColabのランタイムにGoogleDriveをマウントすることで、読み込めるようにします。 . ColabのランタイムにGoogleDriveをマウントするには、以下のコードを実行し、表示されるウィンドウの指示に従って操作します。 . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . コードを実行すると、Colabランタイムの/content/driveにGoogleDriveがマウントされるので、あとは先述の方法でファイルを読み込むことができます。ファイルのパスは、次のように!を使ってlsなどのコマンドを実行し、探すのが良いでしょう。 . !ls /content/drive/ . MyDrive . CSV&#12501;&#12449;&#12452;&#12523;&#12434;&#35501;&#12415;&#36796;&#12416;&#22580;&#21512; . CSVファイルを読み込む場合は、先述のfile objectを使って読み込む方法でもマジックコマンドを使って読み込む場合でも、csvモジュールを用いてパースを行うべきです。読み込んだ各行を,(カンマ)で分割してはいけません。以下にその理由を示します。 . &#12469;&#12531;&#12503;&#12523;&#12501;&#12449;&#12452;&#12523;&#12434;&#29992;&#24847;&#12377;&#12427; . サンプルコードを例示するためには、Colabのランタイム上に読み込むファイルを用意する必要があります。 . 次に、以下のコードを実行します。実行すると、カレントディレクトリにuser.csvファイルが作成されます。 . %%writefile user.csv family name,personal name &quot;TAGU,CHI&quot;,Tetsuya &quot;TA&quot;&quot;KATA&quot;,Yoshinao . Writing user.csv . 上のcsvファイルの内容は、Excelで作成したものです。 . 2行目の第１列には,(カンマ)が含まれています。この場合は、１列目の文字列が&quot;(ダブルクォート)で括られます。 また、３行目の第１列には&quot;が含まれています。この場合は、１列目の文字列が&quot;で括られた上で、エスケープ文字として&quot;が挿入されています。 . この２行目を,で分割すると次のようになります。 . with open(&#39;user.csv&#39;) as f: lines = f.read().splitlines() lines[1].split(&#39;,&#39;) . [&#39;&#34;TAGU&#39;, &#39;CHI&#34;&#39;, &#39;Tetsuya&#39;] . このように、読み込んだ各行を単純に,で分割することはできないのです。 . file object&#12391;&#35501;&#12415;&#36796;&#12435;&#12391;csv&#12514;&#12472;&#12517;&#12540;&#12523;&#12391;&#12497;&#12540;&#12473;&#12377;&#12427; . 以下にfile bojectを使ってファイルを読み込み、csvモジュールでパースするコードを例示します。csvファイルの1行目に列名が記載されている場合、DictReaderを使うと列名をKeyとするdictにパースされます。 . import csv with open(&#39;user.csv&#39;, newline=&#39;&#39;) as csvfile: user_list = list(csv.DictReader(csvfile)) user_list . [OrderedDict([(&#39;family name&#39;, &#39;TAGU,CHI&#39;), (&#39;personal name&#39;, &#39;Tetsuya&#39;)]), OrderedDict([(&#39;family name&#39;, &#39;TA&#34;KATA&#39;), (&#39;personal name&#39;, &#39;Yoshinao&#39;)])] . DictReaderを使ってdictにパースにしたので、次のコードのように、csvファイルの列名で要素にアクセスできます。 . import pandas pandas.DataFrame(user_list) . family name personal name . 0 TAGU,CHI | Tetsuya | . 1 TA&quot;KATA | Yoshinao | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; print(user_list[0][&#39;family name&#39;])print(user_list[0][&#39;personal name&#39;]) . TAGU,CHI Tetsuya . &#12510;&#12472;&#12483;&#12463;&#12467;&#12510;&#12531;&#12489;&#12434;&#20351;&#12387;&#12390;&#12501;&#12449;&#12452;&#12523;&#12434;&#35501;&#12415;&#36796;&#12435;&#12391;csv&#12514;&#12472;&#12517;&#12540;&#12523;&#12391;&#12497;&#12540;&#12473;&#12377;&#12427; . !を使ってcatを実行しその結果を受けた変数をcsvモジュールでパースするコードを例示します。 . import csv l = !cat user.csv user_list = list(csv.DictReader(l)) user_list . [OrderedDict([(&#39;family name&#39;, &#39;TAGU,CHI&#39;), (&#39;personal name&#39;, &#39;Tetsuya&#39;)]), OrderedDict([(&#39;family name&#39;, &#39;TA&#34;KATA&#39;), (&#39;personal name&#39;, &#39;Yoshinao&#39;)])] . file objectを用いた例ではcsv.DictReaderの引数にfile objcectを渡していましたが、DictReaderはリストを受け取ることも可能なので、!でcatを実行した結果のリストを渡しています。 . &#12486;&#12461;&#12473;&#12488;&#12434;&#20986;&#21147;&#12377;&#12427;&#12356;&#12367;&#12388;&#12363;&#12398;&#26041;&#27861; . Colabでテキストを処理したら、その結果を出力しなければなりません。このセクションでは、そのいくつかの方法について説明します。 . &#12450;&#12454;&#12488;&#12503;&#12483;&#12488;&#12475;&#12523;&#12395;&#20986;&#21147;&#12377;&#12427; . 最も単純な方法は、コードセルのアウトプットに書き出し、それをマウスで選択してコピーする方法でしょう。 . user_list = [ &#39;useradd taguchi&#39;, &#39;useradd tanaka&#39;, &#39;useradd iwamoto&#39;, &#39;useradd nonaka&#39;, &#39;useradd tsukamoto&#39; ] for user in user_list: print(user) . useradd taguchi useradd tanaka useradd iwamoto useradd nonaka useradd tsukamoto . Python&#12398;file object&#12434;&#20351;&#12387;&#12390;&#12501;&#12449;&#12452;&#12523;&#12395;&#26360;&#12365;&#20986;&#12377; . ファイルを書き出すときには、ファイルを読み込むときと同じように、open関数を使います。ただし、mode引数によってファイルを開く際のモードを指定しなければなりません。 mode引数を指定しなかった場合、mode引数のデフォルトはrでこれは、読み取りを表します。wは書き込みですが、ファイルが存在する場合現在の内容を全て捨てます、xも書き込みですが、ファイルが存在する場合は失敗します。aも同じく書き込みですが、ファイルが存在する場合は末尾に追記します。 . with文でラップしておくと、file bcjectはwith文ブロックを抜ける際に閉じられます。ファイルを書き込む際にfile objectを閉じ忘れた場合、ファイルがディスクに書き込まれないことがあるので、with文でラップしておくのが安全です。with文でラップできない場合はfile objectのclose()メソッドを忘れずに実行します。 . これはPythonでファイルを読み込むときの典型的な方法です。 . user_list = [ &#39;useradd taguchi&#39;, &#39;useradd tanaka&#39;, &#39;useradd iwamoto&#39;, &#39;useradd nonaka&#39;, &#39;useradd tsukamoto&#39; ] with open(&#39;add_user.txt&#39;, mode=&#39;w&#39;) as f: for user in user_list: f.write(user) . writeメソッドは受け取った文字列をそのままファイルに書き込みます。そのため、書き込んだファイルは次のようになります。 . !cat add_user.txt . useradd taguchiuseradd tanakauseradd iwamotouseradd nonakauseradd tsukamoto . このため、改行が必要な場合は改行コードも書き出す必要があります。 . user_list = [ &#39;useradd taguchi&#39;, &#39;useradd tanaka&#39;, &#39;useradd iwamoto&#39;, &#39;useradd nonaka&#39;, &#39;useradd tsukamoto&#39; ] with open(&#39;add_user.txt&#39;, mode=&#39;w&#39;) as f: for user in user_list: f.write(user) f.write(&quot; n&quot;) !cat add_user.txt . useradd taguchi useradd tanaka useradd iwamoto useradd nonaka useradd tsukamoto . また、writelinesメソッドにリストを渡すことで、リストをまとめて書き出すことができます。 . user_list = [ &#39;useradd taguchi&#39;, &#39;useradd tanaka&#39;, &#39;useradd iwamoto&#39;, &#39;useradd nonaka&#39;, &#39;useradd tsukamoto&#39; ] with open(&#39;add_user.txt&#39;, mode=&#39;w&#39;) as f: f.writelines(user_list) . この場合も、改行コードは追加されません。 . !cat add_user.txt . useradd taguchiuseradd tanakauseradd iwamotouseradd nonakauseradd tsukamoto . このため、リスト内の文字列に改行コードを含ませておく必要があります。 . user_list = [ &#39;useradd taguchi n&#39;, &#39;useradd tanaka n&#39;, &#39;useradd iwamoto n&#39;, &#39;useradd nonaka n&#39;, &#39;useradd tsukamoto n&#39; ] with open(&#39;add_user.txt&#39;, mode=&#39;w&#39;) as f: f.writelines(user_list) !cat add_user.txt . useradd taguchi useradd tanaka useradd iwamoto useradd nonaka useradd tsukamoto . writefile&#12510;&#12472;&#12483;&#12463;&#12434;&#20351;&#12387;&#12390;&#12501;&#12449;&#12452;&#12523;&#12434;&#26360;&#12365;&#20986;&#12377;...&#12383;&#12384;&#12375;...... . %%writefileマジックコマンドを使うと、セルの内容をファイルへ書き出すことができます。ただし、このマジックコマンドはセルの内容をそのままファイルへ書き出すもので、変数を展開することができません。 . 変数str1を定義して . str1 = &#39;foo&#39; . %%writefileマジックでstr1.txtに書き出す . %%writefile str1.txt str1 . Overwriting str1.txt . そのファイルをcatすると . !cat str1.txt . str1 . 変数の内容ではなく、&quot;str1&quot;という文字列として出力されている。 . &#25991;&#23383;&#21015;&#22411;&#12398;&#22522;&#30990; . このセクションでは文字列型の基礎について説明します . &#25991;&#23383;&#21015;&#12398;&#35352;&#36848; . Pythonで文字列を記述するには、&#39;...&#39;シングルクォート、&quot;...&quot;ダブルクォート、または&#39;&#39;&#39;...&#39;&#39;&#39;トリプルクォート(3つのシングルクォート)で囲みます。&quot;&quot;&quot;...&quot;&quot;&quot;(3つのダブルクォート)で囲んだ場合は3つのシングルクォートで囲む場合と同じになります。 . &#39;&quot;ダブル&quot;クォートを埋め込むことができます&#39; . &#39;&#34;ダブル&#34;クォートを埋め込むことができます&#39; . &quot;&#39;シングル&#39;クォートを埋め込むことができます&quot; . &#34;&#39;シングル&#39;クォートを埋め込むことができます&#34; . &#39;&#39;&#39;改行を 埋め込むことができます。&#39;&#39;&#39; . &#39;改行を n埋め込むことができます。&#39; . 特殊文字は (バックスラッシュ)で始まり、シングルクォートで囲んだ場合でも特殊文字として扱われます。(シングルクォートで囲んだ場合は特殊文字として使わないプログラミング言語もありますが、Pythonは特殊文字として扱います。) . print(&#39;Hello nWorld!&#39;) . Hello World! . print(&quot;Hello nWorld!&quot;) . Hello World! . (バックスラッシュ)とそれに続く文字を特殊文字として解釈されたくない場合はクォートの前にrをつけてrwa stringsにします。 . print(r&quot;Hello nWorld!!&quot;) . Hello nWorld!! . Python3.6から導入されたf-stringを使うと、文字列に変数を指定することができます。 . クォートの前にfをつけるとf-stringになり、クォートに囲まれた文字列の中に{}で囲って変数を指定します。 . s = &#39;Hello&#39; f&#39;{s} World!&#39; . &#39;Hello World!&#39; . &#25991;&#23383;&#21015;&#12398;&#36899;&#32080; . 文字列は+演算子で連結することができます。 . s1 = &#39;Hello&#39; s2 = &#39;World!&#39; s3 = s1 + &#39; &#39; + s2 print(s3) . Hello World! . 先述のf-stringを応用して文字列を連結することもできます。 . s1 = &#39;Hello&#39; s2 = &#39;World!&#39; s3 = f&#39;{s1} {s2}&#39; print(s3) . Hello World! . また、文字列のjoinメソッドにリストを渡すと、リストの各要素を文字列で連結することができます。 . s1 = &#39;Hello&#39; s2 = &#39;World!&#39; s3 = &#39; | &#39;.join([s1, s2, s1, s2]) print(s3) . Hello | World! | Hello | World! . &#25991;&#23383;&#21015;&#12363;&#12425;&#12452;&#12531;&#12487;&#12483;&#12463;&#12473;&#12434;&#25351;&#23450;&#12375;&#12390;&#25991;&#23383;&#12434;&#21462;&#12426;&#20986;&#12377; . Pythonの文字列はindex(添字)を指定して、文字を取り出すことができます。最初の文字のインデックスは0です。 . サンプルコードで使用する文字列を変数sとして定義しておきます。 . s = r&#39;Hello World!&#39; print(s) . Hello World! . indexを指定すると、その位置の文字を取り出すことができます。 . for i in range(len(s)): print(f&#39;{i} : &#39;, s[i]) . 0 : H 1 : e 2 : l 3 : l 4 : o 5 : 6 : W 7 : o 8 : r 9 : l 10 : d 11 : ! . インデックスに負の数を指定すると文字列の後ろから数えて、その位置の文字を取り出します。 . for i in range(-1, -(len(s)) - 1, -1): print(f&#39;{i} : &#39;, s[i]) . -1 : ! -2 : d -3 : l -4 : r -5 : o -6 : W -7 : -8 : o -9 : l -10 : l -11 : e -12 : H . &#25991;&#23383;&#21015;&#12398;&#12473;&#12521;&#12452;&#12473; . Pythonの文字列はスライスをサポートしています。スライスを使うと文字列の一部分を取り出すことができます。 . サンプルコードで使用する文字列を変数sとして定義し、indexとその位置の文字を表示しておきます。 . s = r&#39;Hello World!&#39; for i in range(len(s)): print(f&#39;{i} ({-len(s)+i}): &#39;, s[i]) . 0 (-12): H 1 (-11): e 2 (-10): l 3 (-9): l 4 (-8): o 5 (-7): 6 (-6): W 7 (-5): o 8 (-4): r 9 (-3): l 10 (-2): d 11 (-1): ! . スライスは文字列[index:index]と記述し、1つ目に指定したindexの文字から、2つ目に指定したindexの1つ前の文字を取り出します。 . print(s[1:5]) . ello . 1つ目のindexを省略すると0と見做されます。 . print(s[:5]) . Hello . 2つ目のindexを省略すると文字列の末尾までを取得します。 . print(s[6:]) . World! . 2つ目のindexに1つ目のindexより小さな値を指定すると文字列を取り出せませんが、エラーにもならないので注意が必要です。 . print(s[5:1]) . . &#25991;&#23383;&#21015;&#12398;&#27604;&#36611; . ==&#12392;!= . 2つの文字列を比較する場合、同じ文字列であれば==演算子でTrueになり、異なる文字列であれば!=でTrueになります。 . &#39;Hello&#39; == &#39;Hello&#39; . True . &#39;Hello&#39; != &#39;World&#39; . True . 大文字と小文字は別の文字として扱われます。 . &#39;H&#39; == &#39;h&#39; . False . スライスと組み合わせることで、ある文字列の特定の位置から抜き出した文字列を別の文字列と比較することができます。 . s = r&#39;Hello World!&#39; print(s[:5]) print(s[:5] == &#39;Hello&#39;) . Hello True . startswith&#12392;endswith . 文字列がある文字列で始まるかを判定する場合はstartswith、ある文字列で終わるかを判定する場合はendswithメソッドを使うことができます。どちらのメソッドも間にsが入るので注意してください。(startwithではなくstartswith) . &#39;Hello World!&#39;.startswith(&#39;Hello&#39;) . True . &#39;Hello World!&#39;.endswith(&#39;World!&#39;) . True . in&#12392;not in . in演算子を使うと、ある文字列に別の文字列が含まれているかを判定することができます。含まれていないかを判定する場合はnot演算子を加えてnot inにします . &#39;Hello&#39; in &#39;Hello World!&#39; . True . &#39;Python&#39; not in &#39;Hello World!&#39; . True . &#25991;&#23383;&#21015;&#25805;&#20316; . &#25991;&#23383;&#21015;&#12434;&#20840;&#12390;&#22823;&#25991;&#23383;&#12395;&#22793;&#25563;&#12377;&#12427; . 文字列を全て大文字に変換するときは、upperメソッドを使います。 . s1 = &#39;Hello World!&#39; s2 = s1.upper() print(s2) . HELLO WORLD! . また、大文字小文字関係なく文字列を比較したい場合はupperメソッドを応用することで比較できます。 . print(&#39;HELLO&#39; == &#39;Hello&#39;.upper()) print(&#39;HELLO&#39; == &#39;HELLO&#39;.upper()) print(&#39;HELLO&#39; == &#39;hello&#39;.upper()) . True True . &#25991;&#23383;&#21015;&#12434;&#20840;&#12390;&#23567;&#25991;&#23383;&#12395;&#22793;&#25563;&#12377;&#12427; . 文字列を全て小文字に変換するときは、lowerメソッドを使います。 . s1 = &#39;Hello World!&#39; s2 = s1.lower() print(s2) . hello world! . upperメソッドの代わりにlowerメソッドを用いても、大文字小文字関係なく文字列を比較することができます。 . print(&#39;hello&#39; == &#39;Hello&#39;.lower()) print(&#39;hello&#39; == &#39;HELLO&#39;.lower()) print(&#39;hello&#39; == &#39;hello&#39;.lower()) . True True True . &#25991;&#23383;&#21015;&#12434;&#20998;&#21106;&#12377;&#12427; . 文字列を分割する場合はsplitメソッドを使用します。splitメソッドの引数に分割する文字列を与えると、その文字列で分割したリストを返します。 . s1 = &#39;My_Name_is_Python&#39; s1.split(&#39;_&#39;) . [&#39;My&#39;, &#39;Name&#39;, &#39;is&#39;, &#39;Python&#39;] . 引数を与えなかった場合はスペースで分割されます。 . s1 = &#39;My Name is Python&#39; s1.split() . [&#39;My&#39;, &#39;Name&#39;, &#39;is&#39;, &#39;Python&#39;] . &#25991;&#23383;&#21015;&#12363;&#12425;&#31354;&#30333;&#12434;&#21462;&#12426;&#38500;&#12367; . 文字列の両端から空白を取り除く場合はstripメソッド、先頭から取り除く場合はlstripメソッド、末尾から取り除く場合はrstripメソッドを使います。 . s1 = &#39; Hello World!! &#39; print(f&#39;|{s1}|&#39;) print(f&#39;|{s1.strip()}|&#39;) print(f&#39;|{s1.lstrip()}|&#39;) print(f&#39;|{s1.rstrip()}|&#39;) . | Hello World!! | |Hello World!!| |Hello World!! | | Hello World!!| . &#25991;&#23383;&#21015;&#12363;&#12425;&#29305;&#23450;&#12398;&#25991;&#23383;&#21015;&#12434;&#21462;&#12426;&#38500;&#12367; . 文字列の中から特定の文字列を取り除きたい場合は、splitメソッドを使って取り除きたい文字列で分割したリストを作り、それを&#39;&#39;(空文字)のjoinメソッドに与えることで実現できます。 . 文字列から、スペースを取り除きたい場合は以下のようにします。 . s1 = &#39;My Name is Python&#39; l = s1.split() print(l) s2 = &#39;&#39;.join(s1.split()) print(s2) . [&#39;My&#39;, &#39;Name&#39;, &#39;is&#39;, &#39;Python&#39;] MyNameisPython .",
            "url": "https://taka4ma.github.io/fastpages/jupyter/python/2022/04/22/Python-Text-Processing-Starting-with-Colab.html",
            "relUrl": "/jupyter/python/2022/04/22/Python-Text-Processing-Starting-with-Colab.html",
            "date": " • Apr 22, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Ubuntu20.04LTSにJupyterHubをインストールする方法",
            "content": "&#32972;&#26223; . かつて、Ubuntu14.04LTSへJupyterNotebookをインストールする方法として、Ubuntu Serverへのjupyter notebookインストール手順 | taka4ma.github.io を公開しました。当時の(現在からすると古典的な)JupyterNotebookは複数のユーザーに対応していなかったため、ユーザーごとにOSとその上で動作するJupyterNotebook環境を用意する必要がありました。 . 現在では、複数のユーザにJupyterNotebookを提供するための機能として、JupyterHubが提供されているため、この記事ではそのディストリビューションの一つである The Littlest JupyterHub を用いて、Amazon EC2インスタンスのUbuntu20.04LTSにJupyterHubをインストールする手順を紹介します。 . &#21069;&#25552;&#26465;&#20214; . EC2インスタンスは作成済みのこと | セキュリティグループのインバウンドルールに以下を追加しておくこと | . Type Protocol Port Range . SSH | TCP | 22 | . HTTP | TCP | 80 | . HTTPS | TCP. | 443 | . なお、この手順は以下の環境で動作確認しています。 . リージョン: 東京 | AMI: Ubuntu Server 20.04 LTS (HVM), SSD Volume Type - ami-088da9557aae42f39 (64 ビット x86) | インスタンスタイプ: t2.micro | . &#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#25163;&#38918; . EC2&#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12408;&#12398;ssh&#12450;&#12463;&#12475;&#12473; . EC2インスタンスにはsshでアクセスします。 . $ ssh -i &lt;ssh-key-path&gt; ubuntu@&lt;public-ip&gt; . &#12497;&#12483;&#12465;&#12540;&#12472;&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#12377;&#12427; . python3, python3-dev, git, curlをインストールする . $ sudo apt update $ sudo apt install -y python3 python3-dev git curl . Littlest JupyterHub&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#12377;&#12427; . 次のコマンドを実行して、Littlest jupyterHubをインストールします。 . このとき、&lt;admin-user-name&gt;をJupyterHubに作成する管理者のユーザ名に置換します。 . $ curl -L https://tljh.jupyter.org/bootstrap.py | sudo -E python3 - --admin &lt;admin-user-name&gt; . コマンドを実行すると10分程度でインストールが完了します。 . インストールが完了すると、&quot;Done!&quot;と表示されます。 . &#12502;&#12521;&#12454;&#12470;&#12391;JupyterHub&#12395;&#12450;&#12463;&#12475;&#12473;&#12377;&#12427; . ブラウザからhttp://&lt;public-ip&gt;にアクセスします。ネットワークが正しく設定され、インストールに成功していれば、以下のような、JupyterHubのログインページが表示されるはずです。 . . &#12525;&#12464;&#12452;&#12531;&#12377;&#12427; . Usernameに、Littlest jupyterHubをインストールした際に、--adminオプションで設定した管理者のユーザ名を入力します。 | Passwordには、管理者アカウントに設定するパスワードを入力します。 アカウントのパスワードは、初回ログイン時にユーザ自身が設定します。設定が行われるまでの間、アカウントはパスワードによる保護がない状態なので、注意しなければなりません。 | . | . ログインに成功すると、以下のようなWeb UIが表示されます。 . . なお、初回のログインに成功した時点で、OSにユーザが作成され、/homeにユーザのホームディレクトリが作成されます。 . // 以下はadminをjupyter-hubadminにした場合の例 . $ ls -l /home/ total 8 drwxr-x 5 jupyter-hubadmin jupyter-hubadmin 4096 Mar 29 15:09 jupyter-hubadmin drwxr-xr-x 5 ubuntu ubuntu 4096 Mar 29 14:45 ubuntu . また、jupyterhub上で作成したファイルは、ホームディレクトリに保存されます。 . . // 上に示した画像のようにTest.ipynbファイルを作成すると、下に示すようにホームディレクトリに保存される。 . $ sudo ls -l /home/jupyter-hubadmin/ total 4 -rw-r--r-- 1 jupyter-hubadmin jupyter-hubadmin 588 Mar 29 15:11 Test.ipynb . 以上で、JupyterHubのインストールは完了です。 . &#12497;&#12473;&#12527;&#12540;&#12489;&#12434;&#22793;&#26356;&#12377;&#12427;&#24517;&#35201;&#12364;&#12354;&#12427;&#22580;&#21512; . パスワードを変更する必要がある場合は、以下の操作を行います。 . ブラウザからJupyterhubへログインする | ログインした状態で &lt;server_ip&gt;/hub/auth/change-password にアクセスする | 次に示すパスワード変更画面が表示されるので、新しいパスワードを入力してChange Passwordをクリックする | . &#12518;&#12540;&#12470;&#12434;&#36861;&#21152;&#12377;&#12427; . 管理者ユーザ以外のユーザの追加は、JupyterHubのWeb UIから行います。 . JupyterHubの右上にあるControll Panelボタンをクリックして、コントロールパネルを表示します。 | コントロールパネルの左上にあるAdminリンクを開くと、管理画面が表示されます。 | 管理画面のAdd Usersボタンをクリックします | 表示されたAdd Usersアイアログに、追加するユーザのアカウント名を入力します このとき、1行につき1ユーザを入力でき、一度に複数のユーザを作成できます。 | adminにする場合はAdminチェックボックスにチェックを入れます。adminと一般ユーザは同時に作成できません。 | . | Add Usersボタンをクリックするとユーザーが追加されます。 | .",
            "url": "https://taka4ma.github.io/fastpages/jupyter/2022/03/29/How-to-install-JupyterHub-on-Ubuntu20.html",
            "relUrl": "/jupyter/2022/03/29/How-to-install-JupyterHub-on-Ubuntu20.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "fastpagesを使ってgithub.ioでNotebookを簡単に公開する方法",
            "content": "&#32972;&#26223; . Jupyter NotebookやGoogle ColaboratoryのNotebookファイルをGithub Pagesで公開する方法は、以下の2つが知られています。 . NotebookファイルをMarkdownファイルへエクスポートしてGithubリポジトリへPushする。(GitHub PagesにはリポジトリにPushされたMarkdownファイルにアクセスすると、HTMLとしてレンダリングする機能があるため。) | NotebookファイルをGitHub GistにPushし、リポジトリにはgistの埋め込みスクリプトを記述したMarkdownかHTMLをPushする。(GitHub GistにはNotebookファイルを埋め込みスクリプトで表示するとHTMLとしてレンダリングする機能があるため。) | しかし、最初の方法はNotebookを作成・更新するたびに手動でMarkdownにエクスポートしなければなりません。Jupyter Notebookには開いているNotebookファイルをMarkdownファイルにコンバートしてダウンロードする機能があるので、それを利用することができます。Google ColaboratoryにはMarkdownファイルにコンバートする機能がないため、別に用意する必要があります。いずれにしても、NotebookファイルとMarkdownファイルの両方を管理しなければならないため、管理が煩雑になってしまいます。 . また、2つ目の方法では公開するNotebookごとにgistを用意する必要があります。gistはそれ自体が1つのリポジトリなので、Notebookの数だけリポジトリを管理しなくてはならず、管理が煩雑になります。Google Colaboratoryには開いているNotebookファイルのコピーをGitHub Gistへ保存する機能がありますが、保存するたびに新しいgistとして保存されてしまうため、この機能を利用するならば、gistの埋め込みスクリプトを記述したファイルを都度更新しなくてはなりません。 . このように、現在知られている2つの方法は、どちらもファイルやリポジトリの管理に手間がかかってしまうため、より簡単な方法が必要でした。 . fastpages&#12392;&#12399; . fastai/fastpages: An easy to use blogging platform, with enhanced support for Jupyter Notebooks. にて公開されているソフトウェアです。使用するには公開されているリポジトリをCloneし、初期設定を行います。そしてそのリポジトリのmasterブランチへルールに従ってNotebookファイルをPushします。そうするとGithub Actionが実行されます。実行されたGithub Actionによりコンテナが起動し、リポジトリがコンテナ上にCloneされ、ファイルのコンバートが行われ、出来たファイルがリポジトリのgh-pagesブランチへPushされます。このリポジトリはgh-pagesブランチをGitHub Pagesのコンテンツとして公開するように設定されているので、コンバートされたファイルが公開されます。 . Initial settings . fastpagesのリポジトリ(https://github.com/fastai/fastpages) にブラウザでアクセスする. | Setup Instructionsに、Generate a copy of this repo by clicking on this link.と書かれているので、リンクをクリックする. | &quot;Create a new repository from fastpages&quot;というタイトルの、リポジトリ作成画面が表示されるので, ownerに任意のアカウントまたはOrganizationsを選択する. | Repository nameにGithubの自分のユーザー名以外の名前を設定する. | Public/PrivateはPublicを選ぶ。 | Include all branchesにチェックを入れない. (https://github.com/fastai/fastpages/issues/608) | Create repository from templateをクリックする. | | ブラウザに作成したリポジトリが表示される | fastpagesのテンプレートからリポジトリを作成すると、GitHub Actionsのワークフローが実行され、PRが作成されるので、リポジトリのActionsタブを開いて、ワークフローが実行されているか確認する. ワークフローが実行されていれば、All workflowsに実行されたワークフローが表示される. | もし、ワークフローが実行されていない場合は、リポジトリのSettings &gt; Actions &gt; General &gt; Actions permissionsで実行が許可されているか確認する. | . | Pull requestsタブを開いて, &quot;Inital Setup&quot; というPRを開く. | PRの&quot;Before you merge this PR&quot;セクションを順番に処理する &quot;Create an ssh key-pair. Open this utility. Select: RSA and 4096 and leave Passphrase blank. Click the blue button Generate-SSH-Keys.&quot; ブラウザでOnline Generate SSH keys algorithm RSA,DSA,ECDSAを開く | SSH-Keygen Online AlgorithmでRSAを選択する. | RSA Key Sizeで4096を選択する | Passphraseは入力しない | Generate-SSH-Keysをクリックする. そうすると、SSH鍵が作成され、表示される | ssh鍵は、ローカルマシンで、ssh-keygenコマンドで作成してもよい. | . | &quot;Navigate to this link and click New repository secret. Copy and paste the Private Key into the Value field. This includes the &quot;BEGIN RSA PRIVATE KEY&quot; and &quot;--END RSA PRIVATE KEY&quot; portions. In the Name field, name the secret SSH_DEPLOY_KEY.&quot; リポジトリの, Settings &gt; Secrets &gt; Actions を開き、New repository secretをクリックする. | NameにSSH_DEPLOY_KEYと入力. | Valueに生成した秘密鍵をペーストする. この時、&quot;BEGIN RSA PRIVATE KEY&quot; から &quot;--END RSA PRIVATE KEY&quot;までを含むこと. | Add secretをクリックして、登録する. | | &quot;Navigate to this link and click the Add deploy key button. Paste your Public Key from step 1 into the Key box. In the Title, name the key anything you want, for example fastpages-key. Finally, make sure you click the checkbox next to Allow write access (pictured below), and click Add key to save the key.&quot; リポジトリの, Settings &gt; Deploy keysを開き、Add deploy keyをクリックする. | タイトルに、fastpages-keyなど、好きな名前を付けます。 | 作成した公開鍵をKeyにペーストする. | Allow write accessのチェックボックスにチェックをつける. | Add keyをクリックしてキーを保存する. | | | &quot;Inital Setup&quot;PRのMerge pull requestをクリックし、コミットメッセージを入力するか、またはデフォルトのまま、Confirm mergeをクリックする。 PRをマージすると、GitHub Actionsのワークフローが実行され、リポジトリの内容が変更される、最初のデプロイが行われる。 | . | リポジトリのCodeタブを開く。 | README.mdが変更され、fastpagesによってデプロイされるコンテンツのトップのURLが記述されているので、そのURLをリンクで開く URLは通常、 https://ユーザ名.github.io/リポジトリ名 | 404の場合は、デプロイがまだ終わっていないので、数分待ってからリロードする | . | markdown&#12501;&#12449;&#12452;&#12523;&#12434;&#25237;&#31295;&#12377;&#12427; . YYYY-MM-DD-*.mdの命名規則に従って、投稿するmarkdownファイルのファイル名を変更します。 | /_post ディレクトリへプッシュしてください。 | Notebook&#12501;&#12449;&#12452;&#12523;&#12434;&#25237;&#31295;&#12377;&#12427; . YYYY-MM-DD-*.mdの命名規則に従って、投稿するnotebookファイルのファイル名を変更します。 | /_notebooks ディレクトリへプッシュしてください。 |",
            "url": "https://taka4ma.github.io/fastpages/fastpages/2022/03/06/How-to-easily-publish-a-Notebook-on-github-io-using-fastpages.html",
            "relUrl": "/fastpages/2022/03/06/How-to-easily-publish-a-Notebook-on-github-io-using-fastpages.html",
            "date": " • Mar 6, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "GoogleLolaboratoryからboto3を使ってEC2にインスタンスを起動するサンプルnotebook",
            "content": "&#12371;&#12398;notebook&#12399;...... . Amazon Web Services (AWS)のPython向けSDKであるBotoをGoogleColaboratoryから使用し、EC2にネットワークを構築し、そこへインスタンスを起動するサンプルです。 . 起動したインスタンスへはGoogleColaboratoryから ではなく PCからSSHでアクセスできるように設定します。 . Botoの詳細は、 公式ドキュメント を参照してください。特にEC2Clientについてはhttps://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html を参照してください。 . &#28310;&#20633; . AWS&#12450;&#12463;&#12475;&#12473;&#12461;&#12540;&#12434;&#20316;&#25104;&#12375;&#12390;&#12362;&#12367; . Botoを使用するには、事前にAWSのアクセスキーを用意する必要があります。 . アクセスキー管理方法は様々ありますが、AWS IAMのユーザー https://console.aws.amazon.com/iam/home?region=us-west-2#/users からNotebook用のユーザーを作成する方法があります。万が一アクセスキーが漏れた場合に備えて、権限を最小限に、いつでも無効化できるように設定する必要があります。 . boto&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#12377;&#12427; . Boto公式ドキュメントの Installation を参考に、GoogleColaboratoryのラインタイム環境へ、boto3をインストールします。 . !pip install boto3 . boto&#12398;&#12383;&#12417;&#12398;&#35469;&#35388;&#36039;&#26684;&#24773;&#22577;&#12434;&#29872;&#22659;&#22793;&#25968;&#12395;&#35373;&#23450;&#12377;&#12427; . Botoを使用するためには、認証資格情報をセットアップする必要があります。 このnotebookでは以下３つの環境変数を設定することにします。 . AWS_ACCESS_KEY_ID | AWS_SECRET_ACCESS_KEY | AWS_DEFAULT_REGION | AWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYには、AWSアクセスキーのアクセスキー IDとシークレットアクセスキーを設定します。 . AWS_DEFAULT_REGIONには使用するリージョンを設定します。このnotebookでは東京リージョン( ap-northeast-1 )を使用します。 . &#12450;&#12463;&#12475;&#12473;&#12461;&#12540;ID&#12434;&#35373;&#23450;&#12377;&#12427; . import os import getpass os.environ[&#39;AWS_ACCESS_KEY_ID&#39;] = getpass.getpass() . &#12471;&#12540;&#12463;&#12524;&#12483;&#12488;&#12450;&#12463;&#12475;&#12473;&#12461;&#12540;&#12434;&#35373;&#23450;&#12377;&#12427; . os.environ[&#39;AWS_SECRET_ACCESS_KEY&#39;] = getpass.getpass() . &#12487;&#12501;&#12457;&#12523;&#12488;&#12522;&#12540;&#12472;&#12519;&#12531;&#12434;&#35373;&#23450;&#12377;&#12427; . os.environ[&#39;AWS_DEFAULT_REGION&#39;] = &#39;ap-northeast-1&#39; . pandas&#12434;&#12452;&#12531;&#12509;&#12540;&#12488;&#12375;&#12390;&#12362;&#12367; . pandasを多用することになるので、インポートしておく . import pandas as pd . ec2&#12398;client&#12434;&#20316;&#12387;&#12390;&#12362;&#12367; . import boto3 ec2_client = boto3.client(&#39;ec2&#39;) . &#12493;&#12483;&#12488;&#12527;&#12540;&#12463;&#12434;&#27083;&#31689;&#12377;&#12427; . EC2インスタンスを起動するネットワークを構築します . &#26032;&#12375;&#12356;VPC&#12434;&#20316;&#12427; . &#29694;&#22312;&#12398;VPC&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . pd.DataFrame(ec2_client.describe_vpcs()[&#39;Vpcs&#39;]) . &#26032;&#12375;&#12356;VPC&#12434;&#20316;&#25104;&#12377;&#12427; . 今回は、10.0.0.0/16のCIDRブロックを持つVPCを作成する . result = ec2_client.create_vpc(CidrBlock = &#39;10.0.0.0/16&#39;,) . result . 作成したvpcの情報をNEW_VPCに入れておく . NEW_VPC = result[&#39;Vpc&#39;] NEW_VPC . VPC&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . 新しく作成したVPCも見えるはず . pd.DataFrame(ec2_client.describe_vpcs()[&#39;Vpcs&#39;]) . 見えた . &#12469;&#12502;&#12493;&#12483;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427; . 新しく作成したVPCにサブネットを作成する . &#29694;&#22312;&#12398;&#12469;&#12502;&#12493;&#12483;&#12488;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . subnets = ec2_client.describe_subnets()[&#39;Subnets&#39;] pd.DataFrame(subnets) . 新しく再生したVPCのサブネットは、 . list(filter(lambda x:x[&#39;VpcId&#39;] == NEW_VPC[&#39;VpcId&#39;], subnets)) . 当然、ない。 . &#26032;&#12375;&#12356;VPC&#12395;&#12469;&#12502;&#12493;&#12483;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427; . availability zoneはap=northeast-1a, CIDRブロックは10.0.0.0/24にする . result = ec2_client.create_subnet( AvailabilityZone = &#39;ap-northeast-1a&#39;, CidrBlock = &#39;10.0.0.0/24&#39;, VpcId = NEW_VPC[&#39;VpcId&#39;] ) result . NEW_SUBNET = result[&#39;Subnet&#39;] NEW_SUBNET . &#12469;&#12502;&#12493;&#12483;&#12488;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . 新しく作成したサブネットも見えるはず . subnets = ec2_client.describe_subnets()[&#39;Subnets&#39;] pd.DataFrame(subnets) . list(filter(lambda x:x[&#39;VpcId&#39;] == NEW_VPC[&#39;VpcId&#39;], subnets)) . &#12469;&#12502;&#12493;&#12483;&#12488;&#12395;&#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#36215;&#21205;&#26178;&#12395;&#12497;&#12502;&#12522;&#12483;&#12463;IP&#12434;&#20184;&#19982;&#12377;&#12427;&#35373;&#23450;&#12434;&#36861;&#21152;&#12377;&#12427; . response = ec2_client.modify_subnet_attribute( MapPublicIpOnLaunch={&#39;Value&#39;: True}, SubnetId=NEW_SUBNET[&#39;SubnetId&#39;] ) response . list(filter(lambda x:x[&#39;VpcId&#39;] == NEW_VPC[&#39;VpcId&#39;], ec2_client.describe_subnets()[&#39;Subnets&#39;])) . MapPublicIpOnLaunchの値がTrueになっている . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#20316;&#25104;&#12377;&#12427; . &#29694;&#22312;&#12398;&#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . internet_gateways = ec2_client.describe_internet_gateways()[&#39;InternetGateways&#39;] pd.DataFrame(internet_gateways) . &#26032;&#12375;&#12356;&#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#20316;&#25104;&#12377;&#12427; . result = ec2_client.create_internet_gateway() result . NEW_IG = result[&#39;InternetGateway&#39;] NEW_IG . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . internet_gateways = ec2_client.describe_internet_gateways()[&#39;InternetGateways&#39;] pd.DataFrame(internet_gateways) . VPC&#12395;&#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#12450;&#12479;&#12483;&#12481;&#12377;&#12427; . &#12450;&#12479;&#12483;&#12481;&#12377;&#12427; . result = ec2_client.attach_internet_gateway( InternetGatewayId = NEW_IG[&#39;InternetGatewayId&#39;], VpcId = NEW_VPC[&#39;VpcId&#39;] ) result . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12398;&#35373;&#23450;&#12434;&#30906;&#35469;&#12377;&#12427; . list(filter(lambda x:x[&#39;InternetGatewayId&#39;] == NEW_IG[&#39;InternetGatewayId&#39;], ec2_client.describe_internet_gateways()[&#39;InternetGateways&#39;])) . AttachmentsにアタッチしたVPCのIDが設定されている . &#12469;&#12502;&#12493;&#12483;&#12488;&#12395;&#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#12487;&#12501;&#12457;&#12523;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12395;&#12377;&#12427;&#12523;&#12540;&#12488;&#12434;&#36861;&#21152;&#12377;&#12427; . 以下の順番で行います . 新しいルートテーブルを作成する | 作成したルートテーブルにインターネットゲートウェイをデフォルトゲートウェイにするルートを追加する | 作成したルートテーブルを作成したサブネットに関連づける | &#29694;&#22312;&#12398;&#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . route_tables = ec2_client.describe_route_tables()[&#39;RouteTables&#39;] pd.DataFrame(route_tables) . 新しいVPCのルートテーブルを確認する . route_table = list(filter(lambda x:x[&#39;VpcId&#39;] == NEW_VPC[&#39;VpcId&#39;], ec2_client.describe_route_tables()[&#39;RouteTables&#39;]))[0] route_table . Routesに VPCのCidrブロック(10.0.0.0/16)宛のパケットをlocal、つまりVPC領域のルータへ転送する設定がされていることがわかる . &#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12434;&#20316;&#25104;&#12377;&#12427; . response = ec2_client.create_route_table( VpcId = NEW_VPC[&#39;VpcId&#39;] ) response . NEW＿ROUTE_TABLE = response[&#39;RouteTable&#39;] NEW＿ROUTE_TABLE . この時点で、Routesは既存のルートテーブルと同じになっている。また、Associationsが空なので何にも関連づけられていない。 . &#20316;&#25104;&#12375;&#12383;&#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12395;&#12289;&#20840;&#12390;&#12398;&#12497;&#12465;&#12483;&#12488;&#12434;&#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12395;&#36578;&#36865;&#12377;&#12427;&#12523;&#12540;&#12488;&#12434;&#20316;&#25104;&#12377;&#12427; . response = ec2_client.create_route( DestinationCidrBlock = &#39;0.0.0.0/0&#39;, GatewayId = NEW_IG[&#39;InternetGatewayId&#39;], RouteTableId = NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;] ) response . 新しいルートテーブルの設定を確認する . route_table = list(filter(lambda x:x[&#39;RouteTableId&#39;] == NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;], ec2_client.describe_route_tables()[&#39;RouteTables&#39;]))[0] route_table . RoutesにDestinationCidrBlockが0.0.0.0/0の設定が追加されている . &#26032;&#12375;&#12356;&#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12434;&#12469;&#12502;&#12493;&#12483;&#12488;&#12395;&#38306;&#36899;&#12389;&#12369;&#12427; . response = ec2_client.associate_route_table( RouteTableId = NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;], SubnetId = NEW_SUBNET[&#39;SubnetId&#39;] ) response . 新しいルートテーブルの設定を確認する . route_table = list(filter(lambda x:x[&#39;RouteTableId&#39;] == NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;], ec2_client.describe_route_tables()[&#39;RouteTables&#39;]))[0] route_table . Associationsが設定されていることがわかる . &#12469;&#12540;&#12496;&#12434;&#27083;&#31689;&#12377;&#12427; . &#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12434;&#20316;&#25104;&#12377;&#12427; . &#29694;&#22312;&#12398;&#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12398;&#12522;&#12473;&#12488;&#12434;&#30906;&#35469;&#12377;&#12427; . 新しくVPCを作成するとデフォルトのセキュリティグループが作成されるので確認する . list(filter(lambda x:x[&#39;VpcId&#39;] == NEW_VPC[&#39;VpcId&#39;], ec2_client.describe_security_groups()[&#39;SecurityGroups&#39;])) . &#26032;&#12375;&#12356;&#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12434;&#20316;&#25104;&#12377;&#12427; . response = ec2_client.create_security_group( Description = &#39;from-colab&#39;, GroupName = &#39;from-colab&#39;, VpcId = NEW_VPC[&#39;VpcId&#39;] ) response . NEW_SECURITY_GROUP_ID = response[&#39;GroupId&#39;] NEW_SECURITY_GROUP_ID . &#20316;&#25104;&#12375;&#12383;&#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12398;&#35373;&#23450;&#12434;&#30906;&#35469;&#12375;&#12390;&#12362;&#12367; . list(filter(lambda x:x[&#39;GroupId&#39;] == NEW_SECURITY_GROUP_ID, ec2_client.describe_security_groups()[&#39;SecurityGroups&#39;])) . &#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12395;ssh&#12450;&#12463;&#12475;&#12473;&#29992;&#12398;&#35373;&#23450;&#12434;&#36861;&#21152;&#12377;&#12427; . &#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12395;SSH&#12391;&#12450;&#12463;&#12475;&#12473;&#12377;&#12427;PC&#12398;IP&#12450;&#12489;&#12524;&#12473;&#12434;&#35373;&#23450;&#12377;&#12427; . AWSコンソールから設定する場合は &#39;マイ IP&#39; を選択すれば自分のPCのIPアドレスを設定できましたが、boto3から設定する場合は自分のIPアドレスを値として設定する必要があります . myip = &#39;xxx.xxx.xxx.xxx/xx&#39; . &#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12395;&#35373;&#23450;&#12434;&#36861;&#21152;&#12377;&#12427; . response = ec2_client.authorize_security_group_ingress( GroupId = NEW_SECURITY_GROUP_ID, IpPermissions = [{ &#39;FromPort&#39;: 22, &#39;IpProtocol&#39;: &#39;tcp&#39;, &#39;IpRanges&#39;: [{ &#39;CidrIp&#39;: myip, &#39;Description&#39;: &#39;SSH access from my ip&#39; }], &#39;ToPort&#39;: 22 }] ) response . &#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12398;&#35373;&#23450;&#12434;&#30906;&#35469;&#12375;&#12390;&#12362;&#12367; . list(filter(lambda x:x[&#39;GroupId&#39;] == NEW_SECURITY_GROUP_ID, ec2_client.describe_security_groups()[&#39;SecurityGroups&#39;])) . IpPermissionsに設定が追加されている . &#12461;&#12540;&#12506;&#12450;&#12434;&#20316;&#25104;&#12377;&#12427; . &#31192;&#23494;&#37749;&#12398;&#20445;&#23384;&#20808;&#12392;&#12375;&#12390;GoogleDrive&#12434;&#12510;&#12454;&#12531;&#12488;&#12377;&#12427; . Google ドライブをマウントするには、次のセルを実行してください。 実行すると、ランタイム環境がGoogleDriveへアクセスするための権限を要求されます。 . Go to this URL in a browser: https://accounts.google.com/o/oauth2/ という形式のリンクが表示されるので、マウスでクリックして開いてください&lt;/li&gt; (必要に応じてGoogleアカウントへのログインと)開いた先でアクセス権限を要求されるので、承認してください 承認すると認証コードが表示されるのでコピーします。 | Enter your authorization code: と表示されているテキストボックスへ認証コードを入力しEnterを押下してください. Mounted at /content/drive と表示されれば成功です | &lt;/ol&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; from google.colab import drive drive.mount(&#39;/content/drive&#39;) . &#12461;&#12540;&#12506;&#12450;&#12434;&#20316;&#25104;&#12377;&#12427; . response = ec2_client.create_key_pair( KeyName = &#39;from-colab&#39; ) response . NEW_KEY_NAME = response[&#39;KeyName&#39;] NEW_KEY_NAME . &#31192;&#23494;&#37749;&#12434;&#20445;&#23384;&#12377;&#12427; . GoogleDriveの&quot;マイドライブ&quot;保存します。 保存後、SSHアクセスするPCへ移動させてください。 . file_path = &#39;/content/drive/MyDrive/{}.pem&#39;.format(NEW_KEY_NAME) with open(file_path, mode=&#39;w&#39;) as f: f.write(response[&#39;KeyMaterial&#39;]) . &#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12434;&#36215;&#21205;&#12377;&#12427; . &#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#21517;&#12434;&#35373;&#23450;&#12377;&#12427; . instance_name = &#39;from-colab&#39; . &#12452;&#12513;&#12540;&#12472;id&#12434;&#35373;&#23450;&#12377;&#12427; . インスタンスにインストールするイメージのidを設定します。 今回はamzn2-ami-hvm-2.0.20210427.0-x86_64-gp2を使います。 . // 本当はdescribe_imagesメソッドを使って探したいところですが、 // イメージの数が多いので単純に探すと時間がかかり、絞り込みも大変なので // awsコンソールのec2からインスタンスの起動を選び、ステップ1: Amazon マシンイメージ(AMI)で確認するのが簡単です。 . image_id = &#39;ami-0ca38c7440de1749a&#39; . image_idでimageが見つかることを確認しておく . ec2_client.describe_images( ImageIds = [image_id] ) . &#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12434;&#36215;&#21205;&#12377;&#12427; . responce = ec2_client.run_instances( ImageId = image_id, MinCount = 1, MaxCount=1, InstanceType=&#39;t2.micro&#39;, KeyName = NEW_KEY_NAME, SecurityGroupIds = [NEW_SECURITY_GROUP_ID], SubnetId = NEW_SUBNET[&#39;SubnetId&#39;], TagSpecifications = [{ &#39;ResourceType&#39;: &#39;instance&#39;, &#39;Tags&#39;: [ {&#39;Key&#39;: &#39;Name&#39;, &#39;Value&#39;: instance_name} ] }] ) . NEW_INSTANCES = responce[&#39;Instances&#39;] NEW_INSTANCES . &#36215;&#21205;&#12375;&#12383;&#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12398;&#12497;&#12502;&#12522;&#12483;&#12463;IP&#12434;&#30906;&#35469;&#12377;&#12427; . run_instancesのタイミングではパブリックIPは設定されていないので、起動が終わるのを待ってから詳細情報を取得し、そこからパブリックIPを得る . response = ec2_client.describe_instances( InstanceIds = list(map(lambda x:x[&#39;InstanceId&#39;], NEW_INSTANCES)) ) response . pd.DataFrame([ { &#39;InstanceId&#39;: insntance[&#39;InstanceId&#39;], &#39;InsntanceNmae&#39;: list(map(lambda x:x[&#39;Value&#39;], filter(lambda x:x[&#39;Key&#39;] == &#39;Name&#39;, insntance[&#39;Tags&#39;])))[0], &#39;KeyName&#39;: insntance[&#39;KeyName&#39;], &#39;PublicIpAddress&#39;: insntance[&#39;PublicIpAddress&#39;], } for reservation in response[&#39;Reservations&#39;] for insntance in reservation[&#39;Instances&#39;] ]) . ssh&#25509;&#32154;&#30906;&#35469; . 上で出力した情報を参考PCから起動したインスタンスへsshで接続できることを確認します。 . 確認できたら、boto3を使ったEC2インスタンスの起動は完了です。 . &#24460;&#29255;&#20184;&#12369; . このnotebookはサンプルなので、作成したリソースを削除します。 もし、作成したリソースを使い続けたい場合はこのセクションはスキップしてください . &#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12434;&#21066;&#38500;&#12377;&#12427; . response = ec2_client.terminate_instances( InstanceIds = list(map(lambda x:x[&#39;InstanceId&#39;], NEW_INSTANCES)) ) response . &#12461;&#12540;&#12506;&#12450;&#12434;&#21066;&#38500;&#12377;&#12427; . response = ec2_client.delete_key_pair(KeyName=NEW_KEY_NAME) response . &#12475;&#12461;&#12517;&#12522;&#12486;&#12451;&#12464;&#12523;&#12540;&#12503;&#12434;&#21066;&#38500;&#12377;&#12427; . response = ec2_client.delete_security_group(GroupId=NEW_SECURITY_GROUP_ID) response . &#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12434;&#21066;&#38500;&#12377;&#12427; . route_table = list(filter(lambda x:x[&#39;RouteTableId&#39;] == NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;], ec2_client.describe_route_tables()[&#39;RouteTables&#39;]))[0] route_table . &#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12398;&#38306;&#36899;&#20184;&#12369;&#12434;&#35299;&#38500;&#12377;&#12427; . for association in route_table[&#39;Associations&#39;]: response = ec2_client.disassociate_route_table( AssociationId = association[&#39;RouteTableAssociationId&#39;] ) print(response) . &#12523;&#12540;&#12488;&#12486;&#12540;&#12502;&#12523;&#12434;&#21066;&#38500;&#12377;&#12427; . responce = ec2_client.delete_route_table( RouteTableId = NEW＿ROUTE_TABLE[&#39;RouteTableId&#39;] ) responce . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#21066;&#38500;&#12377;&#12427; . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;VPC&#12363;&#12425;&#12487;&#12479;&#12483;&#12481;&#12377;&#12427; . responce = ec2_client.detach_internet_gateway( InternetGatewayId = NEW_IG[&#39;InternetGatewayId&#39;], VpcId = NEW_VPC[&#39;VpcId&#39;] ) responce . &#12452;&#12531;&#12479;&#12540;&#12493;&#12483;&#12488;&#12466;&#12540;&#12488;&#12454;&#12455;&#12452;&#12434;&#21066;&#38500;&#12377;&#12427; . responce = ec2_client.delete_internet_gateway( InternetGatewayId = NEW_IG[&#39;InternetGatewayId&#39;] ) responce . &#12469;&#12502;&#12493;&#12483;&#12488;&#12434;&#21066;&#38500;&#12377;&#12427; . response = ec2_client.delete_subnet( SubnetId = NEW_SUBNET[&#39;SubnetId&#39;] ) response . VPC&#12434;&#21066;&#38500;&#12377;&#12427; . response = ec2_client.delete_vpc( VpcId = NEW_VPC[&#39;VpcId&#39;] ) response . 以上 . &lt;/div&gt; |",
            "url": "https://taka4ma.github.io/fastpages/jupyter/boto3/2021/04/29/Sample-notebook-for-launching-an-instance-from-GoogleLolaboratory-to-EC2-using-boto3.html",
            "relUrl": "/jupyter/boto3/2021/04/29/Sample-notebook-for-launching-an-instance-from-GoogleLolaboratory-to-EC2-using-boto3.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Amazon Linux2に最新バージョンのSQLiteをインストールする",
            "content": "Amazon Linux2に最新バージョンのSQLiteをインストールする . まずは、yumでインストールできるか確認する。 . yum list | grep ^sqlite sqlite.x86_64 3.7.17-8.amzn2.1.1 @amzn2-core sqlite-devel.x86_64 3.7.17-8.amzn2.1.1 @amzn2-core sqlite.i686 3.7.17-8.amzn2.1.1 amzn2-core sqlite-doc.noarch 3.7.17-8.amzn2.1.1 amzn2-core sqlite-tcl.x86_64 3.7.17-8.amzn2.1.1 amzn2-core sqlite2.x86_64 2.8.17-17.el7 epel sqlite2-devel.x86_64 2.8.17-17.el7 epel sqlite2-tcl.x86_64 2.8.17-17.el7 epel sqlite3-dbf.x86_64 2011.01.24-3.el7 epel . yumでインストールsqlite3は3.7.17だけのようだ。 . Amazon Linux2のExtras Libraryではどうだろうか。Amazon Linux 2 EC2 インスタンスに Extras Library からソフトウェアをインストールするを参考に進める。 . amazon-linux-extras がインストールされているか確認する。 . $ which amazon-linux-extras /usr/bin/amazon-linux-extras . インストールされているようだ。 amazon-linux-extrasを実行すると、利用可能なトピックが表示されるはずなので実行してみる。 . $ sudo amazon-linux-extras | tail 46 collectd available [ =stable ] 47 aws-nitro-enclaves-cli available [ =stable ] 48 R4 available [ =stable ] 49 kernel-5.4 available [ =stable ] 50 selinux-ng available [ =stable ] _ php8.0 available [ =stable ] 52 tomcat9 available [ =stable ] 53 unbound1.13 available [ =stable ] _ mariadb10.5 available [ =stable ] 55 kernel-5.10 available [ =stable ] . 実行できるようだ。sqliteはあるだろうか。 . $ sudo amazon-linux-extras | grep sqlite $ . 残念ながら、Extras Libraryにはないようだ。 . Amazon Linux 2でSQLite3を最新バージョンにする - Qiitaを参考に、SQLiteのソースコードを取得して、ビルドすることにする。 . まずは、ビルドに必要なパッケージをインストールする . $ sudo yum install -y wget tar gzip gcc make Loaded plugins: extras_suggestions, langpacks, priorities, update-motd amzn2-core | 3.7 kB 00:00:00 244 packages excluded due to repository priority protections Package wget-1.14-18.amzn2.1.x86_64 already installed and latest version Package 2:tar-1.26-35.amzn2.x86_64 already installed and latest version Package gzip-1.5-10.amzn2.x86_64 already installed and latest version Package gcc-7.3.1-12.amzn2.x86_64 already installed and latest version Package 1:make-3.82-24.amzn2.x86_64 already installed and latest version Nothing to do . SQLite Download Pageにアクセスし、ソースコードのアーカイブのURLを調べる。必要なアーカイブは sqlite-autoconf-xxxxxxx.tar.gz (xxxxxxxにはバージョンが入る。この記事作成時点のファイル名は sqlite-autoconf-3350500.tar.gz ) . URLがわかったらダウンロードする。(environmentディレクトリへ含む必要がないので、ホームディレクトリへダウンロードすることにする。) . $ cd $ wget https://www.sqlite.org/2021/sqlite-autoconf-3350500.tar.gz --2021-05-02 18:43:00-- https://www.sqlite.org/2021/sqlite-autoconf-3350500.tar.gz Resolving www.sqlite.org (www.sqlite.org)... 45.33.6.223, 2600:3c00::f03c:91ff:fe96:b959 Connecting to www.sqlite.org (www.sqlite.org)|45.33.6.223|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2956627 (2.8M) [application/x-gzip] Saving to: ‘sqlite-autoconf-3350500.tar.gz’ 100%[===============================================================================================&gt;] 2,956,627 2.31MB/s in 1.2s 2021-05-02 18:43:02 (2.31 MB/s) - ‘sqlite-autoconf-3350500.tar.gz’ saved [2956627/2956627] . ダウンロードしたら、configure, make, make installする。 . まずは解凍してconfigureする。configureに与えている引数 --prefix でインストール先を設定する。(今回は /usr/local 。実際には /usr/loca/bin へインストールされる。) . $ tar zxvf sqlite-autoconf-3350500.tar.gz &lt; tarの出力は省略 &gt; $ cd sqlite-autoconf-3350500/ $ ./configure --prefix=/usr/local checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a thread-safe mkdir -p... /usr/bin/mkdir -p checking for gawk... gawk checking whether make sets $(MAKE)... yes checking whether make supports nested variables... yes &lt; 中略 &gt; configure: creating ./config.status config.status: creating Makefile config.status: creating sqlite3.pc config.status: executing depfiles commands config.status: executing libtool command . configureできたらmakeする。 . $ make /bin/sh ./libtool --tag=CC --mode=compile gcc -DPACKAGE_NAME= &quot;sqlite &quot; -DPACKAGE_TARNAME= &quot;sqlite &quot; -DPACKAGE_VERSION= &quot;3.35.5 &quot; -DPACKAGE_STRING= &quot;sqlite 3.35.5 &quot; -DPACKAGE_BUGREPORT= &quot;http://www.sqlite.org &quot; -DPACKAGE_URL= &quot; &quot; -DPACKAGE= &quot;sqlite &quot; -DVERSION= &quot;3.35.5 &quot; -DSTDC_HEADERS=1 -DHAVE_SYS_TYPES_H=1 -DHAVE_SYS_STAT_H=1 -DHAVE_STDLIB_H=1 -DHAVE_STRING_H=1 -DHAVE_MEMORY_H=1 -DHAVE_STRINGS_H=1 -DHAVE_INTTYPES_H=1 -DHAVE_STDINT_H=1 -DHAVE_UNISTD_H=1 -DHAVE_DLFCN_H=1 -DLT_OBJDIR= &quot;.libs/ &quot; -DHAVE_FDATASYNC=1 -DHAVE_USLEEP=1 -DHAVE_LOCALTIME_R=1 -DHAVE_GMTIME_R=1 -DHAVE_DECL_STRERROR_R=1 -DHAVE_STRERROR_R=1 -DHAVE_READLINE_READLINE_H=1 -DHAVE_READLINE=1 -DHAVE_POSIX_FALLOCATE=1 -DHAVE_ZLIB_H=1 -I. -D_REENTRANT=1 -DSQLITE_THREADSAFE=1 -DSQLITE_ENABLE_MATH_FUNCTIONS -DSQLITE_ENABLE_FTS4 -DSQLITE_ENABLE_FTS5 -DSQLITE_ENABLE_JSON1 -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_GEOPOLY -DSQLITE_HAVE_ZLIB -g -O2 -MT sqlite3.lo -MD -MP -MF .deps/sqlite3.Tpo -c -o sqlite3.lo sqlite3.c &lt; 中略 &gt; libtool: link: gcc -D_REENTRANT=1 -DSQLITE_THREADSAFE=1 -DSQLITE_ENABLE_MATH_FUNCTIONS -DSQLITE_ENABLE_FTS4 -DSQLITE_ENABLE_FTS5 -DSQLITE_ENABLE_JSON1 -DSQLITE_ENABLE_RTREE -DSQLITE_ENABLE_GEOPOLY -DSQLITE_HAVE_ZLIB -DSQLITE_ENABLE_EXPLAIN_COMMENTS -DSQLITE_ENABLE_DBPAGE_VTAB -DSQLITE_ENABLE_STMTVTAB -DSQLITE_ENABLE_DBSTAT_VTAB -g -O2 -o sqlite3 sqlite3-shell.o sqlite3-sqlite3.o -lreadline -ltermcap -lz -lm -ldl -lpthread . 最後にmake installする。 . $ sudo make install make[1]: Entering directory `/home/ec2-user/sqlite-autoconf-3350500&#39; /usr/bin/mkdir -p &#39;/usr/local/lib&#39; /bin/sh ./libtool --mode=install /usr/bin/install -c libsqlite3.la &#39;/usr/local/lib&#39; libtool: install: /usr/bin/install -c .libs/libsqlite3.so.0.8.6 /usr/local/lib/libsqlite3.so.0.8.6 libtool: install: (cd /usr/local/lib &amp;&amp; { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so.0 || { rm -f libsqlite3.so.0 &amp;&amp; ln -s libsqlite3.so.0.8.6 libsqlite3.so.0; }; }) libtool: install: (cd /usr/local/lib &amp;&amp; { ln -s -f libsqlite3.so.0.8.6 libsqlite3.so || { rm -f libsqlite3.so &amp;&amp; ln -s libsqlite3.so.0.8.6 libsqlite3.so; }; }) libtool: install: /usr/bin/install -c .libs/libsqlite3.lai /usr/local/lib/libsqlite3.la libtool: install: /usr/bin/install -c .libs/libsqlite3.a /usr/local/lib/libsqlite3.a libtool: install: chmod 644 /usr/local/lib/libsqlite3.a libtool: install: ranlib /usr/local/lib/libsqlite3.a libtool: finish: PATH=&quot;/sbin:/bin:/usr/sbin:/usr/bin:/sbin&quot; ldconfig -n /usr/local/lib - Libraries have been installed in: /usr/local/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use the &#39;-LLIBDIR&#39; flag during linking and do at least one of the following: - add LIBDIR to the &#39;LD_LIBRARY_PATH&#39; environment variable during execution - add LIBDIR to the &#39;LD_RUN_PATH&#39; environment variable during linking - use the &#39;-Wl,-rpath -Wl,LIBDIR&#39; linker flag - have your system administrator add LIBDIR to &#39;/etc/ld.so.conf&#39; See any operating system documentation about shared libraries for more information, such as the ld(1) and ld.so(8) manual pages. - /usr/bin/mkdir -p &#39;/usr/local/bin&#39; /bin/sh ./libtool --mode=install /usr/bin/install -c sqlite3 &#39;/usr/local/bin&#39; libtool: install: /usr/bin/install -c sqlite3 /usr/local/bin/sqlite3 /usr/bin/mkdir -p &#39;/usr/local/include&#39; /usr/bin/install -c -m 644 sqlite3.h sqlite3ext.h &#39;/usr/local/include&#39; /usr/bin/mkdir -p &#39;/usr/local/share/man/man1&#39; /usr/bin/install -c -m 644 sqlite3.1 &#39;/usr/local/share/man/man1&#39; /usr/bin/mkdir -p &#39;/usr/local/lib/pkgconfig&#39; /usr/bin/install -c -m 644 sqlite3.pc &#39;/usr/local/lib/pkgconfig&#39; make[1]: Leaving directory `/home/ec2-user/sqlite-autoconf-3350500&#39; . makeが終わったら確認する。 . $ which sqlite3 /usr/local/bin/sqlite3 $ sqlite3 --version 3.35.5 2021-04-19 18:32:05 1b256d97b553a9611efca188a3d995a2fff712759044ba480f9a0c9e98fae886 . SQLite 3.35.5がインストールでき、Pathも通っているようだ。Pythonからはどうだろうか。 . $ python -c &quot;import sqlite3;print(sqlite3.sqlite_version)&quot; 3.7.17 . pythonからは3.7.17のSQLiteが見えているようだ。make installした時に表示された ↓ のメッセージに従って、 /usr/local/lib にインストールされたライブラリとリンクする必要がある。 . Libraries have been installed in: /usr/local/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use the &#39;-LLIBDIR&#39; flag during linking and do at least one of the following: - add LIBDIR to the &#39;LD_LIBRARY_PATH&#39; environment variable during execution - add LIBDIR to the &#39;LD_RUN_PATH&#39; environment variable during linking - use the &#39;-Wl,-rpath -Wl,LIBDIR&#39; linker flag - have your system administrator add LIBDIR to &#39;/etc/ld.so.conf&#39; . CentOS7でldconfigを使って共有ライブラリを追加する - Qiita を参考進めていく。 . 現在認識されているsqlite3のライブラリのパスを確認する。 . $ sudo ldconfig -p | grep sqlite libsqlite3.so.0 (libc6,x86-64) =&gt; /lib64/libsqlite3.so.0 libsqlite3.so (libc6,x86-64) =&gt; /lib64/libsqlite3.so . /etc/ld.so.conf の内容を確認する。 . $ cat /etc/ld.so.conf include ld.so.conf.d/*.conf . /etc/ld.so.conf.d/ に .conf で終わるファイルをおけば良さそう。 . $ sudo bash -c &quot;echo /usr/local/lib &gt; /etc/ld.so.conf.d/sqlite3.conf&quot; $ sudo ls /etc/ld.so.conf.d/ bind-export-x86_64.conf kernel-4.14.165-131.185.amzn2.x86_64.conf kernel-4.14.231-173.360.amzn2.x86_64.conf dyninst-x86_64.conf kernel-4.14.225-168.357.amzn2.x86_64.conf sqlite3.conf $ sudo cat /etc/ld.so.conf.d/sqlite3.conf /usr/local/lib . キャッシュファイルを更新し、sqlite3のライブラリのパスを確認する。 . $ sudo ldconfig $ sudo ldconfig -p | grep sqlite libsqlite3.so.0 (libc6,x86-64) =&gt; /usr/local/lib/libsqlite3.so.0 libsqlite3.so.0 (libc6,x86-64) =&gt; /lib64/libsqlite3.so.0 libsqlite3.so (libc6,x86-64) =&gt; /usr/local/lib/libsqlite3.so libsqlite3.so (libc6,x86-64) =&gt; /lib64/libsqlite3.so . 追加できている。 あらためて、Pythonからどう見えるか確認する。 . $ python -c &quot;import sqlite3;print(sqlite3.sqlite_version)&quot; 3.35.5 . インストールした3.35.5が見えるようになった。 .",
            "url": "https://taka4ma.github.io/fastpages/sqlite/amazon_linux2/2021/04/24/Install-the-latest-version-of-SQLite-on-Amazon-Linux2.html",
            "relUrl": "/sqlite/amazon_linux2/2021/04/24/Install-the-latest-version-of-SQLite-on-Amazon-Linux2.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Cloud9にDjango開発環境を作る",
            "content": "Cloud9にDjango開発環境を作る . この記事では、Cloud9でPython開発環境を作るでCloud9に作ったPython開発環境にDjangoの開発環境を作っていく。 . 仮想環境を起動する . Cloud9でPython開発環境を作る で ~/environment ディレクトリにmyenvという名前の仮想環境を作成した。その仮想環境を起動する . cd ~/environment source myenv/bin/activate . Djangoをインストールする . ここからは、Djangoのインストール · HonKitを参考に進めていく。 . 最初に、requirments.txtを作成する。 . // requirments.txtとは、pipでインストールするライブラリのリストが書かれたファイルのこと。詳細は User Guide - pip documentation v21.0.1を参照。 . $ cd ~/environments $ echo Djangp~=2.2.4 &gt; requirements.txt . 一応、ファイルの内容を確認しておく。 . $ cat requirements.txt Django~=2.2.4 . requirements.txt ができたら、pipを使ってインストールする。 . $ pip install -r requirements.txt Collecting Django~=2.2.4 Downloading Django-2.2.20-py3-none-any.whl (7.5 MB) |████████████████████████████████| 7.5 MB 13.0 MB/s Collecting pytz Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB) |████████████████████████████████| 510 kB 53.6 MB/s Collecting sqlparse&gt;=0.2.2 Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB) |████████████████████████████████| 42 kB 2.3 MB/s Installing collected packages: pytz, sqlparse, Django Successfully installed Django-2.2.20 pytz-2021.1 sqlparse-0.4.1 . インストールが終わったら、pip freezeでインストールされたライブラリとバージョンを確認しておく。 . $ pip freeze Django==2.2.20 pytz==2021.1 sqlparse==0.4.1 . Djangoプロジェクトを作成する . ここからはプロジェクトを作成しよう！ · HonKitを参考に進めていく。 . 以下のコマンドを実行し、”mysite”という名前のDjangoのプロジェクトを~/environmentに作成する。 . $ cd ~/environment $ django-admin startproject mysite . . 実行すると、以下のようなファイル構造が作成される。 . $ tree -L 2 . ├── manage.py ├── myenv │   ├── bin │   ├── include │   ├── lib │   ├── lib64 -&gt; lib │   └── pyvenv.cfg ├── mysite │   ├── __init__.py │   ├── settings.py │   ├── urls.py │   └── wsgi.py ├── README.md └── requirements.txt . // これはtreeコマンドで2階層表示した結果。 // treeコマンドはAmazon Linuxにデフォルトでは入っていないので、インストールする場合は sudo yum install -y tree を実行する。 . manage.pyとmysiteがスクリプトによって作られたファイル。 myenvとrequirements.txtはこのセクションよりも前に作ってあったもの。 README.mdはcloud9のファイル。 . 設定を変更する . 作成したDjangoプロジェクトのmysite/settings.pyをエディタで編集するが、まずは編集前のファイルをコピーしておく。 . cp mysite/settings.py mysite/settings.py.bk . コピーをとったら、オリジナルファイルをエディタで開いて編集する。 . タイムゾーン . TIME_ZONE = &#39;Asia/Tokyo&#39; . | 言語コード . LANGUAGE_CODE = &#39;ja&#39; . | 静的ファイルのパス(STATIC_URLの次の行にSTATIC_ROOTを追加する) . STATIC_URL = &#39;/static/&#39; STATIC_ROOT = os.path.join(BASE_DIR, &#39;static&#39;) . | アクセス許可ホスト . ALLOWED_HOSTS = [&#39;.amazonaws.com&#39;] . | . 編集が終わったら、コピーしておいた編集前のファイルとの差分を確認する。以下のような結果になればOK。 . $ diff mysite/settings.py.bk mysite/settings.py 28c28 &lt; ALLOWED_HOSTS = [] &gt; ALLOWED_HOSTS = [&#39;.amazonaws.com&#39;] 106c106 &lt; LANGUAGE_CODE = &#39;en-us&#39; &gt; LANGUAGE_CODE = &#39;ja&#39; 108c108 &lt; TIME_ZONE = &#39;UTC&#39; &gt; TIME_ZONE = &#39;Asia/Tokyo&#39; 120a121 &gt; STATIC_ROOT = os.path.join(BASE_DIR, &#39;static&#39;) . DBをセットアップする . mysite/settings.pyにはデフォルトのDB設定が書かれている。 . $ grep DATABASES -A 6 mysite/settings.py DATABASES = { &#39;default&#39;: { &#39;ENGINE&#39;: &#39;django.db.backends.sqlite3&#39;, &#39;NAME&#39;: os.path.join(BASE_DIR, &#39;db.sqlite3&#39;), } . 今回は、この設定をそのまま使い、sqlite3をDBとして使用する。DBを作成するために、以下のコマンドを実行すると、 . $ python manage.py migrate Traceback (most recent call last): File &quot;manage.py&quot;, line 21, in &lt;module&gt; main() File &quot;manage.py&quot;, line 17, in main execute_from_command_line(sys.argv) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/core/management/__init__.py&quot;, line 381, in execute_from_command_line utility.execute() File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/core/management/__init__.py&quot;, line 357, in execute django.setup() File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/__init__.py&quot;, line 24, in setup apps.populate(settings.INSTALLED_APPS) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/apps/registry.py&quot;, line 114, in populate app_config.import_models() File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/apps/config.py&quot;, line 211, in import_models self.models_module = import_module(models_module_name) File &quot;/usr/lib64/python3.7/importlib/__init__.py&quot;, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/contrib/auth/models.py&quot;, line 2, in &lt;module&gt; from django.contrib.auth.base_user import AbstractBaseUser, BaseUserManager File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/contrib/auth/base_user.py&quot;, line 47, in &lt;module&gt; class AbstractBaseUser(models.Model): File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/models/base.py&quot;, line 117, in __new__ new_class.add_to_class(&#39;_meta&#39;, Options(meta, app_label)) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/models/base.py&quot;, line 321, in add_to_class value.contribute_to_class(cls, name) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/models/options.py&quot;, line 204, in contribute_to_class self.db_table = truncate_name(self.db_table, connection.ops.max_name_length()) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/__init__.py&quot;, line 28, in __getattr__ return getattr(connections[DEFAULT_DB_ALIAS], item) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/utils.py&quot;, line 201, in __getitem__ backend = load_backend(db[&#39;ENGINE&#39;]) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/utils.py&quot;, line 110, in load_backend return import_module(&#39;%s.base&#39; % backend_name) File &quot;/usr/lib64/python3.7/importlib/__init__.py&quot;, line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/backends/sqlite3/base.py&quot;, line 66, in &lt;module&gt; check_sqlite_version() File &quot;/home/ec2-user/environment/myenv/lib64/python3.7/site-packages/django/db/backends/sqlite3/base.py&quot;, line 63, in check_sqlite_version raise ImproperlyConfigured(&#39;SQLite 3.8.3 or later is required (found %s).&#39; % Database.sqlite_version) django.core.exceptions.ImproperlyConfigured: SQLite 3.8.3 or later is required (found 3.7.17). . エラーが出た。エラーメッセージによると、 . django.core.exceptions.ImproperlyConfigured: SQLite 3.8.3 or later is required (found 3.7.17). . DjangoがSQLite 3.8.3以降を必要としているのに対して、3.7.17がインストールされているためのようだ。 . 念の為確認しておく . $ python -c &quot;import sqlite3;print(sqlite3.sqlite_version)&quot; 3.7.17 . 確かに、pythonからは3.7.17のSQLiteが見えるようだ。 . // このコマンドは、pythonのコマンドオプション -c を使ってコマンドとして渡したPythonコードを実行している。 参考:1. コマンドラインと環境 — Python 3.9.4 ドキュメント . システム上ではどうだろうか。pathが通っているsqlite3のバージョンを確認してみる。 . $ which sqlite3 /usr/bin/sqlite3 $ sqlite3 --version 3.7.17 2013-05-20 00:56:22 118a3b35693b134d56ebd780123b7fd6f1497668 . pathが通っているsqlite3は3.7.17だ。rootのPATHは一般ユーザと異なる場合があり、そこに別バージョンがインストールされている可能性がある。確認してみる。 . $ sudo which sqlite3 /bin/sqlite3 $ /bin/sqlite3 --version 3.7.17 2013-05-20 00:56:22 118a3b35693b134d56ebd780123b7fd6f1497668 . rootのpath上には /bin/sqlite3 があるようだが、バージョンはこちらも3.7.17だ。 . Djangoが要求するバージョンのSQLiteはデフォルトではインストールされていないようなので、最新バージョンのSQLiteをインストールすることにする。 . この記事は、Cloud9でPython開発環境を作るでCloud9に作ったPython開発環境を前提としているので、サーバはAmazon Linux2を前提としている。Amazon Linux2へ最新のSQLite3をインストールする方法は、Amazon Linux2へ最新バージョンのSQLiteをインストールする にまとめたので、そちらを参照して最新のSQLiteをインストールする。 . 最新のSQLiteをインストールできたら、改めてDBを作成する。 . $ python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying sessions.0001_initial... OK . 今度はエラーも出ず終了した。 . webサーバを起動する . DBのマイグレーションができたら、webサーバ(Django開発サーバ)を起動する。 . // 起動するサーバはあくまで開発用なので運用環境でしようしてはいけない。 . python manage.py runserverで起動すると、8000ポートを使用するがCloud9では8000ポートは使えないようなので、8080で起動するよう引数を与える。 . $ python manage.py runserver 8080 Watching for file changes with StatReloader Performing system checks... System check identified no issues (0 silenced). May 04, 2021 - 21:50:22 Django version 2.2.20, using settings &#39;mysite.settings&#39; Starting development server at http://127.0.0.1:8080/ Quit the server with CONTROL-C. . Cloud9で開発サーバを起動するとウィンドウの右上に、 . Cloud9 Help Your code running at https://(a bunch of letters and numbers).vfs.cloud9.us-west-2.amazonaws.com . のように書かれたウィンドウが表示されるので、そのURLをクリックするとブラウザでWebサイトが開かれる。 ブラウザには、 . インストールは成功しました！おめでとうございます！ . と書かれた、ロケットが離陸しているページが表示される。 . 以上で、Cloud9でのDjango開発環境の構築は終わり。 最後に、Clou9のコンソールに戻り、Ctrl+C で開発サーバを停止しておく。 .",
            "url": "https://taka4ma.github.io/fastpages/cloud9/django/2021/04/22/Creating-a-Django-development-environment-on-Cloud9.html",
            "relUrl": "/cloud9/django/2021/04/22/Creating-a-Django-development-environment-on-Cloud9.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Cloud9でPython開発環境を作る",
            "content": "&#21021;&#12417;&#12395; . この記事は、LinuxのPython開発環境を簡単に用意する手段としてCloud9を利用する手順です。 . Cloud9&#12452;&#12531;&#12473;&#12479;&#12531;&#12473;&#12434;&#31435;&#12385;&#19978;&#12370;&#12427; . AWSマネジメントコンソール にログインします . | 使用するリージョンを選択します . | 検索窓にcloud9と入力し、AWS Cloud9コンソールを開きます . | [Create environment]を選択します . | . 環境の名前と説明の入力を求められるので、入力します。入力したら Next stepをクリックします。 | . 環境設定を求められるので、設定します。(この記事では全てデフォルトで進めます。) 選択し終わったら Next stepをクリックします。 . Environment Type : Create a new insntance for environment (direct access) | Instance type : t2.micro | Platform : Amazon Linux2(recommended) | Cost-saving setting : After 30 minutes(default) | . | . 設定のレビューが表示されるので、確認し、問題がなければ Create environmentをクリックします。 クリックするとEC2にCloud9のインスタンスが作成されます。ブラウザはCloud9に遷移し、環境が起動すると以下のようなウェルカム画面が表示されます。 | . Cloud9&#29872;&#22659;&#12434;&#30906;&#35469;&#12377;&#12427; . Cloud9が起動したら、環境の確認を行います。Cloud9はインスタンスをデプロイするタイミングにより使用されるイメージが異なるので、デプロイしたら確認したほうが良いでしょう。 . Cloud9のデフォルトでは、下部にターミナルウィンドウが表示されています。これはCloud9を実行しているEC2インスタンスに接続されています。この記事では、Cloud9のPlatformにAmazon Linux2を選択したので、ターミナルウィンドウからLinuxコマンドを入力して、Cloud9を実行しているインスタンスを操作することができます。 . この記事では、以降の操作はターミナルウィンドウから行います . . まずは、OSのバージョンなどを確認します。この記事の作成時点では以下のようになっていました。 . $ cat /proc/version Linux version 4.14.225-168.357.amzn2.x86_64 (mockbuild@ip-10-0-1-132) (gcc version 7.3.1 20180712 (Red Hat 7.3.1-12) (GCC)) #1 SMP Mon Mar 15 18:00:02 UTC 2021 $ uname -a Linux ip-172-31-1-107.ap-northeast-1.compute.internal 4.14.225-168.357.amzn2.x86_64 #1 SMP Mon Mar 15 18:00:02 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux $ cat /etc/system-release Amazon Linux release 2 (Karoo) $ cat /etc/os-release NAME=&quot;Amazon Linux&quot; VERSION=&quot;2&quot; ID=&quot;amzn&quot; ID_LIKE=&quot;centos rhel fedora&quot; VERSION_ID=&quot;2&quot; PRETTY_NAME=&quot;Amazon Linux 2&quot; ANSI_COLOR=&quot;0;33&quot; CPE_NAME=&quot;cpe:2.3:o:amazon:amazon_linux:2&quot; HOME_URL=&quot;https://amazonlinux.com/&quot; . Python&#12392;pip&#12398;&#12496;&#12540;&#12472;&#12519;&#12531;&#12434;&#30906;&#35469;&#12377;&#12427; . Pythonとpipバージョンも確認しておきます。同じく、記事作成時点では以下のようになっていました。 . $ python --version Python 3.7.9 $ sudo python --version Python 2.7.18 . sudo pythonではPython 2.7にパスが通っているので注意が必要です。(イメージによって異なる可能性があります。) . $ python -m pip --version pip 9.0.3 from /usr/lib/python3.7/site-packages (python 3.7) . pip&#12434;&#26356;&#26032;&#12377;&#12427; . 仮想環境を起動したら、pipを最新バージョンに更新します。 記事作成時点では、pipのバージョンは20.1.1でした。 . 以下のコマンドを実行して、更新します。 . $ pip3 install --upgrade pip --user Collecting pip Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB) 100% |████████████████████████████████| 1.5MB 812kB/s Installing collected packages: pip Successfully installed pip-21.0.1 $ python -m pip --version pip 21.0.1 from /home/ec2-user/.local/lib/python3.7/site-packages/pip (python 3.7) . 実行した結果21.0.1になりました。 . Virtualenv&#12434;&#20316;&#25104;&#12375;&#36215;&#21205;&#12377;&#12427; . Python 3.3以降、標準機能であるvenvで仮想環境を作成することで、pipで導入するパッケージをプロジェクト毎に独立させることができます。 . Cloud9を利用する場合プロジェクト毎にインスタンスを分ければ仮想環境は必要ないように思えます。 しかしPythonがプリインストールされているLinux環境の場合、標準でないライブラリがインストールされている場合があります。 . この記事作成時点でのCloud9では以下のようになっていました。これから開発するソフトウェアが既にインストールされているライブラリの影響を受けないようにする為にvenvを使用します。 . $ python -m pip freeze astroid==2.3.0 backcall==0.2.0 botocore==1.20.37 decorator==4.4.2 Django==2.0.2 git-remote-codecommit==1.15.1 ikp3db==1.4.1 importlib-metadata==3.7.3 ipython==7.21.0 ipython-genutils==0.2.0 isort==4.3.21 jedi==0.18.0 jmespath==0.10.0 lazy-object-proxy==1.6.0 mccabe==0.6.1 parso==0.8.1 pbr==5.5.1 pexpect==4.8.0 pickleshare==0.7.5 prompt-toolkit==3.0.18 ptyprocess==0.7.0 Pygments==2.8.1 pylint==2.4.4 pylint-django==2.3.0 pylint-flask==0.6 pylint-plugin-utils==0.6 python-dateutil==2.8.1 pytz==2021.1 six==1.15.0 stevedore==3.3.0 traitlets==5.0.5 typed-ast==1.4.2 typing-extensions==3.7.4.3 urllib3==1.26.4 virtualenv==16.2.0 virtualenv-clone==0.5.4 virtualenvwrapper==4.8.4 wcwidth==0.2.5 wrapt==1.12.1 zipp==3.4.1 . ~/environmentディレクトリで、仮想環境を作成します。今回は myenv という名前にします。 . $ cd ~/environment $ python -mvenv myenv . 仮想環境を作成すると、カレントディレクトリに仮想環境名(今回はmyenv)のディレクトリが作成されます。) . $ ls -l total 4 drwxrwxr-x 5 ec2-user ec2-user 74 Mar 29 13:32 myenv -rw-r--r-- 1 ec2-user ec2-user 569 Mar 18 10:35 README.md . 仮想環境を作成したら、以下のコマンドで仮想環境を起動します。 . $ source myenv/bin/activete . venvを作成しactivateした直後にpip freezeすると、ライブラリが何もインストールされていないことがわかります。 . $ python -m pip freeze $ # &lt;- 何も表示されない . なお、仮想環境から抜ける場合は以下のコマンドを実行します。 . $ deactivate . 参考: venv 仮想環境の作成 — Python 3.9.2 ドキュメント .",
            "url": "https://taka4ma.github.io/fastpages/cloud9/python/2021/03/30/Creating-a-Python-development-environment-with-Cloud9.html",
            "relUrl": "/cloud9/python/2021/03/30/Creating-a-Python-development-environment-with-Cloud9.html",
            "date": " • Mar 30, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "GoogleColaboratoryでboto3を使用するサンプルnotebook",
            "content": "&#12371;&#12398;notebook&#12399;...... . Amazon Web Services (AWS)のPython向けSDKであるBotoをGoogleColaboratoryから使用するサンプルです。 . Botoの詳細は、 公式ドキュメント を参照してください。 . このNotebookを実行するには、Amazon web service(AWS)のアカウントが必要です。 AWSの利用にはクレジットカード等の登録が必要な場合があります。 . &#20316;&#26989;&#28310;&#20633; . AWS&#12450;&#12463;&#12475;&#12473;&#12461;&#12540;&#12398;&#20316;&#25104; . Botoを使用するには、事前にAWSのアクセスキーを用意する必要があります。 . アクセスキー管理方法は様々ありますが、AWS IAMのユーザー https://console.aws.amazon.com/iam/home?region=us-west-2#/users からNotebook用のユーザーを作成する方法があります。万が一アクセスキーが漏れた場合に備えて、権限を最小限に、いつでも無効化できるように設定する必要があります。 . &#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . Boto公式ドキュメントの Installation を参考に、GoogleColaboratoryのラインタイム環境へ、boto3をインストールします。 . !pip install boto3 . Collecting boto3 Downloading https://files.pythonhosted.org/packages/3f/87/31810f044f2dd2101f2ecd85c5539bbddef4cff47df39eb0be895cc23af4/boto3-1.15.16-py2.py3-none-any.whl (129kB) |████████████████████████████████| 133kB 4.4MB/s Collecting botocore&lt;1.19.0,&gt;=1.18.16 Downloading https://files.pythonhosted.org/packages/2d/9e/afa41db0cd911869305bb783b9b021be67ea23c8b7b317caa46632dbf3cf/botocore-1.18.16-py2.py3-none-any.whl (6.7MB) |████████████████████████████████| 6.7MB 11.9MB/s Collecting s3transfer&lt;0.4.0,&gt;=0.3.0 Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB) |████████████████████████████████| 71kB 6.3MB/s Collecting jmespath&lt;1.0.0,&gt;=0.7.1 Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore&lt;1.19.0,&gt;=1.18.16-&gt;boto3) (2.8.1) Requirement already satisfied: urllib3&lt;1.26,&gt;=1.20; python_version != &#34;3.4&#34; in /usr/local/lib/python3.6/dist-packages (from botocore&lt;1.19.0,&gt;=1.18.16-&gt;boto3) (1.24.3) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.19.0,&gt;=1.18.16-&gt;boto3) (1.15.0) Installing collected packages: jmespath, botocore, s3transfer, boto3 Successfully installed boto3-1.15.16 botocore-1.18.16 jmespath-0.10.0 s3transfer-0.3.3 . &#12467;&#12531;&#12501;&#12451;&#12464;&#12524;&#12540;&#12471;&#12519;&#12531; . Botoを使用するためには、認証資格情報をセットアップする必要があります。 . Boto公式ドキュメントの Configuration には、AWSCLIを用いる方法と、~/.aws/credentialsに設定を記述する方法が記載されていますが、 Using environment variables によれば、環境変数に設定することも可能なので、このnotebookでは環境変数を設定することにします。 . なお、最低限設定すべき環境変数は、 Configuration の記述内容から、以下の3つと考えられます。 . AWS_ACCESS_KEY_ID | AWS_SECRET_ACCESS_KEY | AWS_DEFAULT_REGION | AWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYには、AWSアクセスキーのアクセスキー IDとシークレットアクセスキーを設定します。 . AWS_DEFAULT_REGIONには使用するリージョンを設定します。このnotebookでは東京リージョン( ap-northeast-1 )を使用します。 . &#12450;&#12463;&#12475;&#12473;&#12461;&#12540;ID&#12434;&#35373;&#23450;&#12377;&#12427; . import os import getpass os.environ[&#39;AWS_ACCESS_KEY_ID&#39;] = getpass.getpass() . ·········· . &#12471;&#12540;&#12463;&#12524;&#12483;&#12488;&#12450;&#12463;&#12475;&#12473;&#12461;&#12540;&#12434;&#35373;&#23450;&#12377;&#12427; . os.environ[&#39;AWS_SECRET_ACCESS_KEY&#39;] = getpass.getpass() . ·········· . &#12487;&#12501;&#12457;&#12523;&#12488;&#12522;&#12540;&#12472;&#12519;&#12531;&#12434;&#35373;&#23450;&#12377;&#12427; . os.environ[&#39;AWS_DEFAULT_REGION&#39;] = &#39;ap-northeast-1&#39; . boto3&#12434;&#20351;&#29992;&#12375;&#12390;&#12415;&#12427; . 公式ドキュメントの Using Boto3 を参考に、Boto3を使ってみる . boto3をインポートし、使用するサービスとしてS3を指定する . import boto3 s3 = boto3.resource(&#39;s3&#39;) . S3の全てのバケット名を出力する . for bucket in s3.buckets.all(): print(bucket.name) . mybucket-202007211923 . Using Boto3では、ファイルをバケットへputしているが、その前に現在のバケット内のオブジェクトを確認しておく . Using Boto3に書かれていないS3リソースについては、Boto3ドキュメントの S3 を参照のこと . bucket = s3.Bucket(&#39;mybucket-202007211923&#39;) list(bucket.objects.all()) . [] . オブジェクトは何もないようだ . Using Boto3と同じように、バケットへファイルをputする。 . ただし、Colaboratory環境へ画像ファイルをアップロードするのが面倒なので、今回はテキストファイルをputすることにする . !touch foo.txt !ls -l . total 4 -rw-r--r-- 1 root root 0 Oct 13 14:07 foo.txt drwxr-xr-x 1 root root 4096 Oct 5 16:31 sample_data . with open(&#39;foo.txt&#39;, &#39;rb&#39;) as data: bucket.put_object(Key=&#39;foo.txt&#39;, Body=data) . ファイルがputできたか確認する . list(bucket.objects.all()) . [s3.ObjectSummary(bucket_name=&#39;mybucket-202007211923&#39;, key=&#39;foo.txt&#39;)] . putできたようだ . 以上 .",
            "url": "https://taka4ma.github.io/fastpages/jupyter/boto3/2020/11/01/sample-notebook-for-using-boto3-in-Colab.html",
            "relUrl": "/jupyter/boto3/2020/11/01/sample-notebook-for-using-boto3-in-Colab.html",
            "date": " • Nov 1, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "GoogleColaboratoryでPlantUMLを使ってUMLを作る",
            "content": "PlantUML&#12398;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . &#29872;&#22659;&#12398;&#30906;&#35469; . OS&#12434;&#30906;&#35469;&#12377;&#12427; . インストールする前に、まずはGoogleColaboratoryのOSを確認しておきます。 . !cat /etc/os-release . NAME=&#34;Ubuntu&#34; VERSION=&#34;18.04.3 LTS (Bionic Beaver)&#34; ID=ubuntu ID_LIKE=debian PRETTY_NAME=&#34;Ubuntu 18.04.3 LTS&#34; VERSION_ID=&#34;18.04&#34; HOME_URL=&#34;https://www.ubuntu.com/&#34; SUPPORT_URL=&#34;https://help.ubuntu.com/&#34; BUG_REPORT_URL=&#34;https://bugs.launchpad.net/ubuntu/&#34; PRIVACY_POLICY_URL=&#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&#34; VERSION_CODENAME=bionic UBUNTU_CODENAME=bionic . コマンドの実行結果から、Ubuntu 18.04.3 LTSということがわかります。 . Java&#12364;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#12373;&#12428;&#12390;&#12356;&#12427;&#12363;&#30906;&#35469;&#12377;&#12427; . PlantUMLの実行にはJavaが必要なので、GoogleColaboratory環境にインストールされているか確認します。 . !which java . /usr/bin/java . どうやらインストールされているようです。ちなみにバージョンは、 . !java --version . openjdk 11.0.6 2020-01-14 OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1) OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing) . OpenJDKの11.0.6のようです。 . PlantUML&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523;&#12377;&#12427; . sourceforgeでホストされているplantumlのjarファイルを/usr/loca/binへインストールします . !curl -L -o /usr/local/bin/plantuml.jar http://sourceforge.net/projects/plantuml/files/plantuml.jar/download . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 178 100 178 0 0 1028 0 --:--:-- --:--:-- --:--:-- 1028 100 21190 100 21190 0 0 35854 0 --:--:-- --:--:-- --:--:-- 82773 100 313 100 313 0 0 332 0 --:--:-- --:--:-- --:--:-- 332 100 8358k 100 8358k 0 0 6187k 0 0:00:01 0:00:01 --:--:-- 100M . lsコマンドで確認しておきます . !ls -la /usr/local/bin/plant* . -rw-r--r-- 1 root root 8559351 Apr 30 13:25 /usr/local/bin/plantuml.jar . インストールできました。 . graphviz&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . シーケンス図・アクティビティ図以外のダイアグラムを作成する場合はGraphvizも必要なので、インストールしておきます。 . !sudo apt-get install -y graphviz . Reading package lists... Done Building dependency tree Reading state information... Done graphviz is already the newest version (2.40.1-2). 0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded. . IPlantUML&#12434;&#12452;&#12531;&#12473;&#12488;&#12540;&#12523; . GoogleColatobatoryにPlantUMLのセルマジックを追加し、インラインSVGとして生成できるように、IPlantUMLもインストールします . !sudo pip install iplantuml . Collecting iplantuml Downloading https://files.pythonhosted.org/packages/10/b9/4db9b9ce81184d1d67f82284ca6131258b32f3f69376ee88aab5f7ff60a4/IPlantUML-0.1.1.tar.gz Collecting plantweb Downloading https://files.pythonhosted.org/packages/d6/6f/9ab1a1c3e33aaa0c0931983578c09336b092c75dce777ea666d3032f756e/plantweb-1.2.1-py3-none-any.whl Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plantweb-&gt;iplantuml) (1.12.0) Requirement already satisfied: docutils in /usr/local/lib/python3.6/dist-packages (from plantweb-&gt;iplantuml) (0.15.2) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plantweb-&gt;iplantuml) (2.21.0) Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;plantweb-&gt;iplantuml) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;plantweb-&gt;iplantuml) (2020.4.5.1) Requirement already satisfied: urllib3&lt;1.25,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;plantweb-&gt;iplantuml) (1.24.3) Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;plantweb-&gt;iplantuml) (2.8) Building wheels for collected packages: iplantuml Building wheel for iplantuml (setup.py) ... done Created wheel for iplantuml: filename=IPlantUML-0.1.1-py2.py3-none-any.whl size=4897 sha256=afc5be23c60bc3f2596072cd6ef33d2658197b2fcf0e08b9f8d81da62ca9582a Stored in directory: /root/.cache/pip/wheels/98/e3/22/5474b6852d1717733862688fe1d1470f749f1fe7ae0d508ce7 Successfully built iplantuml Installing collected packages: plantweb, iplantuml Successfully installed iplantuml-0.1.1 plantweb-1.2.1 . &#12480;&#12452;&#12450;&#12464;&#12521;&#12512;&#12434;notebook&#12398;&#12452;&#12531;&#12521;&#12452;&#12531;SVG&#12392;&#12375;&#12390;&#20316;&#25104;&#12377;&#12427; . 環境が整ったので、iplantumlを使って、notebookに埋め込まれた形のUMLを作成してみます。 . import iplantuml . %%plantuml @startuml Title シーケンス図 Alice -&gt; Bob: Authentication Request Bob --&gt; Alice: Authentication Response Alice -&gt; Bob: Another authentication Request Alice &lt;-- Bob: another authentication Response @enduml . シーケンス図AliceAliceBobBobAuthentication RequestAuthentication ResponseAnother authentication Requestanother authentication Response できました。 . PlantUML言語リファレンスガイド に記載されている各ダイアグラムの文法に従えば、シーケンス図以外のダイアグラムも作成できます。 . &#12486;&#12461;&#12473;&#12488;&#12392;&#12480;&#12452;&#12450;&#12464;&#12521;&#12512;&#12434;&#12501;&#12449;&#12452;&#12523;&#12392;&#12375;&#12390;&#20316;&#25104;&#12377;&#12427; . PlantUMLのテキストや、そこから生成したダイアグラムをファイルとして保存したい場合には、以下のようにします。 . PantUML&#12398;&#12486;&#12461;&#12473;&#12488;&#12501;&#12449;&#12452;&#12523;&#12434;&#20316;&#25104;&#12377;&#12427; . wfitefileマジックコマンドを使って、PlantUMLのテキストを、plantuml.umlという名前で保存します。 . %%writefile plantuml.uml @startuml Title sequence diagram Alice -&gt; Bob: Authentication Request Bob --&gt; Alice: Authentication Response Alice -&gt; Bob: Another authentication Request Alice &lt;-- Bob: another authentication Response @enduml . Overwriting plantuml.uml . ファイルができているか確認します。 . !ls -l . total 16 -rw-r--r-- 1 root root 8171 Apr 30 13:51 plantuml.png -rw-r--r-- 1 root root 210 Apr 30 13:54 plantuml.uml drwxr-xr-x 1 root root 4096 Apr 3 16:24 sample_data . できていました。 . &#12486;&#12461;&#12473;&#12488;&#12501;&#12449;&#12452;&#12523;&#12363;&#12425;&#30011;&#20687;&#12434;&#29983;&#25104;&#12377;&#12427; . plantuml.jarを実行して、画像を生成します。 . !java -jar /usr/local/bin/plantuml.jar plantuml.uml . 正常終了するとアウトプットセルには何も出力されません。 . lsコマンドで画像ファイルができているか確認します。 . !ls -l . total 20 -rw-r--r-- 1 root root 9888 Apr 30 13:54 plantuml.png -rw-r--r-- 1 root root 210 Apr 30 13:54 plantuml.uml drwxr-xr-x 1 root root 4096 Apr 3 16:24 sample_data . できていました。 . notebookに読み込んで確認してみます。 . from IPython.display import Image Image(&quot;./plantuml.png&quot;) . 意図した通りの図になっています。 . GoogleDriveのフォルダをColaboratory環境にマウントすれば、ここで作成したファイルをGoogleDriveへ直接保存することができます。 .",
            "url": "https://taka4ma.github.io/fastpages/jupyter/plantuml/2020/04/30/googlecolaboratory-plantuml-uml.html",
            "relUrl": "/jupyter/plantuml/2020/04/30/googlecolaboratory-plantuml-uml.html",
            "date": " • Apr 30, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "k8s概要",
            "content": "k8s overview . k8s = 複数のホストを束ねてDockerを利用するためのオーケストレーションツール あたかも1台のサーバのように、透過的にアクセスできる。 . 主な機能 . 複数サーバ間でのコンテナ管理 | コンテナ間のネットワーキング | コンテナの負荷分散 | コンテナの監視 | 無停止でのアップデート | . k8sのサーバ構成 . マスターサーバ(kubernetes master) | データストア(backend database) | ノード | . マスタサーバ(kubernetes master) . コンテナを操作するためのサーバ | kubctlコマンドからのリクエストを受けて処理を行う | ノードのリソース使用状況を確認してコンテナを起動するノードを選択する | . データストア(backend database) . etcdというKVSでクラスタの構成情報を管理 | マスタサーバに構築する構成もありうる | . ノード . コンテナを動作させるサーバ | . アプリケーションの構成管理 . Pod | Replica set | Deployment | . Pod . k8sでは複数のコンテナをまとめてPodとして管理する webサーバとプロキシなど | . | Podがデプロイの単位になる 開始/停止/作成/削除 がpod単位で行われる | . | Pod(pod内のコンテナ)は同じノードに同時にデプロイされる Pod内のコンテナは仮想NICを共有する コンテナ同士はlocalhost軽油で通信できる | 共有ディレクトリを介してログ情報をやり取りできる | . | . | . Replica set . k8sクラスタ上で予めpodを作成/起動しておく仕組み クラスタ上に決められた数のpodを起動しておく | 起動しておくpodの数をレプリカ数という | . | Replica setは起動中のpodを監視し、障害など何らかの理由で停止したpodを削除し、新たなpodを起動する | pod数を同的に変更してオートスケーリングを実現することも可能 | . Deployment . PodとReplica setをまとめたもの | Replica setの履歴を管理するもの 履歴を管理できるので、コンテナのアップデートやロールバックができる | . | Replica setのテンプレートを持ち、それに従ってReplica setを作る テンプレートでpodの構成を定義する | . | . ネットワークの管理(Service) . Serviceはlocalhostのネットワークを管理するもの | Podに対して外部からアクセスする時はServiceを定義する | Serviceにはいくつかの種類がある Load Balancer Serviceに対応するIPアドレス:ポート番号にアクセスするとL4レベルの負荷分散が行われる | . | . | サービスによって割り当てられるIPアドレスにはCluster IPとExternal IPがある Cluster IPはクラスタ内のPod同士で通信するためのプライベートIPアドレス | External IPはクラスタ外部から通信するためのパブリックIPアドレス | . | Podを起動すると、既存のサービスのIPアドレスとポートは環境変数として参照できるようになる | IngressというPodへの通信を制御する昨日もある k8sが動作する環境によって実装が異なる GCPの場合はHTTP Load Balanser(L7) | . | . | . Labelによるリソースの識別 . k8sではリソースを識別するためにランダムな文字列が自動的付与される | リソースには任意のLabelをつけて管理できる | Labelはkey-value型の任意の文字列 | サービス定義のSelectorでLabelを指定すると、そのLabelを保つPodのみにリクエストを転送することが可能 | . k8sの仕組み . Master API Server フロントエンドのREST API | 各コンポーネントから情報を受け取ってetcdに保存する 各コンポーネントはREST API経由でetcdの情報にアクセスする | . | 人間はkubctlコマンドはWebのGUIツールからアクセスする | 認証・認可の機能も持つ | . | Scheduler Podをどのノードで動かすか制御するバックエンドコンポーネント | . | Controller Manager k8sクラスタの状態を監視するバックエンドコンポーネント | 定義ファイルで指定したものと実際の状態をまとめて管理する | . | . | Datastore k8sクラスタの構成を保持する分散KVS | APIサーバから参照される | . | Node kublet ノードで動作するエージェント | Dockerコンテナの実行やストレージのマウント機能を持つ | ノードのステータスを定期的に監視し、ステータスが変わるとAPI Serverに通知する | . | . |",
            "url": "https://taka4ma.github.io/fastpages/k8s/2020/04/19/k8s-overview.html",
            "relUrl": "/k8s/2020/04/19/k8s-overview.html",
            "date": " • Apr 19, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Ubuntu Serverへのjupyter notebookインストール手順",
            "content": "Ubuntu Serverへのjupyter notebookインストール手順 . これは、AWS EC2のUbuntu Server 14.04 LTSへjupyter notebookをインストールし起動するための手順です。(AWSの設定手順については、この記事では触れません。) . 前提条件 . EC2インスタンスは作成済みのこと | セキュリティグループのインバウンドルールに以下を追加しておくこと | タイプ:カスタムTCPルール, ポート範囲:8888, 送信元は自身の環境に合わせて適切に設定すること | . なお、この手順は以下の環境で動作確認しています。 . リージョン: 東京 | AMI: Ubuntu Server 14.04 LTS (HVM), SSD Volume Type - ami-936d9d93 | インスタンスタイプ: t2.micro | . 手順 . Installation — Jupyter Documentation 4.1.0b1 documentationではanacondaの利用を勧めているので、pyenvを使ってpythonとanacondaをインストールし、anacondaでjupyter notebookをインストールします。 . EC2インスタンスへのsshアクセス . EC2インスタンスにはsshでアクセスします。 . $ ssh -i aws-key ubuntu@public-ip . git インストール . pyenvのインストールにgitが必要になるのでインストールします。 . $ sudo apt-get install -y git . pyenv インストール . pyenvのInstallation-Basic GitHub Checkoutの1~4の手順でインストールします。 ただし、basic-github-checkoutの手順そのままでは上手く行きません。幾つか手順を変える必要があります。 . Ubuntu 14.04では.bash_profileが.profileに変わっているので、そこを読み替える 1 | 手順4はシェルのリスタートなのでexecに-lオプションが不足している 2 | 実際に叩くコマンドは以下になります。 . $ git clone https://github.com/yyuu/pyenv.git ~/.pyenv $ echo &#39;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&#39; &gt;&gt; ~/.profile $ echo &#39;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&#39; &gt;&gt; ~/.profile $ echo &#39;eval &quot;$(pyenv init -)&quot;&#39; &gt;&gt; ~/.profile $ exec -l $SHELL . anacondaインストール . pyenvででpythonとanacondaをインストールします。 まず、pyenvでインストール出来るanacondaのリストを確認しておきます。 . $ pyenv install -l | grep anaconda anaconda-1.4.0 anaconda-1.5.0 anaconda-1.5.1 anaconda-1.6.0 anaconda-1.6.1 anaconda-1.7.0 anaconda-1.8.0 anaconda-1.9.0 anaconda-1.9.1 anaconda-1.9.2 anaconda-2.0.0 anaconda-2.0.1 anaconda-2.1.0 anaconda-2.2.0 anaconda-2.3.0 anaconda-2.4.0 anaconda2-2.4.0 anaconda2-2.4.1 anaconda3-2.0.0 anaconda3-2.0.1 anaconda3-2.1.0 anaconda3-2.2.0 anaconda3-2.3.0 anaconda3-2.4.0 anaconda3-2.4.1 . このとき表示されたバージョンをインストールするとanacondaに加えてpythonもインストールされます。anaconda-*及びanaconda2-がPython2系、anaconda3-*がPython3系です。3 . 今回の手順ではanaconda2.4.1をPython3系で使うことにします。 なお、この時ダウンロードされるAnaconda3-2.4.1-Linux-x86_64.shは270MBほどのサイズです。EC2ではあまり問題にならないと思いますが、回線の細い環境でインストールする場合は時間がかかる場合がありあす。 . $ pyenv install anaconda3-2.4.1 Downloading Anaconda3-2.4.1-Linux-x86_64.sh... -&gt; http://repo.continuum.io/archive/Anaconda3-2.4.1-Linux-x86_64.sh Installing Anaconda3-2.4.1-Linux-x86_64... Installed Anaconda3-2.4.1-Linux-x86_64 to /home/ubuntu/.pyenv/versions/anaconda3-2.4.1 . インストールが終わったらanaconda3-2.4.1をpyenvのグローバルにします。 . $ pyenv global anaconda3-2.4.1 . なお、グローバルに設定したPythonとanacondaのバージョンはpython --versionで確認できます。 . $ python --version Python 3.5.1 :: Anaconda 2.4.1 (64-bit) . jupyterのインストール . anacondaをインストールできたらいよいよjupyter notebookのインストールです。 コマンドはconda install -y jupyterだけで大丈夫です。 . $ conda install -y jupyter Fetching package metadata: .... Solving package specifications: .................................................................. Package plan for installation in environment /home/ubuntu/.pyenv/versions/anaconda3-2.4.1: The following packages will be downloaded: package | build |-- openssl-1.0.2e | 0 3.2 MB defaults sqlite-3.9.2 | 0 3.9 MB defaults decorator-4.0.6 | py35_0 6 KB defaults pyzmq-15.2.0 | py35_0 792 KB defaults requests-2.9.1 | py35_0 648 KB defaults setuptools-19.2 | py35_0 348 KB defaults conda-3.19.0 | py35_0 180 KB defaults ipython-4.0.2 | py35_0 970 KB defaults ipykernel-4.2.2 | py35_0 115 KB defaults nbconvert-4.1.0 | py35_0 275 KB defaults notebook-4.1.0 | py35_0 4.4 MB defaults ipywidgets-4.1.1 | py35_0 99 KB defaults Total: 14.8 MB The following packages will be UPDATED: conda: 3.18.8-py35_0 defaults --&gt; 3.19.0-py35_0 defaults decorator: 4.0.4-py35_0 defaults --&gt; 4.0.6-py35_0 defaults ipykernel: 4.1.1-py35_0 defaults --&gt; 4.2.2-py35_0 defaults ipython: 4.0.1-py35_0 defaults --&gt; 4.0.2-py35_0 defaults ipywidgets: 4.1.0-py35_0 defaults --&gt; 4.1.1-py35_0 defaults nbconvert: 4.0.0-py35_0 defaults --&gt; 4.1.0-py35_0 defaults notebook: 4.0.6-py35_0 defaults --&gt; 4.1.0-py35_0 defaults openssl: 1.0.2d-0 defaults --&gt; 1.0.2e-0 defaults pyzmq: 14.7.0-py35_1 defaults --&gt; 15.2.0-py35_0 defaults requests: 2.8.1-py35_0 defaults --&gt; 2.9.1-py35_0 defaults setuptools: 18.5-py35_0 defaults --&gt; 19.2-py35_0 defaults sqlite: 3.8.4.1-1 defaults --&gt; 3.9.2-0 defaults Fetching packages ... openssl-1.0.2e 100% |################################| Time: 0:00:01 2.16 MB/s sqlite-3.9.2-0 100% |################################| Time: 0:00:01 2.43 MB/s decorator-4.0. 100% |################################| Time: 0:00:00 7.56 MB/s pyzmq-15.2.0-p 100% |################################| Time: 0:00:01 770.63 kB/s requests-2.9.1 100% |################################| Time: 0:00:01 552.84 kB/s setuptools-19. 100% |################################| Time: 0:00:00 467.58 kB/s conda-3.19.0-p 100% |################################| Time: 0:00:00 284.50 kB/s ipython-4.0.2- 100% |################################| Time: 0:00:01 826.19 kB/s ipykernel-4.2. 100% |################################| Time: 0:00:00 245.78 kB/s nbconvert-4.1. 100% |################################| Time: 0:00:00 369.84 kB/s notebook-4.1.0 100% |################################| Time: 0:00:01 2.37 MB/s ipywidgets-4.1 100% |################################| Time: 0:00:00 229.46 kB/s Extracting packages ... [ COMPLETE ]|###################################################| 100% Unlinking packages ... [ COMPLETE ]|###################################################| 100% Linking packages ... [ COMPLETE ]|###################################################| 100% . jupyterの設定 . jupyter notebookをEC2で使うには、いくつかの設定を変更しなければなりません。 まずは、コンフィグファイルを作成します。4 . $ jupyter notebook --generate-config Writing default config to: /home/ubuntu/.jupyter/jupyter_notebook_config.py . 出力のとおり/home/ubuntu/.jupyter/jupyter_notebook_config.pyにコンフィグファイルが作られるので、以下の項目を変更します。 . c.NotebookApp.ip = &#39;*&#39; # ローカルホスト以外からもアクセス可能にする c.NotebookApp.open_browser = False # ブラウザが自動で開かないようにする . なお、各項目の変更前の値は以下です。 . # c.NotebookApp.ip = &#39;localhost&#39; # c.NotebookApp.open_browser = True . sedで処理する場合は次のように。 . $ sed -ri &quot;s/# c.NotebookApp.ip = &#39;localhost&#39;/c.NotebookApp.ip = &#39;*&#39;/g&quot; /home/ubuntu/.jupyter/jupyter_notebook_config.py $ sed -ri &quot;s/# c.NotebookApp.open_browser = True/c.NotebookApp.open_browser = False/g&quot; /home/ubuntu/.jupyter/jupyter_notebook_config.py . なお、コンフィグファイルの各項目について知りたい場合は、Config file and command line options — Jupyter Notebook 4.1.0rc1 documentationを参照してください。 . jupyter notebookの開始 . 以上でjupyter notebookのインストールと設定が出来ました。 コンソールでjupyter notebookと入力するとjupyter notebookがスタートします。 . $ jupyter notebook . ブラウザでEC2インスタンスのpublic_ip_address:8888にアクセスし、jupyter notebookのトップページが表示されればインストール・設定は完了です。 . オプション . パスワードの設定 . これまでの手順でjupyter notebookを立ち上げてアクセスすることは可能ですが、このまま立ち上げると誰でもアクセス可能(=サーバ上でPythonコードを実行し放題)なので、パスワードを設定します。5 . まずサーバのコンソールでipythonを立ち上げパスワードのハッシュを得ます。 . $ ipython In [1]: from notebook.auth import passwd In [2]: passwd() Enter password: # パスワードを入力 Verify password: # パスワードを再入力 Out[2]: &#39;sha1:371793e28601:458c6bb9fc9371410b37cfc0d5833bfb54a26d7c&#39; #ハッシュ値が出力されるのでこれをコピーする In [3]: quit() # ipythonを終了 . 次に/home/ubuntu/.jupyter/jupyter_notebook_config.pyにパスワードのハッシュを書き込みます。 c.NotebookApp.passwordはコメントアウトされているので、#も忘れずに消します。 . c.NotebookApp.password = &#39;sha1:371793e28601:458c6bb9fc9371410b37cfc0d5833bfb54a26d7c&#39; . 暗号化通信の設定 . パスワードを設定してもこのままでは平文で送信されるため、パスワードもjupyter notebookとブラウザ間の通信も盗聴される恐れがあります。 . 今回は とりあえず 、Using SSL for encrypted communicationの内容で自己署名証明書を設定して通信経路の暗号化を行ってみます。 . $ openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout .jupyter/mykey.key -out .jupyter/mycert.pem . 作成したcertfileとkeyfileを使用するようコンフィグを設定します。 . c.NotebookApp.certfile = &#39;/home/ubuntu/.jupyter/mycert.pem&#39; c.NotebookApp.keyfile = &#39;/home/ubuntu/.jupyter/mykey.key&#39; . jupyter notebookをスタートしたら、httpsでのアクセスのみを受け付けるようになります。 . Ubuntu14.04 - Ubuntu 14.04 の .bash_profile ファイル のファイル名 は、.profile に変わっていた件 - Qiita &#8617; . | shell - シェルの再起動 - Qiita &#8617; . | AnacondaでPythonの分析環境をまとめてインストール - TASK NOTES &#8617; . | Configuring Jupyter applications — Jupyter Documentation 4.1.0b1 documentation &#8617; . | ipython notebookをリモートサーバ上で動かす。 - 忘れないようにメモっとく &#8617; . |",
            "url": "https://taka4ma.github.io/fastpages/jupyter/2016/03/01/jupyter-notebook-installation-procedure-on-ubuntu-server.html",
            "relUrl": "/jupyter/2016/03/01/jupyter-notebook-installation-procedure-on-ubuntu-server.html",
            "date": " • Mar 1, 2016"
        }
        
    
  
    
        ,"post15": {
            "title": "kitchen-docker用Dockerfile",
            "content": "kitchen-docker用Dockerfile . test-kitchenでkitchen-dockerを使う場合、.kitchen.ymlでテストインスタンスのベースイメージを設定する方法として、以下の3種類があります。 . 設定しない (内部ではKitchen::Driver::Docker.default_image()によって、platform.nameからname:TAGが作られる) . ~~~ 前略 ~~~ platforms: - name: centos-7.1 # &lt;= ここからcentos:centos7が生成される driver_config: privileged: true run_command: /sbin/init; sleep 3 ~~~ 後略 ~~~ . | name:TAGで設定 . ~~~ 前略 ~~~ platforms: - name: centos-7.1 driver_config: image: centos:centos7 # &lt;= コレ privileged: true run_command: /sbin/init; sleep 3 ~~~ 後略 ~~~ . | Dockerfileのパスを設定 (内部ではerbテンプレートとして扱われるので、eRubyタグでマークアップ可能。) . ~~~ 前略 ~~~ platforms: - name: centos-7.1 driver_config: dockerfile: test/platforms/centos-7.1/Dockerfile # &lt;= コレ privileged: true run_command: /sbin/init; sleep 3 ~~~ 後略 ~~~ . FROM centos:centos7 . | kitchen-dockerでは上記1. 2. の場合ベースイメージとして設定されたイメージをFROMとし、test-kitchenで使用する場合に必要となるパッケージや設定を加えたDockerfileを作ってdocker buildを行い、ビルドされたコンテナイメージをテスト環境として使用します。 しかし、3. の場合はパスで設定されたDockerfileをそのまま使ってdocker buildするので、Dockerfileに1. 2.の場合にビルドされる内容が含まれていないとテスト環境として使用できません。 . ということで、それに対応しているDockerfileが以下になります。 . &lt;%= from = &quot;FROM #{@image}&quot; platform = case @platform when &#39;debian&#39;, &#39;ubuntu&#39; disable_upstart = &lt;&lt;-eos RUN dpkg-divert --local --rename --add /sbin/initctl RUN ln -sf /bin/true /sbin/initctl eos packages = &lt;&lt;-eos ENV DEBIAN_FRONTEND noninteractive RUN apt-get update RUN apt-get install -y sudo openssh-server curl lsb-release eos @disable_upstart ? disable_upstart + packages : packages when &#39;rhel&#39;, &#39;centos&#39;, &#39;fedora&#39; &lt;&lt;-eos RUN yum clean all RUN yum install -y sudo openssh-server openssh-clients which curl RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N &#39;&#39; RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -N &#39;&#39; eos when &#39;arch&#39; &lt;&lt;-eos RUN pacman -Syu --noconfirm RUN pacman -S --noconfirm openssh sudo curl RUN ssh-keygen -A -t rsa -f /etc/ssh/ssh_host_rsa_key RUN ssh-keygen -A -t dsa -f /etc/ssh/ssh_host_dsa_key eos when &#39;gentoo&#39; &lt;&lt;-eos RUN emerge sync RUN emerge net-misc/openssh app-admin/sudo RUN ssh-keygen -A -t rsa -f /etc/ssh/ssh_host_rsa_key RUN ssh-keygen -A -t dsa -f /etc/ssh/ssh_host_dsa_key eos when &#39;gentoo-paludis&#39; &lt;&lt;-eos RUN cave sync RUN cave resolve -zx net-misc/openssh app-admin/sudo RUN ssh-keygen -A -t rsa -f /etc/ssh/ssh_host_rsa_key RUN ssh-keygen -A -t dsa -f /etc/ssh/ssh_host_dsa_key eos else raise ActionFailed, &quot;Unknown platform &#39;#{@platform}&#39;&quot; end username = @username password = @password public_key = IO.read(@public_key).strip homedir = username == &#39;root&#39; ? &#39;/root&#39; : &quot;/home/#{username}&quot; base = &lt;&lt;-eos RUN if ! getent passwd #{username}; then useradd -d #{homedir} -m -s /bin/bash #{username}; fi RUN echo #{username}:#{password} | chpasswd RUN echo &#39;#{username} ALL=(ALL) NOPASSWD:ALL&#39; &gt;&gt; /etc/sudoers RUN mkdir -p /etc/sudoers.d RUN echo &#39;#{username} ALL=(ALL) NOPASSWD:ALL&#39; &gt;&gt; /etc/sudoers.d/#{username} RUN chmod 0440 /etc/sudoers.d/#{username} RUN mkdir -p #{homedir}/.ssh RUN chown -R #{username} #{homedir}/.ssh RUN chmod 0700 #{homedir}/.ssh RUN touch #{homedir}/.ssh/authorized_keys RUN chown #{username} #{homedir}/.ssh/authorized_keys RUN chmod 0600 #{homedir}/.ssh/authorized_keys eos custom = &#39;&#39; Array(@provision_command).each do |cmd| custom &lt;&lt; &quot;RUN #{cmd} n&quot; end ssh_key = &quot;RUN echo &#39;#{public_key}&#39; &gt;&gt; #{homedir}/.ssh/authorized_keys&quot; # Empty string to ensure the file ends with a newline. [from, platform, base, custom, ssh_key, &#39;&#39;].join(&quot; n&quot;) %&gt; . これをdriver_config.dockerfileに設定したパスへ保存し、個別のテスト環境に必要なDockerbuildを追記してあげれば使えるハズです。 . 実のところ、Kitchen::Driver::Docker.build_dockerfileをコピーしつつ若干手をいれて、erbテンプレートとして使えるようにしただけです。 .",
            "url": "https://taka4ma.github.io/fastpages/kitchen-docker/2015/10/02/Dockerfile-for-kitchen-docker.html",
            "relUrl": "/kitchen-docker/2015/10/02/Dockerfile-for-kitchen-docker.html",
            "date": " • Oct 2, 2015"
        }
        
    
  
    
        ,"post16": {
            "title": "AnsibleTDD環境をtest-kitchen, serverspec, Dockerで作る(2015年10月版)",
            "content": "AnsibleTDD環境をtest-kitchen, serverspec, Dockerで作る(2015年10月版) . この記事は、test-kitchen, serverspec, DockerをつかってAnsibleのテスト駆動開発を行う環境を構築する手順をまとめたものです。 Ubuntu14,CentOS7でApache2をインストールし、サービスを起動し、ブート時のサービス自動起動を設定するベストプラクティス構成1のAnsible playbookを例として取りあげます。 . この記事の目標 . AnsibleのTDD環境として、test-kitchenで次のことが出来る環境を作ります。 . Docker上にUbuntu14, CentOS7のコンテナを立ち上げ | 各コンテナをAnsibleでプロビジョニング | 各コンテナのプロビジョニング結果をServerspecで検証 | . 前提条件等 . この記事の前提条件は以下のとおりです。 . 作成するAnsible playbookの構成はベストプラクティスのディレクトリレイアウトに従う1　 | 作業環境は CentOS6.7(x86_64) | Rubyインストール済みのこと | bundlerインストール済みのこと | Dockerインストール済みのこと | . | . なお、この記事の検証に使用した環境は以下のとおりです。 . $ cat /etc/redhat-release CentOS release 6.7 (Final) $ arch x86_64 $ ruby -v ruby 2.1.5p273 (2014-11-13 revision 48405) [x86_64-linux] $ bundler -v Bundler version 1.9.2 $ docker -v Docker version 1.7.1, build 786b29d . (2015-12-04追記) 環境構築用のVagrantfileを作りました。 https://github.com/takasix/vagrant_kitchen_ansible . (元々別の用があって作ったものなので、バージョン指定が入っておらず、この記事の検証に使用した環境と全く同じ環境は構築されません。追記時点では記事の内容が全て動くことを確認済みです。) . 本文 . プロジェクト用ディレクトリの作成 . プロジェクト用のディレクトリを作成します。これ以降の手順はこのディレクトリをベースに行います。 . $ mkdir ~/ansibletdd $ cd ~/ansibletdd . test-kitchenインストール . プロジェクトディレクトリにGemfileを作成し、bundlerを使ってtest-kitchenをインストールします。 . source &#39;https://rubygems.org&#39; gem &#39;test-kitchen&#39; . 書けたらbundle installします。 . $ bundle install Fetching gem metadata from https://rubygems.org/.......... Fetching version metadata from https://rubygems.org/... Fetching dependency metadata from https://rubygems.org/.. Resolving dependencies... Using mixlib-shellout 2.2.1 Using net-ssh 2.9.2 Using net-scp 1.2.1 Using safe_yaml 1.0.4 Using thor 0.19.1 Using test-kitchen 1.4.2 Using bundler 1.9.2 Bundle complete! 1 Gemfile dependency, 7 gems now installed. Use `bundle show [gemname]` to see where a bundled gem is installed. . test-kitchen初期化 . kitchen initコマンドでtest-kitchenを初期化します。このとき–driver(または-D)オプションでドライバを、–provisioner(または-P)オプションでプロビジョナを指定できます。 今回は、テストを行う環境にDockerを使うのでドライバに”kitchen-docker”、プロビジョニングにはAnsibleを使うのでプロビジョナに”ansible_playbook”をそれぞれ指定します。 . $ bundle exec kitchen init --driver=kitchen-docker --provisioner=ansible_playbook create .kitchen.yml create chefignore create test/integration/default append Gemfile You must run `bundle install&#39; to fetch any new gems. . 初期化を行うと.kitchen.ymlファイルといくつかのディレクトリが作成されます。また、Gemfileが変更されます。 . $ cat .kitchen.yml driver: name: docker provisioner: name: ansible_playbook platforms: - name: ubuntu-14.04 - name: centos-7.1 suites: - name: default run_list: attributes: $ $ tree . ├── Gemfile ├── Gemfile.lock ├── chefignore └── test └── integration └── default $ $ cat Gemfile source &#39;https://rubygems.org&#39; gem &#39;test-kitchen&#39; gem &quot;kitchen-docker&quot; . kitchen-ansibleとServerspecインストール . kitchen initによって変更されたGemfileにkitchen-ansibleとserverspecを加え、bundlerを使ってインストールします。 . source &#39;https://rubygems.org&#39; gem &#39;test-kitchen&#39; gem &quot;kitchen-docker&quot; gem &#39;kitchen-ansible&#39; gem &#39;serverspec&#39; . 変更したら、もう一度bundle installします。 . $ bundle install Resolving dependencies... Using diff-lcs 1.2.5 Using multipart-post 2.0.0 Using faraday 0.9.2 Using highline 1.7.8 Using thor 0.19.1 Using librarian 0.1.2 Using librarian-ansible 1.0.6 Using mixlib-shellout 2.2.1 Using net-ssh 2.9.2 Using net-scp 1.2.1 Using safe_yaml 1.0.4 Using test-kitchen 1.4.2 Using kitchen-ansible 0.0.27 Using kitchen-docker 2.3.0 Using multi_json 1.11.2 Using net-telnet 0.1.1 Using rspec-support 3.3.0 Using rspec-core 3.3.2 Using rspec-expectations 3.3.1 Using rspec-mocks 3.3.2 Using rspec 3.3.0 Using rspec-its 1.2.0 Using sfl 2.2 Using specinfra 2.43.10 Using serverspec 2.24.1 Using bundler 1.9.2 Bundle complete! 4 Gemfile dependencies, 26 gems now installed. Use `bundle show [gemname]` to see where a bundled gem is installed. . .kitchen.ymlの設定 . kitchen initで作成された.kitchen.ymlを編集しtest-kitchenの設定を行います。 (編集が終わった.kitchen.ymlはこのセクションの一番最後にあります。) . driver: name: docker provisioner: name: ansible_playbook platforms: - name: ubuntu-14.04 - name: centos-7.1 suites: - name: default run_list: attributes: . driver . driverは、変更する必要はありません。 . driver: name: docker . provisioner . provisionerにはプロビジョナーのオプションを以下のように設定します。 なお、ansible_playbookのオプションはProvisioner Optionsも参照してください。 . provisioner: name: ansible_playbook playbook: site.yml roles_path: ./roles group_vars_path: ./group_vars host_vars_path: ./host_vars filter_plugins: ./filter_plugins additional_copy_path: - webservers.yml hosts: webservers require_ansible_omnibus: true require_ruby_for_busser: true . playbook master playbook(site.yml)を.kitchen.ymlからの相対パスで設定します。 . | roles_path, group_vars_path, host_vars_path, filter_plugins それぞれのディレクトリを.kitchen.ymlからの相対パスで設定します。 . | additional_copy_path 他にテスト環境へコピーするファイル・ディレクトリを.kitchen.ymlからの相対パスで設定します。この設定は配列なので複数の項目を設定できます。 . ベストプラクティス構成では、サーバー群(tier)ごとのPlay bookを作成し、site.ymlでサーバ群ごとのPlay bookをincludeすることで、site.ymlをインフラ全体の定義とします。2 しかし、kitchen-ansibleはplaybookに設定したymlをテスト環境へコピーしますが、その中でincludeしているymlまではコピーしてくれません。そこでサーバー群別Play bookもテスト環境へコピーされるようadditional_copy_pathに設定します。 (rolesディレクトリにあるrole別のPlay bookはroles_pathの設定によってコピーされます。) . 今回は、Apacheをインストールしたいので、サーバー群Play bookはwebservers.ymlという名前で作ることにして、とりあえずadditional_copy_pathに書いておきます。 . | hosts hostsオプションにはテスト環境がどのホストグループに含まれるホストかを定義します。 テスト環境にはhostsの設定を元に以下のようなinventryファイルが作成され、プロビジョニングに使用されます。 . localhost ansible_connection=local [webservers] # &lt;= ここにhostsオプションが設定される localhost . 今回は、ホストグループもwebserversという名前で作ることにして、とりあえずhostsに書いておきます。 . | require_ansible_omnibus trueにすると、テスト環境へのAnsibleインストールを、ansible_omnibus_urlオプション(デフォルトは　https://raw.githubusercontent.com/neillturner/omnibus-ansible/master/ansible_install.sh)で定義されたスクリプトで行います。 . (このオプションのデフォルトはfalseです。falseの場合、テスト環境へのAnsibleのインストールはyumまたはaptで行うのですが、記事執筆時点ではsyntax errorとなるため、オムニバスインストーラーを使用します。) . | require_ruby_for_busser trueの場合、テスト環境でbusserの実行に使用するrubyをインストールします。(busserはtest-kitchenのテストフレームワークです。) . このオプションのデフォルトはfalseで、その場合はChefをインストールし、それに同梱されているrubyでbusserを実行します。今回はAnsibleを使うためChefは不要、その上rubyよりもインストールに時間がかかるのでtrueにします。 . | platforms . platformsにはテスト環境を以下のように設定します。 . platforms: - name: ubuntu-14.04 - name: centos-7.1 driver_config: privileged: true run_command: /sbin/init; sleep 3 . 本記事執筆時点のcentos:centos7イメージでは、systemctlを使用するためには特権モードかつ起動コマンドを/sbin/initにしなければならない3ので、そのためのオプションを追加します。 . verifier . .kitchen.ymlにverifierを追加しテストツールのオプションを以下のように設定します。 . verifier: ruby_bindir: &#39;/usr/bin&#39; . verifierのruby_bindirにはテストツールの実行に使用するrubyがインストールされているディレクトリを設定します。 デフォルトは/opt/chef/embedded/binで、これはChefに同梱されるrubyのディレクトリを指しています。 今回はprovisioner設定でChefを入れず、代わりにrubyをインストールするため、ruby_bindirにはそちらのパスを設定します。 . suites . suitesにはテストスイートを以下のように設定します。 . suites: - name: default attributes: . run_listはkitchen-ansibleでは使用しないため消してしまいます。 attributesは今回は使用しませんが、extra_varsやtagsを設定する場合はここにぶら下げるので、残しておきます。 . 以上で、.kitchen.ymlの設定は終わりです。 最終的に.kitchen.ymlは以下のようになります。 . driver: name: docker provisioner: name: ansible_playbook playbook: site.yml roles_path: ./roles group_vars_path: ./group_vars host_vars_path: ./host_vars filter_plugins: ./filter_plugins additional_copy_path: - webservers.yml hosts: webservers require_ansible_omnibus: true require_ruby_for_busser: true platforms: - name: ubuntu-14.04 - name: centos-7.1 driver_config: privileged: true run_command: /sbin/init; sleep 3 verifier: ruby_bindir: &#39;/usr/bin&#39; suites: - name: default attributes: . .kitchen.ymlの編集が終わったら、kitchen listコマンドを叩くと以下のようにテスト環境が表示されるはずです。 . $ bundle exec kitchen list Instance Driver Provisioner Verifier Transport Last Action default-ubuntu-1404 Docker AnsiblePlaybook Busser Ssh &lt;Not Created&gt; default-centos-71 Docker AnsiblePlaybook Busser Ssh &lt;Not Created&gt; . テスト環境は[テストスイート名]-[プラットフォーム名]になり、platformとsuiteの組み合わせになります。 . Serverspecの初期化 . test-kitchenのルール4にしたがって、test/integration/defaultディレクトリへServerspecファイルを配置します。 (test/integration/defaultのdefaultの部分は.kitchen.ymlのsuitesのnameに対応します。テストスイートの名前を変更している場合はServerspecを配置するパスも変更しなければなりません。) . $ cd test/integration/default $ bundle exec serverspec-init Select OS type: 1) UN*X 2) Windows Select number: 1 Select a backend type: 1) SSH 2) Exec (local) Select number: 2 + spec/ + spec/localhost/ + spec/localhost/sample_spec.rb + spec/spec_helper.rb + Rakefile . Serverspecの初期化によって作成されたspecディレクトリをserverspecへリネームします。 これは、test-kitchenがテスト環境へインストールするテストランナー(busser)のプラグインをディレクトリ名から決めるためです。ディレクトリ名を変更しない場合busser-specという存在しないプラグインをインストールしようとしてエラーになります。) . $ mv spec/ serverspec/ . Serverspecの初期化を行うと、サンプルのspecファイルが作成されます。 中身は以下のとおりで、今回作成したいAnsible play bookにちょうど良いので名前だけ変更して中身はそのまま使います。 . mv test/integration/default/serverspec/localhost/sample_spec.rb test/integration/default/serverspec/localhost/webservers_spec.rb . require &#39;spec_helper&#39; describe package(&#39;httpd&#39;), :if =&gt; os[:family] == &#39;redhat&#39; do it { should be_installed } end describe package(&#39;apache2&#39;), :if =&gt; os[:family] == &#39;ubuntu&#39; do it { should be_installed } end describe service(&#39;httpd&#39;), :if =&gt; os[:family] == &#39;redhat&#39; do it { should be_enabled } it { should be_running } end describe service(&#39;apache2&#39;), :if =&gt; os[:family] == &#39;ubuntu&#39; do it { should be_enabled } it { should be_running } end describe service(&#39;org.apache.httpd&#39;), :if =&gt; os[:family] == &#39;darwin&#39; do it { should be_enabled } it { should be_running } end describe port(80) do it { should be_listening } end . リネームしたserverspecディレクトリにGemfileを追加します。 . source &#39;https://rubygems.org&#39; gem &#39;rake&#39; gem &#39;serverspec&#39; . 参考:Rake dependency missing for older rubies · Issue #28 . 仮のsite.yml作成 . 以上でTDDの準備が出来ました。と、言いたいところですが、この状態でkitchen testコマンドを叩くとエラーが発生します。 . $ cd ~/ansibletdd $ bundle exec kitchen test --&gt; Starting Kitchen (v1.4.2) --&gt; Cleaning up any prior instances of &lt;default-ubuntu-1404&gt; ~~~中略~~~ Preparing playbook &gt;&gt;&gt;&gt;&gt;&gt; Exception- &gt;&gt;&gt;&gt;&gt;&gt; Class: Kitchen::ActionFailed &gt;&gt;&gt;&gt;&gt;&gt; Message: Failed to complete #converge action: [unknown file type: site.yml] &gt;&gt;&gt;&gt;&gt;&gt; - &gt;&gt;&gt;&gt;&gt;&gt; Please see .kitchen/logs/kitchen.log for more details &gt;&gt;&gt;&gt;&gt;&gt; Also try running `kitchen diagnose --all` for configuration . とりあえずエラーを解消するため仮のsite.ymlとwebservers.ymlを作成します。 . - include: webservers.yml . - hosts: webservers tasks: . 作成したらもう一度kitchen testを行います。 . $ bundle exec kitchen test --&gt; Starting Kitchen (v1.4.2) --&gt; Cleaning up any prior instances of &lt;default-ubuntu-1404&gt; ~~~ 中略 ~~~ Finished in 0.27052 seconds (files took 0.46124 seconds to load) 4 examples, 4 failures Failed examples: rspec /tmp/verifier/suites/serverspec/localhost/webservers_spec.rb:8 # Package &quot;apache2&quot; should be installed rspec /tmp/verifier/suites/serverspec/localhost/webservers_spec.rb:17 # Service &quot;apache2&quot; should be enabled rspec /tmp/verifier/suites/serverspec/localhost/webservers_spec.rb:18 # Service &quot;apache2&quot; should be running rspec /tmp/verifier/suites/serverspec/localhost/webservers_spec.rb:27 # Port &quot;80&quot; should be listening ~~~ 後略 ~~~ . 今度は、default-ubuntu-1404でServerspecによる検証まで行われ、全てfailしました。 (test-kitchenはテストが失敗するとそのインスタンスでテストをやめてしまうので、それ以降のインスタンスでテストを行いたい場合は、bundle exec kitchen test default-centos-71のようにインスタンス名を指定します。インスタンス名は正規表現でも指定できるので、条件に合う複数のインスタンスをテストすることも出来ます。) . これでようやくTDDの準備が出来ました。 あとは、全てのテストが成功するよう、「書く -&gt; テスト」を繰り返しながらAnsible playbookを書いていけばOKです。 . Ansible playbookの実装 . TDD環境が出来たので、あとはPlay bookを実装していくだけです。 書き方の詳細は本記事の趣旨から外れるのでGoogle先生に聞いてもらうとして、とりあえず全てのテストが通るPlay bookを置いておきます。 . - include: webservers.yml . - hosts: webservers roles: - apache . - apt: pkg=apache2 when: &quot;ansible_os_family == &#39;Debian&#39;&quot; - yum: pkg=httpd when: &quot;ansible_os_family == &#39;RedHat&#39;&quot; - service: name=apache2 state=started enabled=yes when: &quot;ansible_os_family == &#39;Debian&#39;&quot; - service: name=httpd state=started enabled=yes when: &quot;ansible_os_family == &#39;RedHat&#39;&quot; . これで、kitchen testすれば全てのテストが成功するはずです。 . $ bundle exec kitchen test --&gt; Starting Kitchen (v1.4.2) --&gt; Cleaning up any prior instances of &lt;default-ubuntu-1404&gt; ~~~ 中略 ~~~ Package &quot;apache2&quot; should be installed Service &quot;apache2&quot; should be enabled should be running Port &quot;80&quot; should be listening Finished in 0.1665 seconds (files took 1.22 seconds to load) 4 examples, 0 failures Finished verifying &lt;default-ubuntu-1404&gt; (0m28.28s). ~~~ 中略 ~~~ Package &quot;httpd&quot; should be installed Service &quot;httpd&quot; should be enabled should be running Port &quot;80&quot; should be listening Finished in 0.16315 seconds (files took 1.07 seconds to load) 4 examples, 0 failures Finished verifying &lt;default-centos-71&gt; (0m24.25s). ~~~　後略 ~~~ . まとめ . AnsibleをTDDするための環境構築の一連の手順を追いかけました。 test-kitchenを使ってトライ&amp;エラーを簡単に行えるTDD環境を用意するとAnsible(やChef)の開発をサクサク進められる用になりますが、デフォルト設定では動かない箇所などハマりどころがいくつかあるので注意が必要です。ハマった場合はログと関連ドキュメントを読んで頑張りましょう。 . appendix . Docker imageを指定したい場合 . kitchen-docerはKitchen::Driver::Docker.default_imageによってplatform.nameからテスト環境のベースイメージのタグを生成しますが、任意のタグを指定することも出来ます。 その場合は、.kitchen.ymlを以下のように変更します。 . platforms: - name: ubuntu-14.04 driver_config: # &lt;= 追加 image: ubuntu:14.04 # &lt;= 追加 - name: centos-7 driver_config: image: centos:centos7 # &lt;= 追加 privileged: true run_command: /sbin/init; sleep 3 . 複数のホストグループに対応したい場合 . Play bookにホストグループ(例えば、apservers)を追加定義したい場合は、以下のようにします。 . テストスイートではprovisionerのオプションを上書きできるので、テストスイートを増やし、スイートごとにホストグループオプションを設定します。 . suites: - name: webservers # &lt;= defaultから変更 provisioner: # &lt;= 追加 hosts: webservers # &lt;= 追加 - name: apservers # &lt;= 追加 provisioner: # &lt;= 追加 hosts: apservers # &lt;= 追加 . 次にスイートごとのServerspecを用意します。 現在のtestディレクトリは以下のような状態です。 . $ tree test └── integration └── default ├── Rakefile └── serverspec ├── Gemfile ├── localhost │   └── webservers_spec.rb └── spec_helper.rb . このディレクトリに以下の操作を行います。 . defaultディレクトリはテストスイート名なのでこれはwebserversに変更します | Rakefile, Gemfile, spec_helper.rbは複数のテストスイートで共通なので、helpersディレクトリを作りそこへ移動します | webserversディレクトリをコピーしapserversディレクトリとします | コピーしたディレクトリのwebservers_spec.rbをapservers_spec.rbにリネームします。 | $ mv test/integration/default/ test/integration/webservers $ mkdir -p test/integration/helpers/serverspec $ cd test/integration $ mv webservers/Rakefile helpers/ $ mv webservers/serverspec/Gemfile helpers/serverspec/ $ mv webservers/serverspec/spec_helper.rb helpers/serverspec/ $ cp -r webservers/ apservers $ mv apservers/serverspec/localhost/webservers_spec.rb apservers/serverspec/localhost/apservers_spec.rb $ tree test test └── integration ├── apservers │   └── serverspec │   └── localhost │   └── apservers_spec.rb ├── helpers │   ├── Rakefile │   └── serverspec │   ├── Gemfile │   └── spec_helper.rb └── webservers └── serverspec └── localhost └── webservers_spec.rb . 以上で共通のファイルをhelpersへ移動し、各テストスイートに必要なファイル・ディレクトリを用意できました。あとはapservers_spec.rbファイルをapserversグループに適した形に書き換えれば完了です。 . 参考資料 . Ansibleのテストをtest-kitchenとServerspec、dockerで行う - Qiita | Chef &amp; Test Kitchen+Serverspec &amp; Docker &amp; PackerによるInfrastructure as Code事始め - Qiita | test-kitchenのつかいかた - Qiita | Introduction - KitchenCI | Kitchen — Chef Docs | Best Practices — Ansible Documentation | neillturner/kitchen-ansible | portertech/kitchen-docker | test-kitchen/busser | test-kitchen/busser-serverspec | . Best Practices — Ansible Documentation &#8617; &#8617;2 . | Best Practices — Ansible Documentation#top-level-playbooks-are-separated-by-role &#8617; . | Chef &amp; Test Kitchen+Serverspec &amp; Docker &amp; PackerによるInfrastructure as Code事始め - Qiita &#8617; . | Writing a Test - KitchenCI &#8617; . |",
            "url": "https://taka4ma.github.io/fastpages/test-kitchen/ansible/2015/10/01/Creating-an-AnsibleTDD-environment.html",
            "relUrl": "/test-kitchen/ansible/2015/10/01/Creating-an-AnsibleTDD-environment.html",
            "date": " • Oct 1, 2015"
        }
        
    
  

  
  
      ,"page0": {
          "title": "An Example Markdown Post",
          "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
          "url": "https://taka4ma.github.io/fastpages/test/2020-01-14-test-markdown-post.html",
          "relUrl": "/test/2020-01-14-test-markdown-post.html",
          "date": ""
      }
      
  

  

  
      ,"page2": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://taka4ma.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://taka4ma.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}